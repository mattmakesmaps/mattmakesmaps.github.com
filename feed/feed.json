{
	"version": "https://jsonfeed.org/version/1.1",
	"title": "mattmakesmaps",
	"language": "en",
	"home_page_url": "https://mattmakesmaps.com/",
	"feed_url": "https://mattmakesmaps.com/feed/feed.json",
	"description": "Matthew Matt Kenny GIS and woodworking blog.",
	"author": {
		"name": "Matt Kenny",
		"url": "https://mattmakesmaps.com/about-me/"
	},
	"items": [
		{
			"id": "https://mattmakesmaps.com/blog/2023-11-01-fldigi-baofeng/",
			"url": "https://mattmakesmaps.com/blog/2023-11-01-fldigi-baofeng/",
			"title": "FLDIGI on Mac With Digirig and Baofeng HT",
			"content_html": "<p>I participated for the first time in the weekly <a href=\"https://www.psdhn.org/\">Puget Sound Digital Ham Net</a>\nthis past Monday. This net specializes in sending digital data over the 2m and 70cm amateur radio bands\nas opposed to traditional voice communication. This allows for text and image files to be sent over\na variety of different &quot;digital modes&quot;, although the most common for the group appeared to be\n<a href=\"http://www.w1hkj.com/modes/mfsk.htm\">multi-frequency shift keyed</a> aka <code>MFSK128</code>,\nwhere the 128 indicates 128 baud or symbols per second. Pretty amazing to be able to send data across\nSeattle without the internet.</p>\n<p>With the help of <a href=\"https://www.qrz.com/db/KB7SDM\">Ryan KB7SDM</a> and a great\n<a href=\"https://www.youtube.com/watch?v=zSX64XwJ0E4\">getting started presentation</a>\na group member had put together, I was able to receive and decode other participants' messages\nusing the <a href=\"http://www.w1hkj.com/\"><code>fldigi</code> software suite</a>.</p>\n<p>Here is an example of a message transmitted by a net member, received by my radio, and decoded on my\nmacbook pro using <code>fldigi</code>.</p>\n<p><picture><source type=\"image/webp\" srcset=\"https://mattmakesmaps.com/img/a6MA4y-4Pf-320.webp 320w, https://mattmakesmaps.com/img/a6MA4y-4Pf-600.webp 600w, https://mattmakesmaps.com/img/a6MA4y-4Pf-960.webp 960w, https://mattmakesmaps.com/img/a6MA4y-4Pf-1280.webp 1280w, https://mattmakesmaps.com/img/a6MA4y-4Pf-1600.webp 1600w, https://mattmakesmaps.com/img/a6MA4y-4Pf-1920.webp 1920w\" sizes=\"90vw, (min-width: 1280px) 1156px\"><source type=\"image/jpeg\" srcset=\"https://mattmakesmaps.com/img/a6MA4y-4Pf-320.jpeg 320w, https://mattmakesmaps.com/img/a6MA4y-4Pf-600.jpeg 600w, https://mattmakesmaps.com/img/a6MA4y-4Pf-960.jpeg 960w, https://mattmakesmaps.com/img/a6MA4y-4Pf-1280.jpeg 1280w, https://mattmakesmaps.com/img/a6MA4y-4Pf-1600.jpeg 1600w, https://mattmakesmaps.com/img/a6MA4y-4Pf-1920.jpeg 1920w\" sizes=\"90vw, (min-width: 1280px) 1156px\"><img alt=\"Screenshot of fldigi software displaying decoded message.\" loading=\"lazy\" decoding=\"async\" src=\"https://mattmakesmaps.com/img/a6MA4y-4Pf-320.jpeg\" width=\"1920\" height=\"1242\"></picture></p>\n<p>Receiving was as easy as tuning my radio to the net frequency, and turning on my mac's microphone to\ncapture the sound from the radio's speaker. With regards to transmitting however, I wanted to be able\nto connect the radio to directly the computer. This ensures maximum fidelity in the transmission,\nand also allows the software to directly control the radio, &quot;keying&quot; or opening and closing the radio\nfor transmit only while sending a message. Alternatively, I'd have to manually key the radio myself.</p>\n<p>In comes the <a href=\"https://digirig.net/\">digirig</a> a tiny piece of hardware that sits between the\nradio and computer, and essentially acts as a usb soundcard enables software control of the radio\nitself.</p>\n<p>Below you can see my handheld radio, a baofeng UV-5R, and the digirig interface. The digirig is connected\nto the radio via an audio cable that plugs into both the radio's speaker and microphone jacks, allowing\nfor transmit and receive into the macbook pro. The digirig itself is connected to the computer via usb-c.</p>\n<p><picture><source type=\"image/webp\" srcset=\"https://mattmakesmaps.com/img/KwSYhcmrto-320.webp 320w, https://mattmakesmaps.com/img/KwSYhcmrto-600.webp 600w, https://mattmakesmaps.com/img/KwSYhcmrto-960.webp 960w, https://mattmakesmaps.com/img/KwSYhcmrto-1280.webp 1280w, https://mattmakesmaps.com/img/KwSYhcmrto-1600.webp 1600w, https://mattmakesmaps.com/img/KwSYhcmrto-1920.webp 1920w\" sizes=\"90vw, (min-width: 1280px) 1156px\"><source type=\"image/jpeg\" srcset=\"https://mattmakesmaps.com/img/KwSYhcmrto-320.jpeg 320w, https://mattmakesmaps.com/img/KwSYhcmrto-600.jpeg 600w, https://mattmakesmaps.com/img/KwSYhcmrto-960.jpeg 960w, https://mattmakesmaps.com/img/KwSYhcmrto-1280.jpeg 1280w, https://mattmakesmaps.com/img/KwSYhcmrto-1600.jpeg 1600w, https://mattmakesmaps.com/img/KwSYhcmrto-1920.jpeg 1920w\" sizes=\"90vw, (min-width: 1280px) 1156px\"><img alt=\"A baofeng uv-5r handheld ham radio connected to a digirig interface.\" loading=\"lazy\" decoding=\"async\" src=\"https://mattmakesmaps.com/img/KwSYhcmrto-320.jpeg\" width=\"1920\" height=\"2560\"></picture></p>\n<p>Actually configuring the <code>fldigi</code> software to key the radio via the digirig was a little tricky.\n<a href=\"https://forum.digirig.net/t/digirig-flrig-baofeng/580/4\">This post</a> on the digirig forum\nhelped clear it up, however.</p>\n<p>I had to set my <code>fldigi</code> software's <code>Hardware PTT</code> controls to the following (open image in a new tab\nto enlarge):</p>\n<p><picture><source type=\"image/webp\" srcset=\"https://mattmakesmaps.com/img/oIxHPV3M4i-320.webp 320w, https://mattmakesmaps.com/img/oIxHPV3M4i-600.webp 600w, https://mattmakesmaps.com/img/oIxHPV3M4i-960.webp 960w, https://mattmakesmaps.com/img/oIxHPV3M4i-1280.webp 1280w, https://mattmakesmaps.com/img/oIxHPV3M4i-1600.webp 1600w\" sizes=\"90vw, (min-width: 1280px) 1156px\"><source type=\"image/jpeg\" srcset=\"https://mattmakesmaps.com/img/oIxHPV3M4i-320.jpeg 320w, https://mattmakesmaps.com/img/oIxHPV3M4i-600.jpeg 600w, https://mattmakesmaps.com/img/oIxHPV3M4i-960.jpeg 960w, https://mattmakesmaps.com/img/oIxHPV3M4i-1280.jpeg 1280w, https://mattmakesmaps.com/img/oIxHPV3M4i-1600.jpeg 1600w\" sizes=\"90vw, (min-width: 1280px) 1156px\"><img alt=\"fldigi configuration menu for baofeng use.\" loading=\"lazy\" decoding=\"async\" src=\"https://mattmakesmaps.com/img/oIxHPV3M4i-320.jpeg\" width=\"1600\" height=\"912\"></picture></p>\n<p>Basically the magic here is:</p>\n<ul>\n<li>Check <code>Use separate serial port PTT</code></li>\n<li>Check <code>Use RTS</code></li>\n<li>Set <code>Device</code> to <code>/dev/cu.usbserial-1120</code></li>\n</ul>\n<p>The first setting, <code>Use separate serial port PTT</code> I believe enables <code>fldigi</code> to use the new serial port\nwhich the digirig hardware creates.</p>\n<p>The second setting, <code>Use RTS</code> tells <code>fldigi</code> to transmit a <code>Ready to Transmit Signal</code> to the radio, which\nactually keys up the radio and begins the transmission.</p>\n<p>The third setting, for the device, simply selects the digirig from the list of connected devices on\nthe mac. There are two varients listed for each device, with <code>cu</code> or <code>tty</code> prefixes.\ne.g <code>/dev/cu.usbserial-1120</code> or <code>/dev/tty.usbserial-1120</code>. This <a href=\"https://stackoverflow.com/questions/8632586/whats-the-difference-between-dev-tty-and-dev-cu-on-macos\">stack overflow post</a>\nexplains the difference between the two. <code>cu</code> appears to be used for outbound connections on linux\nsystems.</p>\n<p>I was able to successfully transmit over simplex with this setup, and am looking forward to trying\nout more modes in a future iteration of the Puget Sound Digital Hams Net.</p>\n",
			"date_published": "2023-11-01T00:00:00Z"
		}
		,
		{
			"id": "https://mattmakesmaps.com/blog/2023-10-19-site-migration/",
			"url": "https://mattmakesmaps.com/blog/2023-10-19-site-migration/",
			"title": "New Site - From Jekyll to Eleventy",
			"content_html": "<p>I've rebuilt this site using the <a href=\"https://www.11ty.dev/\">Eleventy</a> static site generator.</p>\n<p>The previous version ran on <a href=\"https://jekyllrb.com/\">jekyll</a>, whoose out-of-the-box integration\nwith <a href=\"https://pages.github.com/\">Github Pages</a> felt revolutionary when I made the switch\nfrom WordPress years ago.</p>\n<p>This site is based on the <a href=\"https://github.com/11ty/eleventy-base-blog\">eleventy-base-blog</a> template\n(which appears to be an official release).</p>\n<p>Source files are hosted on the <a href=\"https://github.com/mattmakesmaps/mattmakesmaps.github.com\">mattmakesmaps.github.com</a>\nproject repo's <code>master</code> branch, with <a href=\"https://github.com/mattmakesmaps/mattmakesmaps.github.com/actions/runs/6556377877\">github actions</a>\nused to build and deploy content from the <code>gh-pages</code> branch. At Tableau, I used Travis CI and JetBrains' TeamCity for builds, and getting started with Github Actions felt very similar.</p>\n<p>With the old Jekyll content also being markdown entries, I'll be able to migrate as much or as\nlittle of my old content as I choose over the next few weeks.</p>\n<p>Below is an example of a Github Actions run deploying the site. 35s for a free build\n(since the repo is public) is perfect for my purposes.</p>\n<p><picture><source type=\"image/webp\" srcset=\"https://mattmakesmaps.com/img/q4kJHwBnN7-320.webp 320w, https://mattmakesmaps.com/img/q4kJHwBnN7-600.webp 600w\" sizes=\"90vw, (min-width: 1280px) 1156px\"><source type=\"image/jpeg\" srcset=\"https://mattmakesmaps.com/img/q4kJHwBnN7-320.jpeg 320w, https://mattmakesmaps.com/img/q4kJHwBnN7-600.jpeg 600w\" sizes=\"90vw, (min-width: 1280px) 1156px\"><img alt=\"Screenshot showing the github actions build pipeline. Total runtime is 35 seconds.\" loading=\"lazy\" decoding=\"async\" src=\"https://mattmakesmaps.com/img/q4kJHwBnN7-320.jpeg\" width=\"600\" height=\"646\"></picture></p>\n<p>With regards to images, I wasn't familiar with the current standard\n<a href=\"https://developers.google.com/speed/webp\">webp format</a> nor the best practice of generating multiple sized\nversions of each image, optimizing loading performance across a variety of potential screen sizes.\nThe latter is refered as <a href=\"https://developer.mozilla.org/en-US/docs/Learn/HTML/Multimedia_and_embedding/Responsive_images\">responsive images</a>.</p>\n<p>The Eleventy framework handles this well out-of-the-box, allowing you generate custom export functions\nthat handle all aspects of output resolution and formats. I found the following to be a\ngreat tutorial: <a href=\"https://www.aleksandrhovhannisyan.com/blog/eleventy-image-plugin/\">https://www.aleksandrhovhannisyan.com/blog/eleventy-image-plugin/</a></p>\n",
			"date_published": "2023-10-19T00:00:00Z"
		}
		,
		{
			"id": "https://mattmakesmaps.com/blog/2014-01-15-using-pg-dump-with-postgis-topology/",
			"url": "https://mattmakesmaps.com/blog/2014-01-15-using-pg-dump-with-postgis-topology/",
			"title": "Using pg_dump with PostGIS Topology",
			"content_html": "<p>Using the <a href=\"http://www.postgresql.org/docs/0.0/static/app-pgdump.html\">pg_dump</a> utility is a standard\nmethod for backing up a PostgreSQL database. Furthermore, limiting a <code>pg_dump</code> export to a particular schema increases the portability of your geospatial data across different versions of PostGIS.\nSince the PostGIS function signatures themselves are not copied in the data backup, data can be\nbacked up from a database under one version of PostGIS and restored into a new database of a differing version. <a href=\"http://workshops.boundlessgeo.com/postgis-intro/backup.html\">Boundless</a> has a great intro\nguide to backing up and restoring PostGIS databases.</p>\n<p>Working with PostGIS Topologies however, requires a special tweak. <!-- more --> A typical PostGIS topology contains\ndata spread across three schemas:</p>\n<ul>\n<li>Topology 'Metadata' schema, containing registered topologies and their layers.\nCreated by executing the statement <code>CREATE EXTENSION postgis_topology;</code>.</li>\n<li>Schema containing topology primitives. This is created as the result of a call to\n<a href=\"http://postgis.net/docs/CreateTopology.html\">CreateTopology()</a></li>\n<li>Schema containing topogeometry columns. These would be created by a call to\n<a href=\"http://postgis.net/docs/AddTopoGeometryColumn.html\">AddTopoGeometryColumn</a></li>\n</ul>\n<p>As an example, we'll have a PostGIS database called <code>parcels_postgis</code> with the following:</p>\n<ul>\n<li>Topology extension enabled</li>\n<li>Topology primitives are stored in the <code>parcel_topology</code> schema.</li>\n<li>Topogeometry columns are stored in the <code>parcels</code> schema</li>\n</ul>\n<p>Under this example, a call to <code>pg_dump</code> looks like the following:</p>\n<pre class=\"language-bash\" tabindex=\"0\"><code class=\"language-bash\">pg_dump <span class=\"token parameter variable\">--schema</span><span class=\"token operator\">=</span>topology <span class=\"token parameter variable\">--schema</span><span class=\"token operator\">=</span>parcels <span class=\"token parameter variable\">--schema</span><span class=\"token operator\">=</span>parcel_topology <span class=\"token parameter variable\">--file</span><span class=\"token operator\">=</span>parcel_data.sql parcels_postgis </code></pre>\n<p>Restoring to a new db however, produces the following error:</p>\n<pre class=\"language-bash\" tabindex=\"0\"><code class=\"language-bash\">psql:test_data.sql:644: ERROR:  insert or update on table <span class=\"token string\">\"layer\"</span> violates foreign key constraint <span class=\"token string\">\"layer_topology_id_fkey\"</span>\nDETAIL:  Key <span class=\"token punctuation\">(</span>topology_id<span class=\"token punctuation\">)</span><span class=\"token operator\">=</span><span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span> is not present <span class=\"token keyword\">in</span> table <span class=\"token string\">\"topology\"</span><span class=\"token builtin class-name\">.</span></code></pre>\n<p>This is because the <code>pg_dump</code> utility defaults to INSERT'ing records into the <code>topology</code> schema's\n<code>layer</code> table <strong>before</strong> INSERT'ing records into the <code>topology</code> schema's <code>topology</code> table. Since\nthe <code>layer</code> table has a foreign key constraint with the <code>topology</code> table, this can never work properly.</p>\n<p>One solution therefore, is to manually edit your <code>pg_dump</code> output file to run <code>COPY</code> commands onto\nthe <code>topology.topology</code> table first, then the <code>topology.layer</code> table second. A modified script with\nthe highlighted changes can be seen <a href=\"https://github.com/mattmakesmaps/travis-postgis-test/blob/master/test_data.sql#L633-L651\">here</a>.</p>\n",
			"date_published": "2014-01-15T00:00:00Z"
		}
		,
		{
			"id": "https://mattmakesmaps.com/blog/2014-01-11-configure-postgis-with-travis-ci/",
			"url": "https://mattmakesmaps.com/blog/2014-01-11-configure-postgis-with-travis-ci/",
			"title": "Configure PostGIS with Travis CI",
			"content_html": "<p>Thanks to a great presentation by <a href=\"https://github.com/foundatron\">foundatron</a> on the continuous\nintegration framework, <a href=\"https://travis-ci.org\">Travis CI</a>, I've finally been motivated to push\nfor higher test coverage in my python projects.</p>\n<p>Some of these <a href=\"https://github.com/mattmakesmaps/pgsql2gist\">projects</a> require connectivity to a\nPostGIS database for testing, and with Travis CI that process is extremely straightforward.\nThis post includes notes on configuring a Travis CI environment with PostgreSQL and PostGIS, then\nloading that empty database with data.</p>\n<h3 id=\"postgresql-postgis-versions\" tabindex=\"-1\">PostgreSQL/Postgis Versions <a class=\"header-anchor\" href=\"https://mattmakesmaps.com/blog/2014-01-11-configure-postgis-with-travis-ci/\">#</a></h3>\n<p><strong>NOTE:</strong> These versions are current as of <strong>January 2014</strong>.</p>\n<ul>\n<li>PostgreSQL: 9.1.11 by default, although you can <a href=\"http://about.travis-ci.org/blog/2013-11-29-PostgreSQLql-92-93-now-available/\">explicitly declare</a> 9.2 or 9.3.</li>\n<li>PostGIS: 2.1.1 r12113</li>\n<li>GEOS: 3.3.8</li>\n<li>PROJ: 4.8.0</li>\n<li>GDAL: 1.9.2</li>\n</ul>\n<!-- more -->\n<h3 id=\"configuration\" tabindex=\"-1\">Configuration <a class=\"header-anchor\" href=\"https://mattmakesmaps.com/blog/2014-01-11-configure-postgis-with-travis-ci/\">#</a></h3>\n<p><strong>NOTE:</strong> For background reading on Travis CI, check out the <a href=\"http://about.travis-ci.org/docs/user/getting-started/\">Getting Started</a> and <a href=\"http://about.travis-ci.org/docs/user/build-configuration/\">Build Configuration</a> docs.</p>\n<p>As stated in the <a href=\"http://about.travis-ci.org/docs/user/database-setup/#PostgreSQLQL\">database docs</a>,\na Travis CI environment comes with PostgreSQL installed and ready-to-go. This also includes supporting\nutilities such as: <code>psql</code>,<code>pg_dump</code>, and <code>pg_restore</code>. Since we're using PostgreSQL 9.1+ and PostGIS 2.0+,\nPostGIS can be installed using the <code>CREATE EXTENSION</code> syntax.</p>\n<p>The <code>.travis.yml</code> configuration file should now be modified to execute <code>psql</code> calls in the\n<code>before_script</code> block to:</p>\n<ol>\n<li>Create the database</li>\n<li>Create the PostGIS/PostGIS Topology Extensions</li>\n<li>Populate the database with test data. (See Below for Instructions)</li>\n</ol>\n<p>A reference example <code>.travis.yml</code> looks like this:</p>\n<pre class=\"language-yml\" tabindex=\"0\"><code class=\"language-yml\"><span class=\"token key atrule\">language</span><span class=\"token punctuation\">:</span> python\n<span class=\"token key atrule\">python</span><span class=\"token punctuation\">:</span>\n  <span class=\"token punctuation\">-</span> <span class=\"token string\">\"2.7\"</span>\n\n<span class=\"token comment\"># command to install dependencies</span>\n<span class=\"token key atrule\">install</span><span class=\"token punctuation\">:</span>\n  <span class=\"token punctuation\">-</span> <span class=\"token string\">\"pip install -r requirements.txt --use-mirrors\"</span>\n\n<span class=\"token comment\"># database creation</span>\n<span class=\"token key atrule\">before_script</span><span class=\"token punctuation\">:</span>\n  <span class=\"token punctuation\">-</span> psql <span class=\"token punctuation\">-</span>c 'create database travis_postgis;' <span class=\"token punctuation\">-</span>U postgres\n  <span class=\"token punctuation\">-</span> psql <span class=\"token punctuation\">-</span>c 'CREATE EXTENSION postgis;' <span class=\"token punctuation\">-</span>U postgres <span class=\"token punctuation\">-</span>d travis_postgis\n  <span class=\"token punctuation\">-</span> psql <span class=\"token punctuation\">-</span>c 'CREATE EXTENSION postgis_topology;' <span class=\"token punctuation\">-</span>U postgres <span class=\"token punctuation\">-</span>d travis_postgis\n  <span class=\"token punctuation\">-</span> psql <span class=\"token punctuation\">-</span>f test_data.sql <span class=\"token punctuation\">-</span>U postgres <span class=\"token punctuation\">-</span>d travis_postgis\n\n<span class=\"token comment\"># command to run tests</span>\n<span class=\"token key atrule\">script</span><span class=\"token punctuation\">:</span> nosetests <span class=\"token punctuation\">-</span><span class=\"token punctuation\">-</span>verbose</code></pre>\n<h3 id=\"creating-test-data\" tabindex=\"-1\">Creating Test Data <a class=\"header-anchor\" href=\"https://mattmakesmaps.com/blog/2014-01-11-configure-postgis-with-travis-ci/\">#</a></h3>\n<p>The <code>pg_dump</code> utility can be used to export the contents of a PostGIS database into a sql file,\nsuitable for loading into a newly created database by the Travis worker. Key to this is to have testing\ndata that you want to export inside of a separate schema (e.g. not in <code>public</code>). With <code>pg_dump</code> we can\nspecify an individual schema of data tables to export, otherwise we'd be stuck with exporting potentially\nincompatible PostGIS function signitures in addition to our data. Boundless has a\n<a href=\"http://workshops.boundlessgeo.com/postgis-intro/backup.html\">good article</a> on backup strategies for PostGIS.</p>\n<p>From our source PostGIS database, export tables from our schema of interest (<code>test_data</code>) into <code>test_data.sql</code></p>\n<pre class=\"language-bash\" tabindex=\"0\"><code class=\"language-bash\">$ pg_dump <span class=\"token parameter variable\">--schema</span><span class=\"token operator\">=</span>test_data travis_postgis <span class=\"token operator\">></span> test_data.sql</code></pre>\n<p>As seen in the section above, the resulting sql file, <code>test_data.sql</code> is then executed as part of the\nTravis <code>before_script</code> block, populating the testing database with geometries.</p>\n<p><strong>NOTE:</strong> I've used the same name <code>travis_postgis</code> for both my local database as well as the testing\ndatabase used by Travis CI. This isn't required.</p>\n<h3 id=\"wrap-up\" tabindex=\"-1\">Wrap Up <a class=\"header-anchor\" href=\"https://mattmakesmaps.com/blog/2014-01-11-configure-postgis-with-travis-ci/\">#</a></h3>\n<p>Thanks to the combination of PostgreSQL's easy to use <code>CREATE EXTENSION</code> syntax along with Travis CI's flexible build configurations, setting up a custom PostGIS database is fairly simple.</p>\n<p>An example repository with a <code>.travis.yml</code> file and an example unit test can be found here: https://github.com/mattmakesmaps/travis-postgis-test</p>\n<p>This repository's Travis CI build log can be found here: https://travis-ci.org/mattmakesmaps/travis-postgis-test</p>\n",
			"date_published": "2014-01-11T00:00:00Z"
		}
		,
		{
			"id": "https://mattmakesmaps.com/blog/2013-11-13-creating-label-points-with-openstreetmap-data/",
			"url": "https://mattmakesmaps.com/blog/2013-11-13-creating-label-points-with-openstreetmap-data/",
			"title": "Creating Label Points With OpenStreetMap Data",
			"content_html": "<h2 id=\"tl-dr\" tabindex=\"-1\">tl;dr <a class=\"header-anchor\" href=\"https://mattmakesmaps.com/blog/2013-11-13-creating-label-points-with-openstreetmap-data/\">#</a></h2>\n<pre class=\"language-sql\" tabindex=\"0\"><code class=\"language-sql\"><span class=\"token comment\">-- Use a CTE to create a table of water polygons, aggregating</span>\n<span class=\"token comment\">-- overlapping polygons sharing the same name</span>\n<span class=\"token keyword\">WITH</span> polys <span class=\"token keyword\">AS</span> <span class=\"token punctuation\">(</span>\n    <span class=\"token keyword\">SELECT</span> name<span class=\"token punctuation\">,</span> <span class=\"token punctuation\">(</span>ST_DUMP<span class=\"token punctuation\">(</span>ST_BUFFER<span class=\"token punctuation\">(</span>ST_Collect<span class=\"token punctuation\">(</span><span class=\"token keyword\">geometry</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token number\">0</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>geom <span class=\"token keyword\">AS</span> single_geom\n    <span class=\"token keyword\">FROM</span> osm_new_waterareas\n    <span class=\"token keyword\">WHERE</span> name <span class=\"token operator\">IS</span> <span class=\"token operator\">NOT</span> <span class=\"token boolean\">NULL</span>\n    <span class=\"token keyword\">GROUP</span> <span class=\"token keyword\">BY</span> name\n<span class=\"token punctuation\">)</span>\n<span class=\"token comment\">-- Generate a name and label point for each feature</span>\n<span class=\"token comment\">-- Generate an accurate area attribute by casting to geography</span>\n<span class=\"token keyword\">SELECT</span> name<span class=\"token punctuation\">,</span> ST_PointOnSurface<span class=\"token punctuation\">(</span>single_geom<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n       ST_Area<span class=\"token punctuation\">(</span>Geography<span class=\"token punctuation\">(</span>ST_Transform<span class=\"token punctuation\">(</span>single_geom<span class=\"token punctuation\">,</span> <span class=\"token number\">4326</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">AS</span> area\n<span class=\"token keyword\">FROM</span> polys<span class=\"token punctuation\">;</span></code></pre>\n<!-- more -->\n<h2 id=\"overview\" tabindex=\"-1\">Overview <a class=\"header-anchor\" href=\"https://mattmakesmaps.com/blog/2013-11-13-creating-label-points-with-openstreetmap-data/\">#</a></h2>\n<p><a href=\"http://www.openstreetmap.org/\">OpenStreetMap</a> is one the most amazing data projects I know of.\nThe breadth of high-quality, high-precision features contained with the OSM Planet never ceases\nto impress me. That being said, the freedom of the OSM data model, which allows this high-level of\nflexibility and openness, is not without its problems. Having participated in the OSM edit-a-thon,\nI was inspired to deep dive into the OSM tagging ontology, and subsequent rendering workflows. As part\nof this exploration, one of the major problems I've run into was the generation of label points\nderived from Open Street Map data.</p>\n<p>The following example is illustrative of the primary problem faced when generating label points,\noverlapping geometries. The SQL statement below returns all features within an <a href=\"http://imposm.org\">imposm</a>\ndatabase's <code>osm_new_waterareas</code> table named, 'Lake Chelan'. Three geometries are returned, one\nrepresenting the entire lake, and two others representing northern and southern sections of the lake.\nAll three share a name of, <code>Lake Chelan</code>, but two are of type <code>water</code>, and one is of type <code>reservoir</code>.</p>\n<pre class=\"language-sql\" tabindex=\"0\"><code class=\"language-sql\"><span class=\"token keyword\">SELECT</span> name<span class=\"token punctuation\">,</span> <span class=\"token keyword\">type</span><span class=\"token punctuation\">,</span> osm_id\n<span class=\"token keyword\">FROM</span> osm_new_waterareas\n<span class=\"token keyword\">WHERE</span> name <span class=\"token operator\">=</span> <span class=\"token string\">'Lake Chelan'</span><span class=\"token punctuation\">;</span>\n\n    name     <span class=\"token operator\">|</span>   <span class=\"token keyword\">type</span>    <span class=\"token operator\">|</span>  osm_id   \n<span class=\"token comment\">-------------+-----------+-----------</span>\n Lake Chelan <span class=\"token operator\">|</span> reservoir <span class=\"token operator\">|</span>    <span class=\"token number\">446718</span>\n Lake Chelan <span class=\"token operator\">|</span> water     <span class=\"token operator\">|</span> <span class=\"token number\">135297050</span>\n Lake Chelan <span class=\"token operator\">|</span> water     <span class=\"token operator\">|</span>  <span class=\"token number\">52045429</span></code></pre>\n<p>Click the map below to view each of the three geometries.</p>\n<p><code>gist 03d7f78a1591971ed2d8 chelan.geojson</code></p>\n<p>Rendering label points using PostGIS's <a href=\"http://postgis.org/docs/ST_PointOnSurface.html\">ST_PointOnSurface()</a>\nfunction would yield three separate points, as illustrated below. I however, would like only a single\nlabel point for each feature.</p>\n<p><code>gist 9cf8b49844cb43dfae81 chelan.geojson</code></p>\n<h2 id=\"step-by-step\" tabindex=\"-1\">Step By Step <a class=\"header-anchor\" href=\"https://mattmakesmaps.com/blog/2013-11-13-creating-label-points-with-openstreetmap-data/\">#</a></h2>\n<p>In addition to a single label point, I'd also like to attribute that label point with an area value,\nto be used as a toggle for display at varying zoom levels.</p>\n<p>The query at the beginning of the post generates this output table. Let's walk through the major parts\nthat make up the <code>single_geom</code> parameter, step-by-step.</p>\n<h3 id=\"step-one-st-collect\" tabindex=\"-1\">Step One: ST_Collect() <a class=\"header-anchor\" href=\"https://mattmakesmaps.com/blog/2013-11-13-creating-label-points-with-openstreetmap-data/\">#</a></h3>\n<p>The <a href=\"http://postgis.net/docs/manual-1.4/ST_Collect.html\">ST_Collect()</a> in PostGIS is an aggregate\nfunction. Just as a <code>GROUP BY</code> clause can be used to aggregate features sharing a common attribute\nvalue, <code>ST_Collect()</code> can be used to group geometries. In this case, we'll use it to group\ngeometries that are associated with the same name. See the code snippet below.</p>\n<pre class=\"language-sql\" tabindex=\"0\"><code class=\"language-sql\"><span class=\"token comment\">-- Execute ST_Collect() Function, creating a MULTIPOLYGON</span>\n<span class=\"token comment\">-- for all features sharing a common name.</span>\n<span class=\"token keyword\">WITH</span> collected <span class=\"token keyword\">as</span> <span class=\"token punctuation\">(</span>\n    <span class=\"token keyword\">SELECT</span> name<span class=\"token punctuation\">,</span> ST_Collect<span class=\"token punctuation\">(</span><span class=\"token keyword\">geometry</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">AS</span> <span class=\"token keyword\">geometry</span>\n    <span class=\"token keyword\">FROM</span> osm_new_waterareas\n    <span class=\"token keyword\">WHERE</span> name <span class=\"token operator\">=</span> <span class=\"token string\">'Lake Chelan'</span>\n    <span class=\"token keyword\">GROUP</span> <span class=\"token keyword\">BY</span> name\n<span class=\"token punctuation\">)</span> <span class=\"token keyword\">SELECT</span> name<span class=\"token punctuation\">,</span> ST_GeometryType<span class=\"token punctuation\">(</span><span class=\"token keyword\">geometry</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> ST_NRings<span class=\"token punctuation\">(</span><span class=\"token keyword\">geometry</span><span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">FROM</span> collected<span class=\"token punctuation\">;</span>\n\n<span class=\"token comment\">-- Results</span>\n    name     <span class=\"token operator\">|</span> st_geometrytype <span class=\"token operator\">|</span> st_nrings \n<span class=\"token comment\">-------------+-----------------+-----------</span>\n Lake Chelan <span class=\"token operator\">|</span> ST_MultiPolygon <span class=\"token operator\">|</span>         <span class=\"token number\">4</span></code></pre>\n<p>This produces the following MULTIPOLYGON result.</p>\n<p><code>gist 8d4cdbc307deb6d7977f</code></p>\n<h3 id=\"step-two-st-buffer\" tabindex=\"-1\">Step Two: ST_Buffer() <a class=\"header-anchor\" href=\"https://mattmakesmaps.com/blog/2013-11-13-creating-label-points-with-openstreetmap-data/\">#</a></h3>\n<p>The <a href=\"http://www.postgis.org/docs/ST_Buffer.html\">ST_Buffer()</a> function is used as somewhat of a hack.\nIt has the special quality of creating from its inputs, a new OGC-compliant geometry. This means that\nwhen given a set of input geometries, and a '0' buffer-distance value, we are essentially left with a\ngeometry clean geometry that represents the outer-most ring of our MULTIPOLYGON created during the\n<code>ST_Collect()</code> operation.</p>\n<pre class=\"language-sql\" tabindex=\"0\"><code class=\"language-sql\"><span class=\"token comment\">-- Add a 0-distance buffer to our above result, creating a</span>\n<span class=\"token comment\">-- new single polygon representing the outer ring.</span>\n<span class=\"token keyword\">WITH</span> coll_buff <span class=\"token keyword\">as</span> <span class=\"token punctuation\">(</span>\n    <span class=\"token keyword\">SELECT</span> name<span class=\"token punctuation\">,</span> ST_Buffer<span class=\"token punctuation\">(</span>ST_Collect<span class=\"token punctuation\">(</span><span class=\"token keyword\">geometry</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token number\">0</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">AS</span> <span class=\"token keyword\">geometry</span>\n    <span class=\"token keyword\">FROM</span> osm_new_waterareas\n    <span class=\"token keyword\">WHERE</span> name <span class=\"token operator\">=</span> <span class=\"token string\">'Lake Chelan'</span>\n    <span class=\"token keyword\">GROUP</span> <span class=\"token keyword\">BY</span> name\n<span class=\"token punctuation\">)</span> <span class=\"token keyword\">SELECT</span> name<span class=\"token punctuation\">,</span> ST_GeometryType<span class=\"token punctuation\">(</span><span class=\"token keyword\">geometry</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> ST_NRings<span class=\"token punctuation\">(</span><span class=\"token keyword\">geometry</span><span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">FROM</span> coll_buff<span class=\"token punctuation\">;</span>\n\n<span class=\"token comment\">-- Results</span>\n    name     <span class=\"token operator\">|</span> st_geometrytype <span class=\"token operator\">|</span> st_nrings \n<span class=\"token comment\">-------------+-----------------+-----------</span>\n Lake Chelan <span class=\"token operator\">|</span> ST_Polygon      <span class=\"token operator\">|</span>         <span class=\"token number\">1</span></code></pre>\n<p>Now we're really looking good. We've got a single polygon that represents our water feature.</p>\n<p><code>gist b76fd3997f99086f6d24</code></p>\n<p>I could run <code>ST_PointOnSurface()</code> against the geometry above, and return a single label point. So what\nmore needs to be done? The example above works because all records within my OSM planet file with water\nfeatures named <code>Lake Chelan</code> happen to occur in the same spot. It's a very unique name. What happens\nwhen I run the same query against a more common name, <code>Twin Lakes</code>?</p>\n<pre class=\"language-sql\" tabindex=\"0\"><code class=\"language-sql\"><span class=\"token comment\">-- Re-execute with a much more common name</span>\n<span class=\"token keyword\">WITH</span> coll_buff <span class=\"token keyword\">as</span> <span class=\"token punctuation\">(</span>\n    <span class=\"token keyword\">SELECT</span> name<span class=\"token punctuation\">,</span> ST_Buffer<span class=\"token punctuation\">(</span>ST_Collect<span class=\"token punctuation\">(</span><span class=\"token keyword\">geometry</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token number\">0</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">AS</span> <span class=\"token keyword\">geometry</span>\n    <span class=\"token keyword\">FROM</span> osm_new_waterareas\n    <span class=\"token keyword\">WHERE</span> name <span class=\"token operator\">=</span> <span class=\"token string\">'Twin Lakes'</span>\n    <span class=\"token keyword\">GROUP</span> <span class=\"token keyword\">BY</span> name\n<span class=\"token punctuation\">)</span> <span class=\"token keyword\">SELECT</span> name<span class=\"token punctuation\">,</span> ST_GeometryType<span class=\"token punctuation\">(</span><span class=\"token keyword\">geometry</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> ST_NRings<span class=\"token punctuation\">(</span><span class=\"token keyword\">geometry</span><span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">FROM</span> coll_buff<span class=\"token punctuation\">;</span>\n\n<span class=\"token comment\">-- Our results generate a MULTIPOLYGON, not a POLYGON</span>\n    name    <span class=\"token operator\">|</span> st_geometrytype <span class=\"token operator\">|</span> st_nrings \n<span class=\"token comment\">------------+-----------------+-----------</span>\n Twin Lakes <span class=\"token operator\">|</span> ST_MultiPolygon <span class=\"token operator\">|</span>       <span class=\"token number\">272</span></code></pre>\n<p>A single record is created, however it is the aggregate MULTIPOLYGON of all features in the globe\nthat happen to be named <code>Twin Lakes</code>. Executing <code>ST_PointOnSurface()</code> would return a single point\ngeometry, not the 272 unique label points we need.</p>\n<h3 id=\"step-three-st-dump\" tabindex=\"-1\">Step Three: ST_Dump() <a class=\"header-anchor\" href=\"https://mattmakesmaps.com/blog/2013-11-13-creating-label-points-with-openstreetmap-data/\">#</a></h3>\n<p>Now that our <code>ST_Collect()</code> + <code>ST_Buffer()</code> combo has given us a mixed bag of POLYGON and\nMULTIPOLYGON geometries, it's explode these guys into separate features. For that, we'll be using\nthe <a href=\"http://postgis.refractions.net/docs/ST_Dump.html\">ST_Dump()</a> function. In the example of our\nLake Chelan polygon, <code>ST_Dump()</code> will create for us our same polygon. However, for our example of\nthe <code>Twin Lakes</code> MULTIPOLYGON with 272 rings, we'll get back 272 unique records. This will allow us\nto create a label point for each instance of <code>Twin Lakes</code></p>\n<p>ST_Dump is a bit tricky in that it doesn't simply return the exploded geom (MULTIPOLYGON --&gt; POLYGON),\nbut rather a special <a href=\"http://postgis.net/docs/geometry_dump.html\">geometry_dump</a> data type. From that\nresulting datatype, we'll select out the <code>geom</code> field, giving us our POLYGON.</p>\n<pre class=\"language-sql\" tabindex=\"0\"><code class=\"language-sql\"><span class=\"token comment\">-- ST_Dump - Lake Chelan Example</span>\n<span class=\"token comment\">-- NOTE: Wrapping ST_Dump() call in parentheses, and returning the geom</span>\n<span class=\"token comment\">-- field from the resulting geometry_dump.</span>\n<span class=\"token keyword\">WITH</span> coll_buff <span class=\"token keyword\">as</span> <span class=\"token punctuation\">(</span>\n    <span class=\"token keyword\">SELECT</span> name<span class=\"token punctuation\">,</span> <span class=\"token punctuation\">(</span>ST_Dump<span class=\"token punctuation\">(</span>ST_Buffer<span class=\"token punctuation\">(</span>ST_Collect<span class=\"token punctuation\">(</span><span class=\"token keyword\">geometry</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token number\">0</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>geom <span class=\"token keyword\">AS</span> <span class=\"token keyword\">geometry</span>\n    <span class=\"token keyword\">FROM</span> osm_new_waterareas\n    <span class=\"token keyword\">WHERE</span> name <span class=\"token operator\">=</span> <span class=\"token string\">'Lake Chelan'</span>\n    <span class=\"token keyword\">GROUP</span> <span class=\"token keyword\">BY</span> name\n<span class=\"token punctuation\">)</span> <span class=\"token keyword\">SELECT</span> name<span class=\"token punctuation\">,</span> ST_GeometryType<span class=\"token punctuation\">(</span><span class=\"token keyword\">geometry</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> ST_NRings<span class=\"token punctuation\">(</span><span class=\"token keyword\">geometry</span><span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">FROM</span> coll_buff<span class=\"token punctuation\">;</span>\n\n<span class=\"token comment\">-- Returns a single feature as expected.</span>\n    name     <span class=\"token operator\">|</span> st_geometrytype <span class=\"token operator\">|</span> st_nrings \n<span class=\"token comment\">-------------+-----------------+-----------</span>\n Lake Chelan <span class=\"token operator\">|</span> ST_Polygon      <span class=\"token operator\">|</span>         <span class=\"token number\">1</span>\n\n\n<span class=\"token comment\">-- ST_Dump - Twin Lakes Example</span>\n<span class=\"token keyword\">WITH</span> coll_buff <span class=\"token keyword\">as</span> <span class=\"token punctuation\">(</span>\n    <span class=\"token keyword\">SELECT</span> name<span class=\"token punctuation\">,</span> <span class=\"token punctuation\">(</span>ST_Dump<span class=\"token punctuation\">(</span>ST_Buffer<span class=\"token punctuation\">(</span>ST_Collect<span class=\"token punctuation\">(</span><span class=\"token keyword\">geometry</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token number\">0</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>geom <span class=\"token keyword\">AS</span> <span class=\"token keyword\">geometry</span>\n    <span class=\"token keyword\">FROM</span> osm_new_waterareas\n    <span class=\"token keyword\">WHERE</span> name <span class=\"token operator\">=</span> <span class=\"token string\">'Twin Lakes'</span>\n    <span class=\"token keyword\">GROUP</span> <span class=\"token keyword\">BY</span> name\n<span class=\"token punctuation\">)</span> <span class=\"token keyword\">SELECT</span> name<span class=\"token punctuation\">,</span> ST_GeometryType<span class=\"token punctuation\">(</span><span class=\"token keyword\">geometry</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> ST_NRings<span class=\"token punctuation\">(</span><span class=\"token keyword\">geometry</span><span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">FROM</span> coll_buff<span class=\"token punctuation\">;</span>\n\n<span class=\"token comment\">-- Returns each of the 272 rings of the MULTIPOLYGON as</span>\n<span class=\"token comment\">-- unique polygon features.</span>\n    name    <span class=\"token operator\">|</span> st_geometrytype <span class=\"token operator\">|</span> st_nrings \n<span class=\"token comment\">------------+-----------------+-----------</span>\n Twin Lakes <span class=\"token operator\">|</span> ST_Polygon      <span class=\"token operator\">|</span>         <span class=\"token number\">1</span>\n Twin Lakes <span class=\"token operator\">|</span> ST_Polygon      <span class=\"token operator\">|</span>         <span class=\"token number\">1</span>\n Twin Lakes <span class=\"token operator\">|</span> ST_Polygon      <span class=\"token operator\">|</span>         <span class=\"token number\">1</span>\n Twin Lakes <span class=\"token operator\">|</span> ST_Polygon      <span class=\"token operator\">|</span>         <span class=\"token number\">1</span>\n<span class=\"token comment\">-- NOTE: Selection of results shown.</span></code></pre>\n<h3 id=\"step-four-generate-an-area-attribute\" tabindex=\"-1\">Step Four: Generate An Area Attribute <a class=\"header-anchor\" href=\"https://mattmakesmaps.com/blog/2013-11-13-creating-label-points-with-openstreetmap-data/\">#</a></h3>\n<p>In order to have some type of filtration attribute to filter the display of our labels\nat different zoom levels, we'll be calculating an area attribute. Since our data are in\nthe Spherical Mercator projection common to all web maps, we have inherit problems\ngenerating accurate area calculations directly. One solution to this is to CAST our\ngeometries into a PostGIS <a href=\"http://workshops.boundlessgeo.com/postgis-intro/geography.html\">geography</a>\ndata type.</p>\n<p>As a prerequisite to the Geometry --&gt; Geography cast, we need to first use\n<a href=\"http://www.postgis.org/docs/ST_Transform.html\">ST_Transform</a> to convert our data from the\nSpherical Mercator projection to WGS84 Lat/Lng.</p>\n<p>The area calculation snippet looks like this</p>\n<pre class=\"language-sql\" tabindex=\"0\"><code class=\"language-sql\">ST_Area<span class=\"token punctuation\">(</span>Geography<span class=\"token punctuation\">(</span>ST_Transform<span class=\"token punctuation\">(</span>single_geom<span class=\"token punctuation\">,</span> <span class=\"token number\">4326</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">AS</span> area</code></pre>\n<p>And wrapped into our larger label point SQL statement, looks like this.</p>\n<pre class=\"language-sql\" tabindex=\"0\"><code class=\"language-sql\"><span class=\"token keyword\">WITH</span> polys <span class=\"token keyword\">AS</span> <span class=\"token punctuation\">(</span>\n    <span class=\"token keyword\">SELECT</span> name<span class=\"token punctuation\">,</span> <span class=\"token punctuation\">(</span>ST_DUMP<span class=\"token punctuation\">(</span>ST_BUFFER<span class=\"token punctuation\">(</span>ST_Collect<span class=\"token punctuation\">(</span><span class=\"token keyword\">geometry</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> <span class=\"token number\">0</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>geom <span class=\"token keyword\">AS</span> single_geom\n    <span class=\"token keyword\">FROM</span> osm_new_waterareas\n    <span class=\"token keyword\">WHERE</span> name <span class=\"token operator\">=</span> <span class=\"token string\">'Lake Chelan'</span> \n    <span class=\"token keyword\">GROUP</span> <span class=\"token keyword\">BY</span> name\n<span class=\"token punctuation\">)</span>\n<span class=\"token comment\">-- Generate a name and label point for each feature</span>\n<span class=\"token comment\">-- Generate an accurate area attribute by casting to geography</span>\n<span class=\"token keyword\">SELECT</span> name<span class=\"token punctuation\">,</span> ST_PointOnSurface<span class=\"token punctuation\">(</span>single_geom<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n       ST_Area<span class=\"token punctuation\">(</span>Geography<span class=\"token punctuation\">(</span>ST_Transform<span class=\"token punctuation\">(</span>single_geom<span class=\"token punctuation\">,</span> <span class=\"token number\">4326</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span> <span class=\"token keyword\">AS</span> area\n<span class=\"token keyword\">FROM</span> polys<span class=\"token punctuation\">;</span></code></pre>\n<p>Just to drive home the importance of accurate area calculations, our call using the CAST\nto geography returns a value of 132.028 square kilometers, while using the raw Spherical\nMercator geometry returns an area value of 295.106 square kilometers! Our geography-based\narea calculation is much more in line with the 135 square kilometer value\n<a href=\"http://en.wikipedia.org/wiki/Lake_Chelan\">reported by wikipedia</a>.</p>\n<h2 id=\"wrap-up\" tabindex=\"-1\">Wrap-up <a class=\"header-anchor\" href=\"https://mattmakesmaps.com/blog/2013-11-13-creating-label-points-with-openstreetmap-data/\">#</a></h2>\n<p>And finally, after all that effort, we get the point shown below.</p>\n<p><code>gist cb1f750979bbcf40a8e5</code></p>\n<h3 id=\"speeding-up-with-indexes\" tabindex=\"-1\">Speeding Up With Indexes <a class=\"header-anchor\" href=\"https://mattmakesmaps.com/blog/2013-11-13-creating-label-points-with-openstreetmap-data/\">#</a></h3>\n<p>While this exercise is extremely fast on our small test dataset, scaling this up to an\nentire imposm OSM planet import is another thing entirely. To facilitate this process,\nboth spatial and non-spatial indexes can be utilized.</p>\n<p>I created a partial btree index on the name column, a functional index on the transformation\nof geometric data to EPSG 4326, and a gist index already existed on the geometry column\nas part of the imposm import.</p>\n<pre class=\"language-sql\" tabindex=\"0\"><code class=\"language-sql\"><span class=\"token comment\">-- Create a partial index on names that are not null.</span>\n<span class=\"token keyword\">CREATE</span> <span class=\"token keyword\">INDEX</span> idx_waterareas_name_partial <span class=\"token keyword\">ON</span> osm_new_waterareas <span class=\"token punctuation\">(</span>name<span class=\"token punctuation\">)</span> <span class=\"token keyword\">WHERE</span> name <span class=\"token operator\">IS</span> <span class=\"token operator\">NOT</span> <span class=\"token boolean\">NULL</span><span class=\"token punctuation\">;</span>\n<span class=\"token comment\">-- Create a functional index on the transformation</span>\n<span class=\"token keyword\">CREATE</span> <span class=\"token keyword\">INDEX</span> idx_waterareas_4326 <span class=\"token keyword\">ON</span> osm_new_waterareas <span class=\"token keyword\">USING</span> gist<span class=\"token punctuation\">(</span>ST_Transform<span class=\"token punctuation\">(</span><span class=\"token keyword\">geometry</span><span class=\"token punctuation\">,</span> <span class=\"token number\">4326</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span></code></pre>\n<p>This process, after applying indexes, took about 5.4 minutes to create. That is, to create a global\nset of label points for ~185,000 named water features within the OSM planet file, with both a name and\ndynamically calculated area attribute. This test was performed on modest desktop hardware, on a PostGIS\ninstance that was already hot (had been running, been used for querying water area data as part\nof this experiment).</p>\n",
			"date_published": "2013-11-13T00:00:00Z"
		}
		,
		{
			"id": "https://mattmakesmaps.com/blog/2013-10-15-tilestache-links-roundup/",
			"url": "https://mattmakesmaps.com/blog/2013-10-15-tilestache-links-roundup/",
			"title": "TileStache-Links-Roundup",
			"content_html": "<p>I'm giving a presentation at this year's <a href=\"http://cugos.org/events/2013/10/16/fall-fling/\">CUGOS Fall Fling Bling</a>, on <a href=\"http://tilestache.org\">TileStache</a>. The list below are a series of interesting links I've found regarding TileStache, or Vector Tiles in general.</p>\n<h2 id=\"mind-of-migurski\" tabindex=\"-1\">Mind of Migurski <a class=\"header-anchor\" href=\"https://mattmakesmaps.com/blog/2013-10-15-tilestache-links-roundup/\">#</a></h2>\n<ul>\n<li><a href=\"http://mike.teczno.com/notes/vector-tile-rendering-numbers.html\">Tiled Vector Update, with Math</a></li>\n<li><a href=\"http://mike.teczno.com/notes/postgreslessness-mapnik-vectiles.html\">the libery of postgreslessness: tiled vectors in mapnik</a></li>\n<li><a href=\"http://mike.teczno.com/notes/tilestache.html\">Presenting TileStache</a></li>\n</ul>\n<h2 id=\"nelson-minar-vector-tiles-notes\" tabindex=\"-1\">Nelson Minar Vector Tiles Notes <a class=\"header-anchor\" href=\"https://mattmakesmaps.com/blog/2013-10-15-tilestache-links-roundup/\">#</a></h2>\n<ul>\n<li><a href=\"https://github.com/NelsonMinar/vector-river-map\">Map of American Rivers</a>: <strong>NOTE:</strong> This is a fantastic tutorial.</li>\n<li><a href=\"http://bl.ocks.org/NelsonMinar/5851197\">TopoJSON Vector Maps from OSM</a></li>\n<li><a href=\"http://vimeopro.com/openstreetmapus/state-of-the-map-us-2013/video/68099164\">TopoJSON: A Smaller GeoJSON with Some Neat Tricks</a></li>\n</ul>\n<h2 id=\"data\" tabindex=\"-1\">Data <a class=\"header-anchor\" href=\"https://mattmakesmaps.com/blog/2013-10-15-tilestache-links-roundup/\">#</a></h2>\n<ul>\n<li><a href=\"http://openstreetmap.us/~migurski/vector-datasource/\">OSM US Vector Tiles</a></li>\n</ul>\n<p>My own slides from the Fall Fling can be found <a href=\"https://speakerdeck.com/mattmakesmaps/tilestache-more-then-youre-granddads-tilecache-server\">here</a>. An introductory blog post on rendering TopoJSON with TileStache can be found, <a href=\"http://mattmakesmaps.com/blog/2013/10/09/tilestache-rendering-topojson/\">here</a>.</p>\n",
			"date_published": "2013-10-15T00:00:00Z"
		}
		,
		{
			"id": "https://mattmakesmaps.com/blog/2013-10-09-tilestache-rendering-topojson/",
			"url": "https://mattmakesmaps.com/blog/2013-10-09-tilestache-rendering-topojson/",
			"title": "TileStache: Generate [Topo|Geo]JSON Vector Tiles",
			"content_html": "<p>Vector tiles are simply tiled representations of geographic data, much like raster tiles\nused to power typical web maps such as OpenStreetMap. They differ from traditional\nraster tiles however in that instead being an image, they actually contain the\ngeographic coordinates and attributes of the features that exist within their bounding boxes.\nVector tiles can be used for a variety of different rendered outputs within a modern web-mapping\napplication. One examples can include serving as an intermediate step in the processing of\nraster tiles. This approach is adopted by Mapbox, who have defined their own\n<a href=\"https://www.mapbox.com/blog/vector-tiles/\">mapnik-vector-tile</a> spec. This allows for amazing\nstyling possibilities, allowing raster tiles to be generated with different styles quickly and\nefficiently based on the same dataset. Another approach relies on transmitting vector data directly\nto the client, where client-side libs render data as SVGs directly in the browser. <a href=\"http://d3js.org\">D3.js</a>\nis a JavaScript library that can do this just this, as illustrated by <a href=\"http://bl.ocks.org/svmatthews/6081504\">Sam Matthews</a>. Now that we know what they're good for, how can we take our own local geographic data, and render our own?</p>\n<!-- more -->\n<p><a href=\"http://tilestache.org\">TileStache</a> is a Tiled Mapping Server written in Python. The core committer on the project\nis <a href=\"http://mike.teczno.com\">Michael Migurski</a>, formerly of <a href=\"http://stamen.com\">Stamen Design</a> and now CTO of\n<a href=\"http://www.codeforamerica.org\">Code for America</a>. He's blogged extensively about his development of\nthe TileStache project to incorporate both use-cases illustrated above\n(<a href=\"http://mike.teczno.com/notes/postgreslessness-mapnik-vectiles.html\">pipeline to raster tiles via mapnik</a>,\n<a href=\"http://mike.teczno.com/notes/vector-tile-rendering-numbers.html\">client-side rendering</a>)</p>\n<p>I've been reviewing the source code for this project for the past few weeks and have been impressed at the accessibility\nof the code to a novice Python developer such as myself. In any event, I'd like to use this post to drop some\nquick notes on how to get things up and running.</p>\n<h2 id=\"prerequisites\" tabindex=\"-1\">Prerequisites <a class=\"header-anchor\" href=\"https://mattmakesmaps.com/blog/2013-10-09-tilestache-rendering-topojson/\">#</a></h2>\n<ul>\n<li>TileStache Installed With Dependencies</li>\n<li>PostGIS Installed</li>\n</ul>\n<h2 id=\"data\" tabindex=\"-1\">Data <a class=\"header-anchor\" href=\"https://mattmakesmaps.com/blog/2013-10-09-tilestache-rendering-topojson/\">#</a></h2>\n<p>The dataset I imported for rendering is known as 'processed_p', which can be downloaded <a href=\"http://openstreetmapdata.com/data/land-polygons\">here</a>. This is the land dataset used in the OpenStreetMap basemap. I picked this dataset because it is highly detailed, large (365 MB), and projected in spherical mercator. This is a perfect example of a dataset in which you would really want to have a server spraying out just those specific slices of data (tiles) a user has requested, from the larger whole.</p>\n<h2 id=\"process\" tabindex=\"-1\">Process <a class=\"header-anchor\" href=\"https://mattmakesmaps.com/blog/2013-10-09-tilestache-rendering-topojson/\">#</a></h2>\n<ol>\n<li>Create a PostGIS Database, 'ts_data'</li>\n</ol>\n<pre class=\"language-bash\" tabindex=\"0\"><code class=\"language-bash\">$ created ts_data\n$ psql <span class=\"token parameter variable\">-d</span> ts_data\nts_data<span class=\"token comment\"># CREATE EXTENSION postgis;</span>\nCREATE EXTENSION\n<span class=\"token assign-left variable\">ts_data</span><span class=\"token operator\">=</span><span class=\"token comment\"># CREATE SCHEMA osm;</span>\nCREATE SCHEMA</code></pre>\n<ol start=\"2\">\n<li>Load processed_p Shapefile into PostGIS</li>\n</ol>\n<p>NOTE: See the excellent shp2pgsql/pgsql2shp cheat sheet by <a href=\"http://www.bostongis.com/pgsql2shp_shp2pgsql_quickguide_20.bqg\">BostonGIS</a></p>\n<pre class=\"language-bash\" tabindex=\"0\"><code class=\"language-bash\"><span class=\"token comment\"># NOTE YMMV, MAY NEED TO ADD ADDITIONAL PSQL CONNECTION PARAMS. SEE '$psql --help'</span>\n$ shp2pgsql <span class=\"token parameter variable\">-I</span> <span class=\"token parameter variable\">-s</span> <span class=\"token number\">900913</span> land_polygons.shp osm.land_polygons_split <span class=\"token operator\">|</span> psql <span class=\"token parameter variable\">-d</span> ts_data </code></pre>\n<ol start=\"3\">\n<li>Create a TileStache Config</li>\n</ol>\n<p>TileStache relies on a user-defined configuration file to define a layer, accessible by a client.\nIn this context, a layer is essentially a combination of a backing dataset (e.g. shapefile, MBTiles,\nPostGIS database, etc.) and instructions on how those data should be rendered (e.g. Vector Tiles, UTF-GRID, Mapnik, etc.)</p>\n<p>An example configuration file can be found <a href=\"https://github.com/mattmakesmaps/TileStache-Experiment/blob/master/config_files/topojson.cfg#L84-L99\">here</a>. I've highlighted the relevant block, which is excerpted\nbelow. This example uses the VecTiles provider (<a href=\"http://tilestache.org/doc/TileStache.Goodies.VecTiles.html\">docs</a>),\nwhich requires a PostGIS backing store, and produces tiles in geojson, topojson, or Mapnik Vector Tile (MVT) format.\nComments have been added below for clarity.</p>\n<pre class=\"language-javascript\" tabindex=\"0\"><code class=\"language-javascript\"><span class=\"token string-property property\">\"osm-processed_p1\"</span><span class=\"token operator\">:</span> <span class=\"token punctuation\">{</span> <span class=\"token comment\">// Layer Name</span>\n    <span class=\"token comment\">// Sets ACCESS-CONTROL-ALLOW-ORIGIN header to \"*\"</span>\n    <span class=\"token string-property property\">\"allowed origin\"</span><span class=\"token operator\">:</span> <span class=\"token string\">\"*\"</span><span class=\"token punctuation\">,</span> \n    <span class=\"token string-property property\">\"provider\"</span><span class=\"token operator\">:</span> <span class=\"token punctuation\">{</span>\n        <span class=\"token string-property property\">\"class\"</span><span class=\"token operator\">:</span> <span class=\"token string\">\"TileStache.Goodies.VecTiles:Provider\"</span><span class=\"token punctuation\">,</span>\n        <span class=\"token comment\">// PostGIS Connection Info</span>\n        <span class=\"token string-property property\">\"kwargs\"</span><span class=\"token operator\">:</span> <span class=\"token punctuation\">{</span> \n            <span class=\"token string-property property\">\"dbinfo\"</span><span class=\"token operator\">:</span> <span class=\"token punctuation\">{</span>\n                <span class=\"token string-property property\">\"host\"</span><span class=\"token operator\">:</span> <span class=\"token string\">\"localhost\"</span><span class=\"token punctuation\">,</span>\n                <span class=\"token string-property property\">\"user\"</span><span class=\"token operator\">:</span> <span class=\"token string\">\"matt\"</span><span class=\"token punctuation\">,</span>\n                <span class=\"token string-property property\">\"database\"</span><span class=\"token operator\">:</span> <span class=\"token string\">\"ts_data\"</span>\n            <span class=\"token punctuation\">}</span><span class=\"token punctuation\">,</span>\n            <span class=\"token comment\">// An array of queries for each zoom level.</span>\n            <span class=\"token comment\">// One query == Used for All Zooms</span>\n            <span class=\"token string-property property\">\"queries\"</span><span class=\"token operator\">:</span> <span class=\"token punctuation\">[</span> \n                <span class=\"token string\">\"SELECT gid, geom AS __geometry__ FROM osm.land_polygons_split\"</span>\n            <span class=\"token punctuation\">]</span>\n        <span class=\"token punctuation\">}</span>\n    <span class=\"token punctuation\">}</span>\n<span class=\"token punctuation\">}</span></code></pre>\n<ol start=\"4\">\n<li>Start the Server.</li>\n</ol>\n<p>TileStache comes pre-canned with it's own simple development server. If installing TileStache from a python package\nmanager, It can be accessed from the command line via <code>$ tilestache-server.py</code>.</p>\n<p>The server should now be accessible via <a href=\"http://127.0.0.1:8080/\">http://127.0.0.1:8080/</a>. &quot;TileStache bellows hello.&quot;</p>\n<ol start=\"5\">\n<li>Request a Tile.</li>\n</ol>\n<p>From the <a href=\"http://tilestache.org/doc/\">API docs</a>: &quot;TileStache URLs are based on a Google Maps-like scheme&quot;:</p>\n<pre><code>/{layer name}/{zoom}/{column}/{row}.{extension}\n</code></pre>\n<p>Utilizing the layer name referenced in the configuration example above, &quot;osm-processed_p1&quot;, a tile request would look like:</p>\n<pre><code>http://127.0.0.1:8080/osm-processed_p1/9/147/196.topojson #TopoJSON\nhttp://127.0.0.1:8080/osm-processed_p1/9/147/196.json #GeoJSON\nhttp://127.0.0.1:8080/osm-processed_p1/9/147/196.mvt # Mapnik Vector Tile\n</code></pre>\n<p>Looking at the HTTP requests above, we can see that we're calling on the same layer, e.g. the same backing datastore,\nbut rendering those same data into three different output formats. Pretty neat.</p>\n<h2 id=\"wrapping-up\" tabindex=\"-1\">Wrapping Up <a class=\"header-anchor\" href=\"https://mattmakesmaps.com/blog/2013-10-09-tilestache-rendering-topojson/\">#</a></h2>\n<p>TileStache vector tiles can be rendered in any number of client side JS libraries that support GeoJSON or TopoJSON.\nPushing the above requested TopoJSON tile to github, we can view the rendered geometries with their attributes.</p>\n<pre><code>gist 6896905 s00_9_147_196.topojson\n</code></pre>\n<p>TileStache provides an easy-to-use point of entry for vector tiles. In a later post I'll go over some of the profiling\nexperiments I've been running, using TileStache's dynamic line simplification, and it's affects on file size as well as\nthe aesthetic affects on representations of these geometries.</p>\n<p>I'll also be writing out the work I did extending TileStache to support calls to the <a href=\"http://labs.giphy.com\">Giphy Labs API</a>: <a href=\"http://mattmakesmaps.github.io/TileStache-GiphyAPI-Demo/\">http://mattmakesmaps.github.io/TileStache-GiphyAPI-Demo/</a></p>\n",
			"date_published": "2013-10-09T00:00:00Z"
		}
		,
		{
			"id": "https://mattmakesmaps.com/blog/2013-08-26-quickstart-gis-setup-on-ubuntu-linux-12-dot-04-lts/",
			"url": "https://mattmakesmaps.com/blog/2013-08-26-quickstart-gis-setup-on-ubuntu-linux-12-dot-04-lts/",
			"title": "Quickstart GIS Setup on Ubuntu Linux 12.04 LTS",
			"content_html": "<p>I had to recently setup a clean Ubuntu 12.04 LTS workstation for GIS\ndata processing. For the simplicity and speed, I decided to go with\npackaged versions of many of the required GIS software. Many of the\npackages are derived from the <a href=\"https://launchpad.net/~ubuntugis/+archive/ubuntugis-unstable\">ubuntugis-unstable</a> repository.</p>\n<p>What follows below are a blow-by-blow of my installation notes\ngrouped by software package. Either code snippets or links to relevant\nblog posts.<!-- More --></p>\n<p>This is certainly only a high-level guide. If anyone has any other\nsuggestions or alternatives, please feel free to list them.</p>\n<p><strong>NOTE:</strong> The order of these installs reflects the actual order in\nwhich I installed them.</p>\n<h2 id=\"non-gis-essentials\" tabindex=\"-1\">Non-GIS Essentials <a class=\"header-anchor\" href=\"https://mattmakesmaps.com/blog/2013-08-26-quickstart-gis-setup-on-ubuntu-linux-12-dot-04-lts/\">#</a></h2>\n<h3 id=\"install-ssh\" tabindex=\"-1\">Install SSH <a class=\"header-anchor\" href=\"https://mattmakesmaps.com/blog/2013-08-26-quickstart-gis-setup-on-ubuntu-linux-12-dot-04-lts/\">#</a></h3>\n<p><a href=\"http://en.wikipedia.org/wiki/Secure_Shell\">SSH</a> or Secure Shell,\nis essential for remote server administration.</p>\n<p><code>$ sudo apt-get install openssh-server</code></p>\n<h3 id=\"increase-history-size\" tabindex=\"-1\">Increase History Size <a class=\"header-anchor\" href=\"https://mattmakesmaps.com/blog/2013-08-26-quickstart-gis-setup-on-ubuntu-linux-12-dot-04-lts/\">#</a></h3>\n<p>The default history size is pretty low. Increasing the size allows us\nto do search for that oft-used terminal command right when you need it\nmost. What was the name of that server I ssh'd into last month?\nPiping history to grep can do the trick. <code>$ history | grep -i &quot;ssh&quot;</code></p>\n<pre class=\"language-bash\" tabindex=\"0\"><code class=\"language-bash\">$ <span class=\"token function\">vim</span> ~/.bashrc\n<span class=\"token assign-left variable\"><span class=\"token environment constant\">HISTSIZE</span></span><span class=\"token operator\">=</span><span class=\"token number\">10000</span>\n<span class=\"token assign-left variable\"><span class=\"token environment constant\">HISTFILESIZE</span></span><span class=\"token operator\">=</span><span class=\"token number\">20000</span></code></pre>\n<h3 id=\"python-virtual-environments\" tabindex=\"-1\">Python Virtual Environments <a class=\"header-anchor\" href=\"https://mattmakesmaps.com/blog/2013-08-26-quickstart-gis-setup-on-ubuntu-linux-12-dot-04-lts/\">#</a></h3>\n<p>Used this <a href=\"https://gist.github.com/panuta/3075882\">awesome gist</a> by\ngithub user <a href=\"https://github.com/panuta\">panuta</a>.</p>\n<p>Didn't follow, but a good reference: <a href=\"http://askubuntu.com/questions/244641/how-to-set-up-and-use-a-virtual-python-environment-in-ubuntu\">http://askubuntu.com/questions/244641/how-to-set-up-and-use-a-virtual-python-environment-in-ubuntu</a></p>\n<h3 id=\"apache\" tabindex=\"-1\">Apache <a class=\"header-anchor\" href=\"https://mattmakesmaps.com/blog/2013-08-26-quickstart-gis-setup-on-ubuntu-linux-12-dot-04-lts/\">#</a></h3>\n<pre><code>$ sudo apt-get install apache2\n</code></pre>\n<h2 id=\"gis-packages\" tabindex=\"-1\">GIS Packages <a class=\"header-anchor\" href=\"https://mattmakesmaps.com/blog/2013-08-26-quickstart-gis-setup-on-ubuntu-linux-12-dot-04-lts/\">#</a></h2>\n<h3 id=\"connect-to-the-ubuntugis-unstable-ppa\" tabindex=\"-1\">Connect to the UbuntuGIS-Unstable PPA <a class=\"header-anchor\" href=\"https://mattmakesmaps.com/blog/2013-08-26-quickstart-gis-setup-on-ubuntu-linux-12-dot-04-lts/\">#</a></h3>\n<p>In order to access many of these packages, we need to connect the\nsystem to the UbuntuGIS-Unstable PPA.</p>\n<pre><code>$ sudo add-apt-repository ppa:ubuntugis/ubuntugis-unstable\n$ sudo apt-get update\n</code></pre>\n<h3 id=\"gdal-fiona\" tabindex=\"-1\">GDAL/Fiona <a class=\"header-anchor\" href=\"https://mattmakesmaps.com/blog/2013-08-26-quickstart-gis-setup-on-ubuntu-linux-12-dot-04-lts/\">#</a></h3>\n<p>GDAL/OGR are the defacto Open Source GIS swiss army knife.\n<a href=\"https://github.com/sgillies/Fiona\">Fiona</a> provides easy-to-use\nPython bindings for use in your projects.</p>\n<pre><code>$ sudo apt-get install libgdal-dev gdal-bin\n$ workon gis-base\n$ sudo apt-get install python2.7-dev\n$ pip install Fiona\n</code></pre>\n<h3 id=\"postgres-postgis\" tabindex=\"-1\">Postgres/PostGIS <a class=\"header-anchor\" href=\"https://mattmakesmaps.com/blog/2013-08-26-quickstart-gis-setup-on-ubuntu-linux-12-dot-04-lts/\">#</a></h3>\n<p>The ubuntu unstable repository provides pre-packaged binaries combining both Postgres and Postgis.</p>\n<p>As of August 2013, GDAL version 1.10 for some reason doesn't include libgdal1, replaced by libgdalh. See: <a href=\"http://lists.osgeo.org/pipermail/ubuntu/2013-July/000757.html\">http://lists.osgeo.org/pipermail/ubuntu/2013-July/000757.html</a>\nThis appearently is causing some issues with packages installations, including Postgres/PostGIS. The steps below appear to work.</p>\n<pre><code>$ sudo apt-get install libgdal1-dev\n$ sudo apt-get install postgresql-9.1-postgis-2.0\n</code></pre>\n<p>If you need any of the postgis util scripts, e.g. <code>postgres_restore.pl</code> used for restoring a postgres database (across differing versions\nof postgis), I believe the only way to get these is by making from source.</p>\n<pre><code>$ sudo apt-get install proj\n$ wget http://download.osgeo.org/postgis/source/postgis-2.0.3.tar.g\n$ tar -zxvf postgis-2.0.3.tar.gz\n$ cd postgis-2.0.3/\n$ ./configure\n$ make\n</code></pre>\n<p>Finally, if you need to change your Postgresql data dir to another\ndisk, this guide provides good advice: <a href=\"http://www.whiteboardcoder.com/2012/04/change-postgres-datadirectory-folder.html\">http://www.whiteboardcoder.com/2012/04/change-postgres-datadirectory-folder.html</a></p>\n<h3 id=\"imposm-2-5-0\" tabindex=\"-1\">Imposm 2.5.0 <a class=\"header-anchor\" href=\"https://mattmakesmaps.com/blog/2013-08-26-quickstart-gis-setup-on-ubuntu-linux-12-dot-04-lts/\">#</a></h3>\n<p>If you're rendering OSM data, imposm is one of the fastest ways\nto get data from an OSM Planet Extract into PostGIS.</p>\n<p>I followed the instructions within the <a href=\"http://imposm.org/docs/imposm/latest/install.html#requirements\">Imposm documentation</a></p>\n<p>Note: Installed imposm directly into my virtualenv &quot;gis-base&quot;</p>\n<h3 id=\"quantum-gis\" tabindex=\"-1\">Quantum GIS <a class=\"header-anchor\" href=\"https://mattmakesmaps.com/blog/2013-08-26-quickstart-gis-setup-on-ubuntu-linux-12-dot-04-lts/\">#</a></h3>\n<pre class=\"language-bash\" tabindex=\"0\"><code class=\"language-bash\">$ <span class=\"token function\">sudo</span> <span class=\"token function\">apt-get</span> <span class=\"token function\">install</span> qgis</code></pre>\n",
			"date_published": "2013-08-26T00:00:00Z"
		}
		,
		{
			"id": "https://mattmakesmaps.com/blog/2013-07-17-mapbox-plus-github-equals-free-and-fast-web-maps/",
			"url": "https://mattmakesmaps.com/blog/2013-07-17-mapbox-plus-github-equals-free-and-fast-web-maps/",
			"title": "MapBox + Github = Free and Fast Web Maps",
			"content_html": "<p>With the announcement of Github's awesome support for <a href=\"http://www.mapbox.com/blog/github-mapbox-maps/\">direct geojson renderingg</a>,\nfolks can deploy an embeddable web map with a single git commit and push. This got me\nthinking about the potential of github, specifically <a href=\"http://pages.github.com/\">github pages</a>,\nas a vehicle for the display of more customized web mapping applications. The result of that\nexperiment is <a href=\"http://aknativenamesatlas.com\">aknativenamesatlas.com</a>. <!-- more --></p>\n<p>I deployed the initial draft of this site in a few hours, thanks entirely not only to\nthe power of MapBox and Github's hosting infrastructure, but also to the easy-to-use\n<a href=\"http://www.mapbox.com/map-sites/\">mapping templates</a> provided by MapBox.</p>\n<p>This blog series will attempt to illustrate some of the major steps involved in the\nprocess of deploying this map. The general process however, is as follows.</p>\n<ol>\n<li>Style cartographic layers via TileMill, upload to MapBox.</li>\n<li>Create composite map of individual operation layers plus a base within MapBox.</li>\n<li>Fork MapBox's dc-properties-template via github.</li>\n<li>Edit forked repository to point to my layers of interest.</li>\n<li>Add CNAME record for custom URL to forked repository.</li>\n<li>Configure DNS to route custom domain name to github pages.</li>\n</ol>\n<p>This first post will cover the cartography, and more importantly, the on-the-fly compositing of\nlayers.</p>\n<h1 id=\"cartography-and-compositing\" tabindex=\"-1\">Cartography &amp; Compositing <a class=\"header-anchor\" href=\"https://mattmakesmaps.com/blog/2013-07-17-mapbox-plus-github-equals-free-and-fast-web-maps/\">#</a></h1>\n<p>The primary tool used to create the cartographic look and feel of the individual data layers is\n<a href=\"http://www.mapbox.com/tilemill/\">TileMill</a>. TileMill is a desktop cartographic design studio, allowing you to\nload your own datasets from a variety of spatial formats (SHP, SpatialLite, PostGIS), and style via a CSS-like\nlanguage, <a href=\"http://www.mapbox.com/tilemill/docs/manual/carto/\">CartoCSS</a>.</p>\n<p>I'll gloss over the details for styling maps in in TileMill, but they've got a great\n<a href=\"http://www.mapbox.com/tilemill/docs/crashcourse/introduction/\">quick-start guide</a>.</p>\n<p>For my site, I ended up creating two projects in TileMill, one for each operational layer present in the final\nmap. The first layer represents <a href=\"http://a.tiles.mapbox.com/v3/mattmakesmaps.language_points/page.html\">place names</a>\n, symbolized as points. The second layer depicts <a href=\"http://a.tiles.mapbox.com/v3/mattmakesmaps.language_lines/page.html\">language regions</a>\n, symbolized as lines, but the geometry are in actuality polygons (required for the display of attribute information via a hover event).</p>\n<p>Splitting these operational layers into separate projects in TileMill, and conversely separate web maps when uploaded to MapBox, allows\nus to mix and match these layers at will. Specifically, the <a href=\"http://www.mapbox.com/developers/api/#Map.resources\">MapBox REST API</a>\nallows us to composite or layer individual maps into a single-tile, on-the-fly. If you're head hasn't been exploded, allow me to illustrate.</p>\n<p>The map on <a href=\"http://aknativenamesatlas.com\">aknativenamesatlas.com</a> is a composite of multiple layers. A basemap, provided by mapbox, as well as two operational layers (a point layer and a line layer).</p>\n<p>A <a href=\"http://a.tiles.mapbox.com/v3/mattmakesmaps.map-9ipoh344/6/5/16.png\">single tile</a> from this map looks like this:</p>\n<p><code>Archived Post. Original Image Unavailable.</code></p>\n<p>The URL is as follows: <a href=\"http://a.tiles.mapbox.com/v3/mattmakesmaps.map-9ipoh344/6/5/16.png\">http://a.tiles.mapbox.com/v3/mattmakesmaps.map-9ipoh344/6/5/16.png</a>. Note the <code>mattmakesmaps.map-9ipoh3441</code> section of the URL. This is a combination of my user account, <code>mattmakesmaps</code> and the unique map id. This identifier indicates that I'm requesting the tile representing this specific map, again, a composite of multiple layers.</p>\n<p>We can however, query individual layers that make up this map. For example, the lines layer specifically has a URL endpoint of <a href=\"http://a.tiles.mapbox.com/v3/mattmakesmaps.language_lines/6/5/16.png\">http://a.tiles.mapbox.com/v3/mattmakesmaps.language_lines/6/5/16.png</a>. It looks like this.</p>\n<p><code>Archived Post. Original Image Unavailable.</code></p>\n<p>Similarly, with the points layer: <a href=\"http://a.tiles.mapbox.com/v3/mattmakesmaps.language_points/6/5/16.png\">http://a.tiles.mapbox.com/v3/mattmakesmaps.language_points/6/5/16.png</a>. NOTE: You'll have to squint to see the points. They don't show up very well with the black on dark blue background. OR, you can open the tile link above in a new tab.</p>\n<p><code>Archived Post. Original Image Unavailable.</code></p>\n<p>The real magic comes when we composite these individual layers together, on-the-fly. From the <a href=\"http://www.mapbox.com/developers/api/#Map.resources\">docs</a></p>\n<blockquote>\n<p>By joining multiple ids with commas into a single :map parameter you can access the MapBox Hosting compositing API to layer multiple tile images, UTFgrids or aggregate the TileJSON of multiple maps into a single map.</p>\n</blockquote>\n<p>That looks something like this <a href=\"http://a.tiles.mapbox.com/v3/mattmakesmaps.language_lines,mattmakesmaps.language_points/6/5/16.png\">http://a.tiles.mapbox.com/v3/mattmakesmaps.language_lines,mattmakesmaps.language_points/6/5/16.png</a>:</p>\n<p><code>Archived Post. Original Image Unavailable.</code></p>\n<p>Pretty cool. You can even flip the z-index in which the layers are composited by simply re-arranging their position in the URL.</p>\n<p>That's it for now. The next post will cover how to fork Mapbox's DC-Properties template, allowing us to visualize our maps, accessible via github pages.</p>\n",
			"date_published": "2013-07-17T00:00:00Z"
		}
		,
		{
			"id": "https://mattmakesmaps.com/blog/2013-07-10-fixing-arcgis-10-dot-1-python-console-numpy-import-error/",
			"url": "https://mattmakesmaps.com/blog/2013-07-10-fixing-arcgis-10-dot-1-python-console-numpy-import-error/",
			"title": "Fixing ArcGIS 10.1 Numpy Import Error From Python Console",
			"content_html": "<p>At my current employer, we have four Windows 7 64-bit workstations, all running ArcGIS 10.1 under\nvarious license levels. Hilariously, due to some quirk that I haven't been able to figure out,\nall machines have been reporting the following traceback when running <code>&gt;&gt;&gt; import numpy</code> from\nArcGIS Desktop's internal Python console.</p>\n<!-- more -->\n<pre><code>&gt;&gt;&gt; import numpy\nRuntime error \nTraceback (most recent call last):\n  File &quot;&lt;string&gt;&quot;, line 1, in &lt;module&gt;\n  File &quot;c:\\program files (x86)\\arcgis\\desktop10.1\\arcpy\\arcpy\\__init__.py&quot;, line 24, in &lt;module&gt;\n    from arcpy.toolbox import *\n  File &quot;c:\\program files (x86)\\arcgis\\desktop10.1\\arcpy\\arcpy\\toolbox.py&quot;, line 342, in &lt;module&gt;\n    from management import Graph, GraphTemplate\n  File &quot;c:\\program files (x86)\\arcgis\\desktop10.1\\arcpy\\arcpy\\management.py&quot;, line 22, in &lt;module&gt;\n    import _management\n  File &quot;c:\\program files (x86)\\arcgis\\desktop10.1\\arcpy\\arcpy\\_management.py&quot;, line 14, in &lt;module&gt;\n    import _graph\n  File &quot;c:\\program files (x86)\\arcgis\\desktop10.1\\arcpy\\arcpy\\_graph.py&quot;, line 27, in &lt;module&gt;\n    import numpy\nImportError: No module named numpy\n</code></pre>\n<p>One solution to this is to explicitly append the <code>PYTHONPATH</code> environment variable to reference the ArcGIS10.1 Python install's <code>site-packages</code> directory.</p>\n<h1 id=\"creation-of-pythonpath-environment-variable\" tabindex=\"-1\">Creation of PYTHONPATH Environment Variable <a class=\"header-anchor\" href=\"https://mattmakesmaps.com/blog/2013-07-10-fixing-arcgis-10-dot-1-python-console-numpy-import-error/\">#</a></h1>\n<ol>\n<li>\n<p>From the start menu, right click the <code>computer</code> button and select <code>properties</code>.</p>\n</li>\n<li>\n<p>Click <code>Advanced System Settings</code>.</p>\n</li>\n<li>\n<p>Click the <code>Advanced</code> tab, and select the <code>Environment Variables</code> button.</p>\n</li>\n<li>\n<p>Click <code>New</code> to create a new environment variable.</p>\n</li>\n<li>\n<p>Name the environment variable <code>PYTHONPATH</code> and set it's value to point to the <code>site-packages</code> directory for ArcGIS. For my instance, this is <code>C:\\Python27\\ArcGIS10.1\\Lib\\site-packages</code>.</p>\n</li>\n<li>\n<p>Restart the machine. You should now be able to successfully import numpy, arcpy, and any other Python modules installed as part of the ArcGIS 10.x version of Python.</p>\n</li>\n</ol>\n",
			"date_published": "2013-07-10T00:00:00Z"
		}
		,
		{
			"id": "https://mattmakesmaps.com/blog/2013-06-16-auto-push-to-github-via-machine-user/",
			"url": "https://mattmakesmaps.com/blog/2013-06-16-auto-push-to-github-via-machine-user/",
			"title": "Auto-Push to GitHub via Machine User",
			"content_html": "<p>This post will review a workflow for automatically pushing data from a client machine to github.\nThis can be useful if you want to automatically make publicly available data that are regularly processed on\na local machine. <!-- more --> For my particular use case, I'm downloading data from the <a href=\"http://waterservices.usgs.gov/rest/IV-Test-Tool.html\">USGS Instantaneus Values\nWeb Service</a> , and would\nlike to process those data locally for use in a d3 visualization. My d3 viz will eventually be\nhosted on github as well, so having a dynamically updated dataset stored on github made sense.\nI'm sure that it's possible to emulate this ETL workflow in pure JavaScript, but I wanted to see\nhow to set this up, in the event that I found myself in a situation in which heavy pre-processing\nof data was required.</p>\n<p>The general steps are as follows:</p>\n<ol>\n<li>On the local machine, create a machine user and group.</li>\n<li>Create a corresponding github account for the machine user.</li>\n<li>Generate an SSH key machine user &amp; associate the public key of the machine user to its github account.</li>\n<li>Assign the github account to the repository of interest.</li>\n<li>Clone the repository of interest, making it group writable.</li>\n<li>On the local machine, create a cron job under the machine user to execute the processing script.</li>\n</ol>\n<h2 id=\"create-machine-user-and-group\" tabindex=\"-1\">Create Machine User and Group <a class=\"header-anchor\" href=\"https://mattmakesmaps.com/blog/2013-06-16-auto-push-to-github-via-machine-user/\">#</a></h2>\n<p>On my local machine, I start by creating a user and group for the purpose of pushing data to github.\nI'm doing this to isolate the amount of exposure that this user has to my wider system.</p>\n<pre class=\"language-bash\" tabindex=\"0\"><code class=\"language-bash\"><span class=\"token comment\"># Create the user, rdi-git</span>\n$ <span class=\"token function\">sudo</span> adduser rdi-git\n<span class=\"token comment\"># You'll be prompted to enter a password as well.</span>\n<span class=\"token comment\"># Create the group, git</span>\n$ <span class=\"token function\">sudo</span> addgroup <span class=\"token function\">git</span>\n<span class=\"token comment\"># Add our new user (rdi-git) to the new group (git)</span>\n$ <span class=\"token function\">sudo</span> <span class=\"token function\">usermod</span> <span class=\"token parameter variable\">-a</span> <span class=\"token parameter variable\">-G</span> <span class=\"token function\">git</span> rdi-git</code></pre>\n<h2 id=\"create-a-github-account-for-machine-user\" tabindex=\"-1\">Create a Github Account for Machine User <a class=\"header-anchor\" href=\"https://mattmakesmaps.com/blog/2013-06-16-auto-push-to-github-via-machine-user/\">#</a></h2>\n<p>After having created the machine users on my local box, the next step is to create an analogous\nuser on <a href=\"https://github.com\">github</a>.</p>\n<h2 id=\"generate-ssh-key-and-assign-to-github-user\" tabindex=\"-1\">Generate SSH Key &amp; Assign to Github User <a class=\"header-anchor\" href=\"https://mattmakesmaps.com/blog/2013-06-16-auto-push-to-github-via-machine-user/\">#</a></h2>\n<p>From the local machine, make sure that you're logged in as the newly created machine user.</p>\n<pre class=\"language-bash\" tabindex=\"0\"><code class=\"language-bash\">$ <span class=\"token function\">sudo</span> <span class=\"token function\">su</span> rdi-git</code></pre>\n<p>At this point, I defer to the great instructions on the Github help docs for <a href=\"https://help.github.com/articles/generating-ssh-keys\">generating an ssh key</a>.</p>\n<h2 id=\"assign-github-account-as-collaborator-to-repo-of-interest\" tabindex=\"-1\">Assign Github Account As Collaborator to Repo of Interest <a class=\"header-anchor\" href=\"https://mattmakesmaps.com/blog/2013-06-16-auto-push-to-github-via-machine-user/\">#</a></h2>\n<p>Next, I add our github user, rdi-git, as a collaborator on my repository of interest. Here is a link on\nthe <a href=\"https://help.github.com/articles/how-do-i-add-a-collaborator\">Github help docs</a>.</p>\n<h2 id=\"clone-the-repository-of-interest-add-assign-permissions\" tabindex=\"-1\">Clone the Repository of Interest, add Assign Permissions <a class=\"header-anchor\" href=\"https://mattmakesmaps.com/blog/2013-06-16-auto-push-to-github-via-machine-user/\">#</a></h2>\n<p>I'm creating a <code>/projects/</code> folder, in which I'll clone my repo. I'd like to ensure that this folder, and\nsubsequently all repos contained within it, are associated with git group. This <a href=\"http://unix.stackexchange.com/questions/12842/make-all-new-files-in-a-directory-accessible-to-a-group\">stackoverflow</a> outlines the required commands.</p>\n<pre class=\"language-bash\" tabindex=\"0\"><code class=\"language-bash\"><span class=\"token comment\"># Make the directory</span>\n$ <span class=\"token builtin class-name\">cd</span> /\n$ <span class=\"token function\">mkdir</span> projects\n$ <span class=\"token builtin class-name\">cd</span> /projects\n<span class=\"token comment\"># Change perms to group writable. See Above SO post.</span>\n$ <span class=\"token builtin class-name\">umask</span> 002            <span class=\"token comment\"># allow group write; everyone must do this</span>\n$ <span class=\"token function\">chgrp</span> <span class=\"token function\">git</span> <span class=\"token builtin class-name\">.</span>          <span class=\"token comment\"># set directory group to gitG</span>\n$ <span class=\"token function\">chmod</span> g+s <span class=\"token builtin class-name\">.</span>          <span class=\"token comment\"># files created in directory will be in group git</span>\n<span class=\"token comment\"># Clone our repo of interest, using ssh</span>\n$ git@github.com:mattmakesmaps/robo-d3.git </code></pre>\n<h2 id=\"create-the-cron-job\" tabindex=\"-1\">Create the Cron Job <a class=\"header-anchor\" href=\"https://mattmakesmaps.com/blog/2013-06-16-auto-push-to-github-via-machine-user/\">#</a></h2>\n<p>The repo I've just cloned contains the <a href=\"https://github.com/mattmakesmaps/robo-d3/blob/master/scripts/waterservices_parser.py\">processing script</a> I'll be running.\nOur processed data will also be stored and pushed back to this repository.</p>\n<p>I'd like to have my processing script run once every hour, on the hour. We setup the cron job by first entering\ncrontab.</p>\n<pre class=\"language-bash\" tabindex=\"0\"><code class=\"language-bash\"><span class=\"token comment\"># Login as machine user, cron job will be run under this id.</span>\n$ <span class=\"token function\">sudo</span> <span class=\"token function\">su</span> rdi-git\n$ <span class=\"token function\">crontab</span> <span class=\"token parameter variable\">-e</span></code></pre>\n<p>Here is an excerpt of the machine user's cron jobs, with the new job added at the bottom.</p>\n<pre class=\"language-bash\" tabindex=\"0\"><code class=\"language-bash\"><span class=\"token comment\"># For more information see the manual pages of crontab(5) and cron(8)</span>\n<span class=\"token comment\">#</span>\n<span class=\"token comment\"># m h  dom mon dow   command</span>\n<span class=\"token number\">0</span> * * * * python /projects/robo-d3/scripts/waterservices_parser.py <span class=\"token operator\">></span> ~/robo-d3.log <span class=\"token operator\"><span class=\"token file-descriptor important\">2</span>></span><span class=\"token file-descriptor important\">&amp;1</span></code></pre>\n<p>We essential say, on the minute zero, of every hour, for every day, month, and weekday, run the command 'python /path/to/script'. The tail indicates that we're outputting both STDOUT and the ERROR log to <code>/home/rdi-git/robo-d3.log</code></p>\n<p>And there we go. If we check out the <a href=\"https://github.com/mattmakesmaps/robo-d3/commits/master\">commit logs</a> we can\nsee that our github user, rdi-git, has been pushing every hour on the hour. Woo-hoo!</p>\n",
			"date_published": "2013-06-16T00:00:00Z"
		}
		,
		{
			"id": "https://mattmakesmaps.com/blog/2013-05-01-django-add-mapquest-tiles/",
			"url": "https://mattmakesmaps.com/blog/2013-05-01-django-add-mapquest-tiles/",
			"title": "Hack GeoDjango Admin with Mapquest Tiles",
			"content_html": "<p>The <a href=\"http://geodjango.org/\">GeoDjango model</a> admin provides a great <a href=\"http://openlayers.org/\">OpenLayers</a> interface, allowing a user to create geographic features (points, lines, polygons) directly via a web map. Out-of-the-box,\nGeoDjango ships with a base GeoAdmin class, using the default OL world borders layer,\nas well as a subclass for OSM streets data. The OSM layer is great, and provides a good base\nfor most use cases. That being said, for <a href=\"https://github.com/mattmakesmaps/PntTrax\">PntTrax</a>, I needed aerial tiles. <!-- more -->My application deals\nprimarily with the storage of field collected (GPS, field notes, aerial markup, etc.) data.\nOur data occur primarily in non-urban areas, where natural features provide a much\nbetter context for orientation then would be expected with any streets layer, OSM or otherwise.\nMapquest provides a good set of aerial tiles, that can be easily integrated into OpenLayers.</p>\n<p>It's easier to place a point on this:</p>\n<p><code>Archived Post. Original Image Unavailable.</code></p>\n<p>Then this:</p>\n<p><code>Archived Post. Original Image Unavailable.</code></p>\n<p>Hacking the admin to display the <a href=\"http://developer.mapquest.com/web/products/open/map\">Mapquest aerial tiles</a> is a pretty straightforward process.\nFrom the gis contrib package, we'll modify <a href=\"https://github.com/django/django/blob/master/django/contrib/gis/admin/options.py\">options.py</a> and its <a href=\"https://github.com/django/django/blob/master/django/contrib/gis/admin/__init__.py\">__init__.py</a>, subclassing the OSMGeoAdmin. Within the <a href=\"https://github.com/django/django/tree/master/django/contrib/gis/templates/gis/admin\">templates\nfolder</a>,\nwe'll create two new files, a html template file, that actually points to a javascript file\ncontaining a reference to the Mapquest Open Aerial tiles service.</p>\n<h2 id=\"creating-mapquestgeoadminsubclass\" tabindex=\"-1\">Creating mapquestGeoAdminSubclass <a class=\"header-anchor\" href=\"https://mattmakesmaps.com/blog/2013-05-01-django-add-mapquest-tiles/\">#</a></h2>\n<p>The <a href=\"https://github.com/django/django/blob/master/django/contrib/gis/admin/options.py#L132-L139\">OSMGeoAdmin class</a> is a subclass of the base GeoModelAdmin. The GeoModelAdmin contains a set of\nconfiguration parameters for the map, covering basic setup. The OSMGeoAdmin class utilizes\nmany of those configuration parameters, but configures the map for a spherical mercator projection.\nSince our Mapquest Aerial Tiles also require a spherical mercator projection, our class will\nbe a subclass of the OSMGeoAdmin.</p>\n<p>We add the following code below the OSMGeoAdmin class definition.</p>\n<pre class=\"language-python\" tabindex=\"0\"><code class=\"language-python\">    <span class=\"token comment\"># Subclass OSMGeoAdmin, pointing to the To-Be-Created</span>\n    <span class=\"token comment\"># Mapquest template file.`</span>\n    <span class=\"token keyword\">class</span> <span class=\"token class-name\">mapquestGeoAdmin</span><span class=\"token punctuation\">(</span>OSMGeoAdmin<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        map_template <span class=\"token operator\">=</span> <span class=\"token string\">'gis/admin/mapquest.html'</span></code></pre>\n<h2 id=\"modify-the-gis-admin-package-s-init-py\" tabindex=\"-1\">Modify the GIS Admin Package's __init__.py <a class=\"header-anchor\" href=\"https://mattmakesmaps.com/blog/2013-05-01-django-add-mapquest-tiles/\">#</a></h2>\n<p>The <code>__init__.py</code> file imports the <code>OSMGeoAdmin</code> class, let's modify it to include our\nnew subclass</p>\n<pre class=\"language-python\" tabindex=\"0\"><code class=\"language-python\">    <span class=\"token comment\"># From this</span>\n    <span class=\"token keyword\">from</span> django<span class=\"token punctuation\">.</span>contrib<span class=\"token punctuation\">.</span>gis<span class=\"token punctuation\">.</span>admin<span class=\"token punctuation\">.</span>options <span class=\"token keyword\">import</span> OSMGeoAdmin\n    <span class=\"token comment\"># To this</span>\n    <span class=\"token keyword\">from</span> django<span class=\"token punctuation\">.</span>contrib<span class=\"token punctuation\">.</span>gis<span class=\"token punctuation\">.</span>admin<span class=\"token punctuation\">.</span>options <span class=\"token keyword\">import</span> OSMGeoAdmin<span class=\"token punctuation\">,</span> mapquestGeoAdmin</code></pre>\n<h2 id=\"create-mapquest-js\" tabindex=\"-1\">Create mapquest.js <a class=\"header-anchor\" href=\"https://mattmakesmaps.com/blog/2013-05-01-django-add-mapquest-tiles/\">#</a></h2>\n<p>Again, using the OpenStreetMap implementation as a reference, we can see that <code>osm.js</code> extends the basic <code>openlayers.js</code> file, but replaces the contents of the <code>base layer</code>\nblock with an a reference to the OpenStreetMap layer.</p>\n<p>We'll create a similar file in this package called <code>mapquest.js</code>. The contents are as\nfollows:</p>\n<pre><code>{# Source: http://openlayers.org/dev/examples/mapquest.html #}\n{% extends &quot;gis/admin/openlayers.js&quot; %}\n{% block base_layer %}\n        new OpenLayers.Layer.XYZ(\n            &quot;Imagery&quot;,\n            [\n                &quot;http://otile1.mqcdn.com/tiles/1.0.0/sat/${z}/${x}/${y}.png&quot;,\n                &quot;http://otile2.mqcdn.com/tiles/1.0.0/sat/${z}/${x}/${y}.png&quot;,\n                &quot;http://otile3.mqcdn.com/tiles/1.0.0/sat/${z}/${x}/${y}.png&quot;,\n                &quot;http://otile4.mqcdn.com/tiles/1.0.0/sat/${z}/${x}/${y}.png&quot;\n            ],\n            {\n                attribution: &quot;Tiles Courtesy of &lt;a href='http://open.mapquest.co.uk/' target='_blank'&gt;MapQuest&lt;/a&gt;. Portions Courtesy NASA/JPL-Caltech and U.S. Depart. of Agriculture, Farm Service Agency. &lt;img src='http://developer.mapquest.com/content/osm/mq_logo.png' border='0'&gt;&quot;,\n                transitionEffect: &quot;resize&quot;\n            }\n        )\n{% endblock %}\n</code></pre>\n<h2 id=\"create-mapquest-html\" tabindex=\"-1\">Create mapquest.html <a class=\"header-anchor\" href=\"https://mattmakesmaps.com/blog/2013-05-01-django-add-mapquest-tiles/\">#</a></h2>\n<p>In the same folder, we'll create an html template file, pointing to our javascript file.\nWe'll call the file <code>mapquest.html</code>. Here are the contents:</p>\n<pre><code>{% extends &quot;gis/admin/openlayers.html&quot; %}\n{% block openlayers %}{% include &quot;gis/admin/mapquest.js&quot; %}{% endblock %}\n</code></pre>\n<h2 id=\"in-admin-py-reference-mapquestgeoadmin\" tabindex=\"-1\">In admin.py, Reference mapquestGeoAdmin <a class=\"header-anchor\" href=\"https://mattmakesmaps.com/blog/2013-05-01-django-add-mapquest-tiles/\">#</a></h2>\n<p>The last step is to replace references to <code>GeoModelAdmin</code> or <code>OSMGeoAdmin</code> to\n<code>mapquestGeoAdmin</code>.</p>\n<pre class=\"language-python\" tabindex=\"0\"><code class=\"language-python\"><span class=\"token keyword\">class</span> <span class=\"token class-name\">PntTraxGeoAdmin</span><span class=\"token punctuation\">(</span>admin<span class=\"token punctuation\">.</span>mapquestGeoAdmin<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token triple-quoted-string string\">\"\"\"Base Class for Geometry Table Admin\"\"\"</span>\n    list_display <span class=\"token operator\">=</span> <span class=\"token punctuation\">(</span><span class=\"token string\">'name'</span><span class=\"token punctuation\">,</span><span class=\"token string\">'collectDate'</span><span class=\"token punctuation\">,</span><span class=\"token string\">'group'</span><span class=\"token punctuation\">,</span><span class=\"token string\">'featurePurpose'</span><span class=\"token punctuation\">,</span><span class=\"token string\">'collectionMethod'</span><span class=\"token punctuation\">)</span>\n    list_editable <span class=\"token operator\">=</span> <span class=\"token punctuation\">(</span><span class=\"token string\">'featurePurpose'</span><span class=\"token punctuation\">,</span><span class=\"token string\">'group'</span><span class=\"token punctuation\">,</span><span class=\"token string\">'collectionMethod'</span><span class=\"token punctuation\">)</span>\n    list_filter <span class=\"token operator\">=</span> <span class=\"token punctuation\">(</span><span class=\"token string\">'featurePurpose'</span><span class=\"token punctuation\">,</span><span class=\"token string\">'group__name'</span><span class=\"token punctuation\">)</span></code></pre>\n<p>And there you go. Your Django GeoAdmin interface is now rocking aerial tiles courtesy\nof Mapquest.</p>\n",
			"date_published": "2013-05-01T00:00:00Z"
		}
		,
		{
			"id": "https://mattmakesmaps.com/blog/2011-12-12-geodjango-standing-up-a-geojson-web-service/",
			"url": "https://mattmakesmaps.com/blog/2011-12-12-geodjango-standing-up-a-geojson-web-service/",
			"title": "GeoDjango: Standing Up A GeoJSON Web-Service",
			"content_html": "<p>The models are complete. The database is loaded with some test tabular and spatial data. We're pushing out HTML representations of attribute data using GeoDjango's standard templating functions. Now, the focus moves to visualizing these features' geometries in a spatial context. Just as with a Django QuerySet, GeoDjango provides a GeoQuerySet. <!-- more --> When paired with a spatially-enabled database (e.g. PostGIS, SpatialLite, etc.), the GeoQuerySet provides functionality for querying data using a series of spatial filters, in addition to tabular filters. As a point of reference, the GeoDjango docs have great tables depicting a blow-by-blow comparison of different spatial databases, displaying each available <a href=\"https://docs.djangoproject.com/en/dev/ref/contrib/gis/db-api/#spatial-lookup-compatibility\">Spatial Lookup</a> and <a href=\"https://docs.djangoproject.com/en/dev/ref/contrib/gis/db-api/#geoqueryset-methods\">GeoQuerySet method</a>. Take note, PostGIS is the clear winner in terms of functionality ;)</p>\n<h2 id=\"why-geojson\" tabindex=\"-1\">Why GeoJSON? <a class=\"header-anchor\" href=\"https://mattmakesmaps.com/blog/2011-12-12-geodjango-standing-up-a-geojson-web-service/\">#</a></h2>\n<p>From the perspective of exporting data, GeoDjango supports a number of formats. The GeoQuerySet methods can represent your model's geometry column in a number of different <a href=\"https://docs.djangoproject.com/en/dev/ref/contrib/gis/geoquerysets/#geometry-output\">formats</a>: GeoHash, GeoJSON, GML, KML, and SVG. Of all these serialization formats, I've found KML to be the most frequently used amongst GeoDjango users. Illustrative of this, three of the four functions in <a href=\"https://code.djangoproject.com/browser/django/trunk/django/contrib/gis/shortcuts.py\">django.contrib.gis.shortcuts</a> have to do with KML/KMZ. That's awesome, but where is the love for GeoJSON?</p>\n<p>KML can be easily consumed by OpenLayers, the king of open source web mapping viewers. But some of the new kids, e.g. leaflet, polymaps, look to favor GeoJSON over KML as an input for dynamically rendered data, not directly consuming KML out-of-the-box. That being said, if you want KML, this <a href=\"https://github.com/shramov/Leaflet/tree/master/src/layer\">fork of leaflet</a> looks like it will work for you. In my particular project, I'm interested in using leaflet, so GeoJSON was the way to go.</p>\n<p>Later on, I'd like to do some speed comparisons, rendering the same featureset using OpenLayers, represented as both KML and GeoJSON, but that's for the future. I'm wondering if OpenLayers will handle the JSON object faster then KML's XML? JSON is just JavaScript after all.</p>\n<h2 id=\"the-problem\" tabindex=\"-1\">The Problem <a class=\"header-anchor\" href=\"https://mattmakesmaps.com/blog/2011-12-12-geodjango-standing-up-a-geojson-web-service/\">#</a></h2>\n<p>The GeoDjango GeoQuerySet API has built in methods to handle the serialization and de-serialization of a result set's geometries into different formats. The problem is that these methods only wrap the geometries of a result set. For display in a web mapping application, like leaflet, I want to have access to both the geometry in the format of my choosing, as well as the supplementary attributes (name, type, etc.) which provide context for that geometry.</p>\n<p>For example, asking for the GeoJSON representation of a given feature through Django's shell, like this:</p>\n<pre class=\"language-python\" tabindex=\"0\"><code class=\"language-python\"><span class=\"token comment\"># Import Models from the Company Application</span>\n<span class=\"token keyword\">from</span> company<span class=\"token punctuation\">.</span>Models <span class=\"token keyword\">import</span> <span class=\"token operator\">*</span>\n<span class=\"token comment\"># Create a GeoQuerySet from the primary key, return GeoJSON</span>\nqs <span class=\"token operator\">=</span> Boundary<span class=\"token punctuation\">.</span>objects<span class=\"token punctuation\">.</span><span class=\"token builtin\">filter</span><span class=\"token punctuation\">(</span>pk<span class=\"token operator\">=</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>geojson<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n<span class=\"token comment\"># Print GeoJSON representation of geom</span>\n<span class=\"token keyword\">print</span> qs<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>geojson</code></pre>\n<p>Will produce a GeoJSON object like this:</p>\n<pre class=\"language-javascript\" tabindex=\"0\"><code class=\"language-javascript\"><span class=\"token punctuation\">{</span>\n <span class=\"token string-property property\">\"type\"</span><span class=\"token operator\">:</span><span class=\"token string\">\"MultiPolygon\"</span><span class=\"token punctuation\">,</span>\n  <span class=\"token string-property property\">\"coordinates\"</span><span class=\"token operator\">:</span><span class=\"token punctuation\">[</span>\n    <span class=\"token punctuation\">[</span>\n      <span class=\"token punctuation\">[</span>\n        <span class=\"token punctuation\">[</span>\n          <span class=\"token operator\">-</span><span class=\"token number\">122.574295</span><span class=\"token punctuation\">,</span>\n          <span class=\"token number\">47.856636</span>\n        <span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span>\n        <span class=\"token punctuation\">[</span>\n          <span class=\"token operator\">-</span><span class=\"token number\">122.573924</span><span class=\"token punctuation\">,</span>\n          <span class=\"token number\">47.85718</span>\n        <span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span>\n        <span class=\"token punctuation\">[</span>\n          <span class=\"token operator\">-</span><span class=\"token number\">122.573719</span><span class=\"token punctuation\">,</span>\n          <span class=\"token number\">47.85757</span>\n        <span class=\"token punctuation\">]</span> <span class=\"token comment\">// Truncated Verticies</span>\n      <span class=\"token punctuation\">]</span>\n    <span class=\"token punctuation\">]</span>\n  <span class=\"token punctuation\">]</span>\n<span class=\"token punctuation\">}</span></code></pre>\n<p>As shown in the example above, the geometries are returned, but not the tabular attributes associated with that feature. Looking at the <a href=\"http://geojson.org/geojson-spec.html\">GeoJSON spec</a>, there are multiple 'type' values which an object can be constrained by. Using GeoDjango's geoJSON() method will produce a type matching the geometry listed in the associated GeoDjango model (point, line, polygon, etc). The distinction here is that I'd like to return a GeoJSON object of type 'Feature' or 'FeatureCollection'. These types require an additional 'properties' parameter, which can store tabular attributes. From the spec:</p>\n<blockquote></blockquote>\n<p>A feature object must have a member with the name &quot;properties&quot;. The value of the properties member is an object (any JSON object or a JSON null value).</p>\n<p>So, the trick now is to dynamically create a GeoJSON object which contains both populated Geom and Properties attributes.</p>\n<h2 id=\"the-fix-vectorformats\" tabindex=\"-1\">The fix (vectorformats) <a class=\"header-anchor\" href=\"https://mattmakesmaps.com/blog/2011-12-12-geodjango-standing-up-a-geojson-web-service/\">#</a></h2>\n<p>In order to create a fully populated GeoJSON object, we need to bring in some extra assistance. Some quick searching brought me to this stack exchange <a href=\"http://stackoverflow.com/questions/3034482/rendering-spatial-data-of-geoqueryset-in-a-custom-view-on-geodjango\">response</a>, from <a href=\"http://crschmidt.net/blog/\">Chris Schmidt</a>. Chris' vectorformats package handles the serialization and de-serializtion of a variety of formats, including Django Querysets and GeoJSON. From the project <a href=\"http://packages.python.org/vectorformats/\">homepage</a>:</p>\n<blockquote></blockquote>\n<p>The vectorformats library is designed to make it easy to serialize content from any source to any source within Python. Think of it as a poor mans OGR  a pure Python implementation of transforming features to and from various formats (largely XML based).</p>\n<p>Installing vectorformats is as easy as:</p>\n<pre class=\"language-bash\" tabindex=\"0\"><code class=\"language-bash\"><span class=\"token variable\">$sudo</span> easy_install vectorformats</code></pre>\n<p>From there, as outlined in the above referenced post, it's only a matter of adding a few lines into your GeoDjango app's <a href=\"https://github.com/mattmakesmaps/geodjango/blob/master/sampling/views.py\">view function</a>.</p>\n<pre class=\"language-python\" tabindex=\"0\"><code class=\"language-python\"><span class=\"token comment\"># Using vectorfeatures module return a GeoJSON FeatureCollection</span>\n<span class=\"token comment\"># for a given boundary ID.</span>\n<span class=\"token keyword\">def</span> <span class=\"token function\">boundary_detail</span><span class=\"token punctuation\">(</span>request<span class=\"token punctuation\">,</span> boundary_id<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    boundary_detail <span class=\"token operator\">=</span> Boundary<span class=\"token punctuation\">.</span>objects<span class=\"token punctuation\">.</span><span class=\"token builtin\">filter</span><span class=\"token punctuation\">(</span>pk<span class=\"token operator\">=</span>boundary_id<span class=\"token punctuation\">)</span>\n    djf <span class=\"token operator\">=</span> Django<span class=\"token punctuation\">.</span>Django<span class=\"token punctuation\">(</span>geodjango<span class=\"token operator\">=</span><span class=\"token string\">'geom'</span><span class=\"token punctuation\">,</span> properties<span class=\"token operator\">=</span><span class=\"token punctuation\">[</span><span class=\"token string\">'name'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n    geoj <span class=\"token operator\">=</span> GeoJSON<span class=\"token punctuation\">.</span>GeoJSON<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n    s <span class=\"token operator\">=</span> geoj<span class=\"token punctuation\">.</span>encode<span class=\"token punctuation\">(</span>djf<span class=\"token punctuation\">.</span>decode<span class=\"token punctuation\">(</span>boundary_detail<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">return</span> HttpResponse<span class=\"token punctuation\">(</span>s<span class=\"token punctuation\">)</span></code></pre>\n<p>The resulting GeoJSON object, represented as a 'type' of 'FeatureCollection':</p>\n<pre class=\"language-javascript\" tabindex=\"0\"><code class=\"language-javascript\"><span class=\"token punctuation\">{</span>\n  <span class=\"token string-property property\">\"crs\"</span><span class=\"token operator\">:</span><span class=\"token keyword\">null</span><span class=\"token punctuation\">,</span>\n  <span class=\"token string-property property\">\"type\"</span><span class=\"token operator\">:</span><span class=\"token string\">\"FeatureCollection\"</span><span class=\"token punctuation\">,</span>\n  <span class=\"token string-property property\">\"features\"</span><span class=\"token operator\">:</span><span class=\"token punctuation\">[</span>\n    <span class=\"token punctuation\">{</span>\n      <span class=\"token string-property property\">\"geometry\"</span><span class=\"token operator\">:</span><span class=\"token punctuation\">{</span>\n        <span class=\"token string-property property\">\"type\"</span><span class=\"token operator\">:</span><span class=\"token string\">\"MultiPolygon\"</span><span class=\"token punctuation\">,</span>\n        <span class=\"token string-property property\">\"coordinates\"</span><span class=\"token operator\">:</span><span class=\"token punctuation\">[</span>\n          <span class=\"token punctuation\">[</span>\n            <span class=\"token punctuation\">[</span>\n              <span class=\"token punctuation\">[</span>\n                <span class=\"token operator\">-</span><span class=\"token number\">122.574295</span><span class=\"token punctuation\">,</span>\n                <span class=\"token number\">47.856636</span>\n              <span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span>\n              <span class=\"token punctuation\">[</span>\n                <span class=\"token operator\">-</span><span class=\"token number\">122.573924</span><span class=\"token punctuation\">,</span>\n                <span class=\"token number\">47.85718</span>\n              <span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span>\n              <span class=\"token punctuation\">[</span>\n                <span class=\"token operator\">-</span><span class=\"token number\">122.573719</span><span class=\"token punctuation\">,</span>\n                <span class=\"token number\">47.85757</span>\n              <span class=\"token punctuation\">]</span> <span class=\"token comment\">// Truncated Verticies</span>\n            <span class=\"token punctuation\">]</span>\n          <span class=\"token punctuation\">]</span>\n        <span class=\"token punctuation\">]</span>\n      <span class=\"token punctuation\">}</span><span class=\"token punctuation\">,</span>\n      <span class=\"token string-property property\">\"type\"</span><span class=\"token operator\">:</span><span class=\"token string\">\"Feature\"</span><span class=\"token punctuation\">,</span>\n      <span class=\"token string-property property\">\"id\"</span><span class=\"token operator\">:</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span>\n      <span class=\"token string-property property\">\"properties\"</span><span class=\"token operator\">:</span><span class=\"token punctuation\">{</span>\n        <span class=\"token string-property property\">\"name\"</span><span class=\"token operator\">:</span><span class=\"token string\">\"Port Gamble\"</span>\n      <span class=\"token punctuation\">}</span>\n    <span class=\"token punctuation\">}</span>\n  <span class=\"token punctuation\">]</span>\n<span class=\"token punctuation\">}</span></code></pre>\n<p>And there you have it, GeoJSON containing both the geometry and attributes. This output can now be mapped to URL, creating an endpoint such as 'http://my-site.com/geojson/boundary/{boundary_id}/'. Pass this to your web mapping client, and you're ready to rock.</p>\n",
			"date_published": "2011-12-12T00:00:00Z"
		}
		,
		{
			"id": "https://mattmakesmaps.com/blog/2011-11-28-moving-to-geodjango/",
			"url": "https://mattmakesmaps.com/blog/2011-11-28-moving-to-geodjango/",
			"title": "Moving to GeoDjango",
			"content_html": "<p>I've been creating a simple GeoDjango application for managing environmental sampling metadata, and it's been a lot of fun so far. I've had experience working with many different forms of metadata tracking, from spreadsheets, to wikis, to online project management tools. All of them have their ups and downs, and it seems like there is always a dealbreaker with each organizational method.</p>\n<p>Spreadsheets are easy to edit, but lack any form of relational structure (two sets of data for the same report? i guess i'll just put two entries into the same cell).</p>\n<!-- more -->\n<p>[caption id=&quot;attachment_487&quot; align=&quot;alignnone&quot; width=&quot;464&quot; caption=&quot;sometimes spreadsheets just don't work...&quot;]<a href=\"http://www.mkgeomatics.com/wordpress/wp-content/uploads/2011/11/Screenshot.png\"><img src=\"http://www.mkgeomatics.com/wordpress/wp-content/uploads/2011/11/Screenshot.png\" alt=\"\"></a>[/caption]</p>\n<p>Wikis are cool, allow easy access to information, but are (in certain cases) a pain for folks to edit. Take the experience of table creation. Dokuwiki, a generic wiki software, requires a series of carefully placed carrots and pipes to delineate headers and columns. A common pain comes when adding a new value to a new row, in which that value exceeds the length of any previous cell. This requires the author to expand the column header, and all previously entered rows, re-aligning the pipes and carrots. Granted as a slightly OCD GIS Analyst, the sight of a well crafted text table fills me with no less wonder then when I saw AlbertBierstadt's <a href=\"http://www.seattleartmuseum.org/exhibit/exhibitDetail.asp?eventID=21084\">&quot;Puget Sound on the Pacific Coast&quot;</a>, but it's just darn tedious at times. Additionally, as the log of sampling events grows larger, it gets harder to manage. Dokuwiki, AFAIK provides no ways to automatically resort entire sections of pages or records in tables based on alphabetical order, which would make searching for information on a particular page much faster as content becomes larger and larger.</p>\n<pre class=\"language-bash\" tabindex=\"0\"><code class=\"language-bash\">^ Column One                ^ Column Two                 ^\n<span class=\"token operator\">|</span> Zee <span class=\"token string\">'z'</span> string            <span class=\"token operator\">|</span> This is a longer string    <span class=\"token operator\">|</span>\n<span class=\"token operator\">|</span> 2nd longer string of text <span class=\"token operator\">|</span> 2nd short string           <span class=\"token operator\">|</span>\n<span class=\"token operator\">|</span> SuperShort                <span class=\"token operator\">|</span> A string starting with <span class=\"token string\">'A'</span> <span class=\"token operator\">|</span></code></pre>\n<p>Online project management tools are interesting as well. They allow rapid collaboration between project members, and provide template functionality, allowing for status reports on recurring workflows to be easily generated (e.g., create a template for a report, spawn off an instance of a template for each new project). The downside to these services are that: they cost money, they also may not provide a normalized way to store data, and (of most interest to myself) they probably don't allow for the storage/visualization of spatial data.</p>\n<p>[caption id=&quot;attachment_488&quot; align=&quot;alignnone&quot; width=&quot;300&quot; caption=&quot;10 megs free for one user? cool!&quot;]<a href=\"http://www.mkgeomatics.com/wordpress/wp-content/uploads/2011/11/Screenshot-1.png\"><img src=\"http://www.mkgeomatics.com/wordpress/wp-content/uploads/2011/11/Screenshot-1-300x162.png\" alt=\"\"></a>[/caption]</p>\n<p>In comes GeoDjango. Over the next few posts, I think I'll record my experiences developing an application that allows the storage of metadata, within the context of environmental sampling efforts. The goal is to provide a web application which stores both tabular and spatial data in a normalized fashion, and easily visualize both in an informative way.</p>\n<p>[caption id=&quot;attachment_489&quot; align=&quot;alignnone&quot; width=&quot;300&quot; caption=&quot;Hey look Ma', it's GeoJSON!&quot;]<a href=\"http://www.mkgeomatics.com/wordpress/wp-content/uploads/2011/11/Screenshot-2.png\"><img src=\"http://www.mkgeomatics.com/wordpress/wp-content/uploads/2011/11/Screenshot-2-300x147.png\" alt=\"\"></a>[/caption]</p>\n",
			"date_published": "2011-11-28T00:00:00Z"
		}
		,
		{
			"id": "https://mattmakesmaps.com/blog/2011-02-25-hand-rolled-vector-tiles-tilestache/",
			"url": "https://mattmakesmaps.com/blog/2011-02-25-hand-rolled-vector-tiles-tilestache/",
			"title": "Hand-Rolled Vector Tiles - TileStache",
			"content_html": "<p>A few weeks ago I found myself surfing the intertubes for instructions on how to serve up some vector tile goodness. That search came up pretty much empty, except for one glimmering <a href=\"http://gis.stackexchange.com/questions/3712/create-vector-geojson-tiles-for-polymaps\">thread</a> of hope. The answer, <a href=\"http://tilestache.org/\">TileStache</a> { &lt;-- Imagine that's a mustache on it's side.</p>\n<blockquote>\n<p>TileStache is a Python-based server application that can serve up map tiles based on rendered geographic data.</p>\n</blockquote>\n<!-- more -->\n<p>By design, TileStache can be used to serve up stylish TMS tiles using <a href=\"http://mapnik.org/\">mapnik</a> map files, and can also be used to locally cache remote-services via <a href=\"http://tilestache.org/doc/#providers\">proxy</a>. What I'm most interested in though, is it's ability to deploy vector tiles. So what are vector tiles? Think TMS tiles... but replace representations of the geometries through images, with <a href=\"http://geojson.org/\">GeoJSON</a>. Pretty wild right? Specifically, the TileStache <a href=\"http://tilestache.org/doc/TileStache.Goodies.Providers.PostGeoJSON.html\">PostGeoJSON Provider</a> can be used to connect TileStache to a PostGIS data source, and return a tile comprised entirely of GeoJSON data.</p>\n<p>For example, data from a PostGIS data source can be rendered as an image tile (.../10/16/357.png), like this:</p>\n<p><a href=\"http://www.mkgeomatics.com/wordpress/wp-content/uploads/2011/02/tile.png\"><img src=\"http://www.mkgeomatics.com/wordpress/wp-content/uploads/2011/02/tile.png\" alt=\"\"></a></p>\n<p>But can also be represtented as a vector tile (.../10/16/357.json), like this:</p>\n<pre class=\"language-javascript\" tabindex=\"0\"><code class=\"language-javascript\"><span class=\"token comment\">// Subset of a single 256x256 pixel vector tile.</span>\n<span class=\"token punctuation\">{</span>\n  <span class=\"token string-property property\">\"type\"</span><span class=\"token operator\">:</span> <span class=\"token string\">\"FeatureCollection\"</span><span class=\"token punctuation\">,</span>\n  <span class=\"token string-property property\">\"features\"</span><span class=\"token operator\">:</span> <span class=\"token punctuation\">[</span>\n    <span class=\"token punctuation\">{</span>\n      <span class=\"token string-property property\">\"geometry\"</span><span class=\"token operator\">:</span> <span class=\"token punctuation\">{</span>\n        <span class=\"token string-property property\">\"type\"</span><span class=\"token operator\">:</span> <span class=\"token string\">\"MultiPolygon\"</span><span class=\"token punctuation\">,</span>\n        <span class=\"token string-property property\">\"coordinates\"</span><span class=\"token operator\">:</span> <span class=\"token punctuation\">[</span>\n          <span class=\"token punctuation\">[</span>\n            <span class=\"token punctuation\">[</span>\n              <span class=\"token punctuation\">[</span>\n                <span class=\"token operator\">-</span><span class=\"token number\">122.973093</span><span class=\"token punctuation\">,</span>\n                <span class=\"token number\">47.969842</span>\n              <span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span><span class=\"token operator\">...</span>\n              <span class=\"token punctuation\">[</span>\n                <span class=\"token operator\">-</span><span class=\"token number\">122.973093</span><span class=\"token punctuation\">,</span>\n                <span class=\"token number\">47.969842</span>\n              <span class=\"token punctuation\">]</span>\n            <span class=\"token punctuation\">]</span>\n          <span class=\"token punctuation\">]</span>\n        <span class=\"token punctuation\">]</span>\n      <span class=\"token punctuation\">}</span><span class=\"token punctuation\">,</span>\n      <span class=\"token string-property property\">\"type\"</span><span class=\"token operator\">:</span> <span class=\"token string\">\"Feature\"</span><span class=\"token punctuation\">,</span>\n      <span class=\"token string-property property\">\"properties\"</span><span class=\"token operator\">:</span> <span class=\"token punctuation\">{</span>\n        <span class=\"token string-property property\">\"property_s\"</span><span class=\"token operator\">:</span> <span class=\"token string\">\"USFS\"</span><span class=\"token punctuation\">,</span>\n        <span class=\"token string-property property\">\"juris_name\"</span><span class=\"token operator\">:</span> <span class=\"token string\">\"Olympic National Forest\"</span>\n      <span class=\"token punctuation\">}</span><span class=\"token punctuation\">,</span>\n      <span class=\"token string-property property\">\"id\"</span><span class=\"token operator\">:</span> <span class=\"token number\">1280</span>\n    <span class=\"token punctuation\">}</span>\n  <span class=\"token punctuation\">]</span>\n<span class=\"token punctuation\">}</span></code></pre>\n<p>So what are the advantages of using vector tiles? You can already use <a href=\"http://dev.openlayers.org/docs/files/OpenLayers/Format/GeoJSON-js.html\">OpenLayers' GeoJSON</a> format reader to populate a vector layer in OL. It's an issue of size. Highly complex geometries can be large in size, and requesting all that data at once can be time consuming. Vector tiles approach this problem using the same answer as TMS... only request those sections of data which you need at that time. By only requesting those tiles within the user's current extent + a small buffer, the need to download large geometries at once can be negated. Furthermore, just as TMS's can be pre-cached to disk (seeded), so can vector tiles.</p>\n<p>One example of this is serving up a combined NFS boundary dataset compiled by my good pal, Greg (<a href=\"http://www.chopshopgeo.com/blog/\">http://www.chopshopgeo.com/blog/</a>). These boundaries are <strong>dense</strong> and displaying them at their full extent &amp; raw level of detail is expensive. But by breaking the vector representations of these geometries up into a standard tile scheme, only those tiles which we need are requested, and only when we need them. As a side note, in addition to tiling, I also simplified the boundaries, to promote faster load time at small-scales. The least granular vector representations display at the smallest zoom-scales, while the highest (raw, unsimplified) level of granularity displays only at the largest zoom-scales.</p>\n<p>[caption id=&quot;attachment_398&quot; align=&quot;alignnone&quot; width=&quot;665&quot; caption=&quot;NFS Boundaries Provided By ChopShopGeo&quot;]<a href=\"http://www.mkgeomatics.com/wordpress/wp-content/uploads/2011/02/parks.png\"><img src=\"http://www.mkgeomatics.com/wordpress/wp-content/uploads/2011/02/parks.png\" alt=\"\"></a>[/caption]</p>\n<p>Additionally, using vector representations of geometry rather then cached images allows styling of those geometries on the fly. <a href=\"http://polymaps.org/\">Polymaps</a>, the only display client I've found so far that can consume vector tiles out-of-the-box, renders these tiles as SVG elements. Because of this, unique styling can be applied via CSS; controlling the color, stroke, fill, etc. of each geometry in response to both attributes associated with the geometry (see image below) or user input... ala the <a href=\"http://polymaps.org/ex/statehood.html\">Polymaps example page</a>.</p>\n<p>[caption id=&quot;attachment_393&quot; align=&quot;alignnone&quot; width=&quot;691&quot; caption=&quot;USGS real-time gauge stations. Darker dots represent stronger streamflow, lighter dots represent slower flow. You'll have to ignore the fact that I'm symbolizing streamflow without the streams.&quot;]<a href=\"http://www.mkgeomatics.com/wordpress/wp-content/uploads/2011/02/usgs.png\"><img src=\"http://www.mkgeomatics.com/wordpress/wp-content/uploads/2011/02/usgs.png\" alt=\"\"></a>[/caption]</p>\n<p>The above example converts data from the <a href=\"http://waterservices.usgs.gov/rest/WOF-IV-Service.html\">USGS Instantaneous Values Web Service</a> (part of the <a href=\"http://waterdata.usgs.gov/nwis/\">USGS Water Date for the Nation program</a>) as a JSON response to GeoJSON. These data points are then symbolized dynamically using Polymaps. More on that later.</p>\n<pre class=\"language-javascript\" tabindex=\"0\"><code class=\"language-javascript\"><span class=\"token punctuation\">{</span>\n<span class=\"token string-property property\">\"type\"</span><span class=\"token operator\">:</span> <span class=\"token string\">\"FeatureCollection\"</span><span class=\"token punctuation\">,</span>\n<span class=\"token string-property property\">\"features\"</span><span class=\"token operator\">:</span> <span class=\"token punctuation\">[</span><span class=\"token punctuation\">{</span>\n<span class=\"token string-property property\">\"geometry\"</span><span class=\"token operator\">:</span> <span class=\"token punctuation\">{</span>\n<span class=\"token string-property property\">\"type\"</span><span class=\"token operator\">:</span> <span class=\"token string\">\"MultiPolygon\"</span><span class=\"token punctuation\">,</span>\n<span class=\"token string-property property\">\"coordinates\"</span><span class=\"token operator\">:</span> <span class=\"token punctuation\">[</span>\n<span class=\"token punctuation\">[</span>\n<span class=\"token punctuation\">[</span>\n<span class=\"token punctuation\">[</span><span class=\"token operator\">-</span><span class=\"token number\">122.973093</span><span class=\"token punctuation\">,</span> <span class=\"token number\">47.969842</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span>\n<span class=\"token punctuation\">[</span><span class=\"token operator\">-</span><span class=\"token number\">122.973093</span><span class=\"token punctuation\">,</span> <span class=\"token number\">47.969842</span><span class=\"token punctuation\">]</span>\n<span class=\"token punctuation\">]</span>\n<span class=\"token punctuation\">]</span>\n<span class=\"token punctuation\">]</span>\n<span class=\"token punctuation\">}</span><span class=\"token punctuation\">,</span>\n<span class=\"token literal-property property\">http</span><span class=\"token operator\">:</span> <span class=\"token comment\">//jsbeautifier.org/</span>\n<span class=\"token string-property property\">\"type\"</span><span class=\"token operator\">:</span> <span class=\"token string\">\"Feature\"</span><span class=\"token punctuation\">,</span>\n<span class=\"token string-property property\">\"properties\"</span><span class=\"token operator\">:</span> <span class=\"token punctuation\">{</span>\n<span class=\"token string-property property\">\"property_s\"</span><span class=\"token operator\">:</span> <span class=\"token string\">\"USFS\"</span><span class=\"token punctuation\">,</span>\n<span class=\"token string-property property\">\"juris_name\"</span><span class=\"token operator\">:</span> <span class=\"token string\">\"Olympic National Forest\"</span>\n<span class=\"token punctuation\">}</span><span class=\"token punctuation\">,</span>\n<span class=\"token string-property property\">\"id\"</span><span class=\"token operator\">:</span> <span class=\"token number\">1280</span>\n<span class=\"token punctuation\">}</span><span class=\"token punctuation\">]</span>\n<span class=\"token punctuation\">}</span></code></pre>\n",
			"date_published": "2011-02-25T00:00:00Z"
		}
		,
		{
			"id": "https://mattmakesmaps.com/blog/2010-07-09-curling-to-featureserver-from-postgis-easier-then-i-thought/",
			"url": "https://mattmakesmaps.com/blog/2010-07-09-curling-to-featureserver-from-postgis-easier-then-i-thought/",
			"title": "cURL&#39;ing to FeatureServer from PostGIS: Easier then I Thought",
			"content_html": "<p>So I've finished cutting a draft tileset using mapnik, <a href=\"http://mkgeomatics.com/apps/bus/bus.html\">depicting bus routes in Bellingham, WA</a>. Now that the cartography is well in progress, I'd like to add some interactivity to the map. My first attempt at this will be to utilize MetaCarta (Chris Schmidt)'s <a href=\"http://featureserver.org/\">FeatureServer</a>. <!-- more --> FeatureServer allows one to use standard HTTP verbs to GET representations of data, POST new data, or DELETE existing data. While querying data you can also pass additional URL parameters like a bounding box or attribute to select out a smaller subset of returned representations. I'll be POST'ing a bus stop dataset to FeatureServer as GeoJSON. Once the data are stored in FeatureServer, I'll be able to add popups based on a user's click of a bus stop. <!-- more --></p>\n<p>Getting data stored on my local PostGIS install to my remote FeatureServer instance turned out to be a three step process.</p>\n<p><strong>Step One:</strong> Convert local PostGIS bus stops layer to GeoJSON via OGR</p>\n<p>I had originally planned on writing a pg/plsql function to try and output a bash script. The script would cURL each feature individually to my FeatureServer instance. This proved to be way more work then I had expected. What was the solution? <a href=\"http://www.gdal.org/ogr/\">OGR</a>, of course. OGR has read/write drivers for both <a href=\"http://www.gdal.org/ogr/drv_geojson.html\">GeoJSON</a> and <a href=\"http://www.gdal.org/ogr/drv_pg.html\">PostGIS</a>. This allows one to convert an entire dataset to GeoJSON with a single command (see below).</p>\n<p>[sourcecode language=&quot;bash&quot;]\nogr2ogr -f &quot;GeoJSON&quot; ogrstops.json PG:&quot;host=localhost dbname=routing user=postgres password=*** port=5432&quot; &quot;wtastops(the_geom)&quot;\n[/sourcecode]</p>\n<p><strong>Step 2:</strong> Wrap &quot;coordinate&quot; elements in double brackets</p>\n<p>When initially trying to cURL the GeoJSON output to FeatureServer, I was receiving an error stating that a bounding box could not be determined for the first geometry in my dataset. After some trial-and-error, I soon realized that the OGR output FeatureCollection was wrapping each point feature's geometry in a single set of brackets. This type of behavior follows the GeoJSON <a href=\"http://geojson.org/geojson-spec.html#id9\">specification for a FeatureCollection</a>, as far as I can tell. However, in order for FeatureServer to consume this dataset, each point feature is required to be wrapped in a second set of brackets. I used gedit to run the find/replace. Below is an example of a GeoJSON feature which FeatureServer can consume. This individual feature is part of a larger FeatureCollection.</p>\n<p>[sourcecode language=&quot;js&quot;]</p>\n<p>{ &quot;type&quot;: &quot;Feature&quot;,\n&quot;properties&quot;: {\n&quot;POINT_ID&quot;: &quot;1000&quot;,\n&quot;POINT_NAME&quot;: &quot;Fielding at 32nd&quot;,\n&quot;SHELTER&quot;: &quot;Yes&quot;, &quot;BENCH&quot;: &quot;No&quot; },\n&quot;geometry&quot;: {\n&quot;type&quot;: &quot;Point&quot;,\n&quot;coordinates&quot;: [[-122.474490,48.730021]]}\n}\n[/sourcecode]</p>\n<p><strong>Step 3:</strong> cURL GeoJSON to FeatureServer</p>\n<p>The last step is to actually POST the data to FeatureServer. For that, I used cURL.</p>\n<p>[sourcecode language=&quot;bash&quot;]</p>\n<p>curl -d @ogrstops.json http://mkgeomatics.com/cgi-bin/featureserver/featureserver.cgi/scribble/create.json</p>\n<p>[/sourcecode]</p>\n<p>Now that the features have been uploaded, we can view them via FeatureServer as <a href=\"http://mkgeomatics.com/cgi-bin/featureserver/featureserver.cgi/scribble/all.georss\">GeoRSS</a>, <a href=\"http://mkgeomatics.com/cgi-bin/featureserver/featureserver.cgi/scribble/all.kml\">KML</a>, <a href=\"http://mkgeomatics.com/cgi-bin/featureserver/featureserver.cgi/scribble/all.json\">JSON</a>, <a href=\"http://mkgeomatics.com/cgi-bin/featureserver/featureserver.cgi/scribble/all.gml\">GML</a>. Neat!</p>\n",
			"date_published": "2010-07-09T00:00:00Z"
		}
		,
		{
			"id": "https://mattmakesmaps.com/blog/2010-06-28-plpgsql-function-to-iterate-pgrouting/",
			"url": "https://mattmakesmaps.com/blog/2010-06-28-plpgsql-function-to-iterate-pgrouting/",
			"title": "PL/pgSQL function to Iterate pgRouting",
			"content_html": "<p>I've been working on a side project using <a href=\"http://www.mkgeomatics.com/wordpress/?s=pgRouting&amp;searchsubmit=Find\">pgRouting</a> to determine the least-cost path across a street network from a given building to the nearest bus stop within <a href=\"http://en.wikipedia.org/wiki/Bellingham,_Washington\">Bellingham, WA</a>. It's one thing to execute pgRouting's built-in functions for a single vertex (building) to another vertex (bus stop)... but another to have the function iterate through all buildings and their closest bus stop. <!-- more --></p>\n<p>So that began my first experience with using PL/pgSQL. The benefit for using the procedural language for PostgreSQL lies in its ability to loop through collections of records easily. I've posted my function below. It's not pretty, but it's filled with enough notices to let me know where an error occurs, which helped me understand how things were acting each step of the way. Here is the basic idea:</p>\n<ul>\n<li>\n<p>Loop through a table in which each row has a source and destination vertex</p>\n</li>\n<li>\n<p>Execute the pgRouting function using these two vertices, determining the length of the least-cost path.</p>\n</li>\n<li>\n<p>Populate a field, 'dist_calc' with the distance.</p>\n</li>\n</ul>\n<p>[sourcecode]\nCREATE OR REPLACE FUNCTION bulk_route_generate() RETURNS VOID AS $$\nDECLARE\nbld_row bld_wtastops_staging5%ROWTYPE;\ndist_calc RECORD;\nBEGIN\nRAISE NOTICE 'Beginning Function';\nFOR bld_row IN SELECT * FROM bld_wtastops_staging5 WHERE bld_wtastops_staging5.bld_vert_node IS NOT NULL\nAND bld_wtastops_staging5.wtastops_vert_node IS NOT NULL\n-- BEGIN ADDING BUM NODES TO SKIP OVER\nAND bld_wtastops_staging5.bld_vert_node &lt;&gt; 2915\nAND bld_wtastops_staging5.wtastops_vert_node &lt;&gt; 293\n-- ADD START GID\n-- USED ONLY IF BUM NODES EXIST\n--AND bld_wtastops_staging5.bld_gid &gt;= 29200\nORDER BY bld_wtastops_staging5.bld_gid LOOP\nRAISE NOTICE 'Value of wtastops_vert_node is %. The value of bld_vert_node is %',bld_row.wtastops_vert_node, bld_row.bld_vert_node;\nRAISE NOTICE 'Value of wtastops_gid is %. The value of bld_gid is %',bld_row.wtastops_gid, bld_row.bld_gid;\n-- BEGIN STANDARD pgRouting A*Star FUNCTION\nSELECT SUM(cost) INTO dist_calc FROM shortest_path_astar('\nSELECT gid as id,\nsource::integer,\ntarget::integer,\nlength::double precision as cost,\nx1, y1, x2, y2\nFROM streets_9102748',\nbld_row.bld_vert_node, bld_row.wtastops_vert_node, false, false);\nRAISE NOTICE 'Value of dist_calc is %.',dist_calc;\nEXECUTE 'UPDATE bld_wtastops_staging5\nSET route_dist = ' ||dist_calc|| '\nWHERE ' ||bld_row.bld_gid|| ' = bld_wtastops_staging5.bld_gid';\nEND LOOP;\n-- BAIL OUT ON ERRORS\nEXCEPTION\nWHEN CONTAINING_SQL_NOT_PERMITTED THEN\nRAISE NOTICE ' EXECPTION Value of wtastops_vert_node is %. The value of bld_vert_node is %',bld_row.wtastops_vert_node, bld_row.bld_vert_node;\nEND;\n$$ LANGUAGE 'plpgsql';\n-- EXECUTE FUNCTION\nSELECT bulk_route_generate();\n[/sourcecode]</p>\n<p>I'm excited at the possibilities that using PL/pgSQL offers in terms of manipulating data. I'm sure that the above function can be cleaned up quite a bit, too. If I ever have the need to re-visit this or similar problems, I'll be sure to do some serious head-scratching to think about a better approach!</p>\n<p>Here is an image of the resulting data generated using <a href=\"http://mapnik.org/\">mapnik</a>. Areas from dark green to light-green are within a 1/4 mile distance, while areas from yellow-to-red represent distances increasingly greater then a 1/4 mile. The large checkered areas are where the dataset failed to route. More on that at another time.</p>\n<p>[caption id=&quot;attachment_360&quot; align=&quot;alignnone&quot; width=&quot;430&quot; caption=&quot;the result as seen in mapnik&quot;]<a href=\"http://www.mkgeomatics.com/wordpress/wp-content/uploads/2010/06/bld_sym_diverging_web.png\"><img src=\"http://www.mkgeomatics.com/wordpress/wp-content/uploads/2010/06/bld_sym_diverging_web.png\" alt=\"bld_sym_diverging_web\"></a>[/caption]</p>\n",
			"date_published": "2010-06-28T00:00:00Z"
		}
		,
		{
			"id": "https://mattmakesmaps.com/blog/2010-02-06-pgrouting-iii-php-openlayers-interface/",
			"url": "https://mattmakesmaps.com/blog/2010-02-06-pgrouting-iii-php-openlayers-interface/",
			"title": "pgRouting III: PHP + OpenLayers Interface",
			"content_html": "<p>With the routing <a href=\"http://www.mkgeomatics.com/wordpress/?p=312\">database configured and populated</a>, and with <a href=\"http://www.mkgeomatics.com/wordpress/?p=322\">geoserver rendering the WMS</a>, now the focus can shift on designing the actual display and functionality.</p>\n<p>The conceptual plan is as follows: <!-- more --></p>\n<ul>\n<li>\n<p>Extract the geometry of a user's click on the map.</p>\n</li>\n<li>\n<p>Pass the extracted geometry to a PHP script, via an HTTP GET request.</p>\n</li>\n<li>\n<p>Use the PHP script to pass the geometry as part of an SQL query against the PostGIS/pgRouting database.</p>\n</li>\n<li>\n<p>Return the geometry from the database as <a href=\"http://geojson.org/\">GeoJSON</a>, and deserialize it into an OpenLayers vector layer feature.</p>\n</li>\n</ul>\n<p>The code to extract a user's clicked coordinates was taken from <a href=\"http://openlayers.org/dev/examples/click.html\">this</a> OpenLayers example. It was then modified to pass the xy coordinates to a second function, designed to create a URL which will execute a PHP script.</p>\n<p>[sourcecode language=&quot;javascript&quot;]trigger: function(e) {\nvar xy = map.getLonLatFromViewPortPx(e.xy);\nexecuteSQL(xy);\n}[/sourcecode]</p>\n<p>Passing the XY variable to the executeSQL() function, we are able to now seperate out the individual X and Y coordinates, and apply them to their respective parameters in our URL string.</p>\n<p>[sourcecode language=&quot;javascript&quot;]// Build the URL\nvar json_url = &quot;http://localhost/near_vertex_astar.php?&quot;;\njson_url += &quot;x=&quot; + escape(xy.lon);\njson_url += &quot;&amp;y=&quot; + escape(xy.lat);[/sourcecode]</p>\n<p>Having constructed the URL, we are now ready to use it to populate an OpenLayers vector layer with data.</p>\n<p>[sourcecode language=&quot;javascript&quot;]// Make a fresh vector layer, pulling features from our script URL\njson_layer = new OpenLayers.Layer.Vector(&quot;GeoJSON&quot;, {\nstyleMap: myStyles,\nstrategies: [new OpenLayers.Strategy.Fixed()],\nprotocol: new OpenLayers.Protocol.HTTP({\nurl: json_url,\nformat: new OpenLayers.Format.GeoJSON()\n})\n});[/sourcecode]</p>\n<p>Alright! So where are we at right now? A user has clicked the map, and that click's geometry has been extracted and sent to a PHP script on the server for further work. The PHP script will execute SQL in the PostGIS/pgRouting data base to do the following:</p>\n<ul>\n<li>\n<p>Find the closest vertex in our routing network to the user's map click. This will be used as a source vertex.</p>\n</li>\n<li>\n<p>Find all firestations within 5km of the vertex (which have been pre-attributed with the closest vertex on the routing network to their location).</p>\n</li>\n<li>\n<p>Calculate the cost (as defined by total length of the route) from the source vertex to each fire station (really the routing network vertex).</p>\n</li>\n<li>\n<p>Return back as GeoJSON only the geometry for the route with the lowest cost.</p>\n</li>\n</ul>\n<p>Why all the hassle with determining the cost? Can't you just use PostGIS' ST_DWithin() function to find the closet firestation to our user's click and create the route? Well you could, but it might not always be the shortest route.</p>\n<p>[caption id=&quot;attachment_339&quot; align=&quot;alignnone&quot; width=&quot;300&quot; caption=&quot;Euclidean distance versus Manhattan. Which one is shorter?&quot;]<a href=\"http://www.mkgeomatics.com/wordpress/wp-content/uploads/2010/02/distance.png\"><img src=\"http://www.mkgeomatics.com/wordpress/wp-content/uploads/2010/02/distance-300x279.png\" alt=\"Euclidean distance versus Manhattan. Which one is shorter?\"></a>[/caption]</p>\n<p>This behavior can be respresented in the routing network with the example below. Two different routes are generated from the same source vertex based on the combination of routing algorithm and account for route cost. On the left, the <a href=\"http://en.wikipedia.org/wiki/Dijkstra%27s_algorithm\">dijkstra algorithm</a> is used to return the route to the closest fire station as the result of an ST_DWithin() query. On the right, the A-Star algorithm is used, and the route costs of all fire stations within a buffer are taken into account. As we can see, a different route and a different station are returned.</p>\n<p><a href=\"http://www.mkgeomatics.com/wordpress/wp-content/uploads/2010/02/dj_left_astar_right1.png\"><img src=\"http://www.mkgeomatics.com/wordpress/wp-content/uploads/2010/02/dj_left_astar_right1-1024x338.png\" alt=\"Comparing the two search algorithms and cost relationships.\"></a></p>\n<p>A link to the JS and PHP scripts can be found at the end of this post. This definitely is not the most elegant solution to working with routing, but in terms of an experiment it was a great learning exercise. I'm really excited to dive deeper into PostGIS and pgRouting. The next step in the process will be incorporating OSM data, and adding in addition attributes which affect cost (speed limits, one-way streets, etc).</p>\n<p>View the <a href=\"http://mkgeomatics.com/apps/syntaxhighlighter/astar_php.html\">PHP</a>.</p>\n<p>View the <a href=\"http://mkgeomatics.com/apps/syntaxhighlighter/astar.html\">OL JS</a>.</p>\n",
			"date_published": "2010-02-06T00:00:00Z"
		}
		,
		{
			"id": "https://mattmakesmaps.com/blog/2010-01-31-pgrouting-part-ii-postgis-geoserver/",
			"url": "https://mattmakesmaps.com/blog/2010-01-31-pgrouting-part-ii-postgis-geoserver/",
			"title": "pgRouting Part II: PostGIS + Geoserver",
			"content_html": "<p>Since compiling <a href=\"http://pgrouting.postlbs.org/\">Orkney's pgRouting extension</a> to PostgreSQL/PostGIS, I've decided to try my hand at creating a simple web interface to poke into the database. The current setup is as follows: <!-- more --></p>\n<ul>\n<li>\n<p>Display: OpenLayers</p>\n</li>\n<li>\n<p>Renderer: Geoserver (via non-cached WMS)</p>\n</li>\n<li>\n<p>Spatial Backend: PostGIS/pgRouting enabled PostgreSQL</p>\n</li>\n<li>\n<p>Data: <a href=\"http://www.cob.org/services/maps/gis/index.aspx\">Public GIS data</a> from the city of Bellingham, Washington's GIS department.</p>\n</li>\n</ul>\n<p>For the sake of brevity, (but really because both TOPP has created some <a href=\"http://workshops.opengeo.org/opengeo-stack/\">fantastic guides</a>) I won't go into the specifics of installing all the pieces. Just as an FYI, remember to set your 'JAVA_HOME' environment variable and make sure that you don't have things trying to use the same port!</p>\n<p>The Bellingham data is currently stored in <a href=\"http://www.spatialreference.org/ref/esri/102748/\">NAD83 State Plane WA North Feet</a>, a typical projection for this area. This projection however, is not part of the EPSG projection set, and as such is not included in a vanilla install of PostGIS.</p>\n<p>In order to add this to the collection of spatial reference systems used by my PostGIS install, I went with the ridiculously cool <a href=\"http://spatialreference.org\">spatialreference.org</a> site (A <a href=\"http://crschmidt.net/\">crschmidt</a>, <a href=\"http://dbsgeo.com/\">dbsgeo</a>, <a href=\"http://hobu.biz/\">hobu</a>, and <a href=\"http://umbrellaconsulting.com/\">umbrella</a> joint, hah). Navigating to the projection's page gives me the option to generate an <a href=\"http://www.spatialreference.org/ref/esri/102748/postgis/\">INSERT</a> statement, adding the projection's info into my database.</p>\n<p>To load shapefiles into the PostGIS database, I chose to use the SPIT plugin for QGIS. Loading the data was fairly straightforward. I had an issue with a datefield that was present in the source shapefile, and had to delete the column manually using Open Office Database. I haven't found a way to delete fields from a shapefile using QGIS.</p>\n<p>[caption id=&quot;attachment_327&quot; align=&quot;alignnone&quot; width=&quot;300&quot; caption=&quot;The SPIT Interface&quot;]<a href=\"http://www.mkgeomatics.com/wordpress/wp-content/uploads/2010/01/spit.png\"><img src=\"http://www.mkgeomatics.com/wordpress/wp-content/uploads/2010/01/spit-300x175.png\" alt=\"spit\"></a>[/caption]</p>\n<p>After uploading the streets data into my PostGIS database, the next step was to transform the geometry into the Web Mercator 900913 Projection. This was done using standard PostGIS functions, adding a new, second, geometry column to the existing streets table. This reprojected data was then exported from my staging PostGIS database as a shapefile using the QGIS, 'Save As Shapefile' tool, and re-imported into my production database (with the routing functions).</p>\n<p>With data stored in the web mercator projection, inside of our PostGIS/pgRouting database, the next step was to add the layers to Geoserver. Using Geoserver 2.x, the process included the following steps (all done through the web-admin).</p>\n<ul>\n<li>\n<p>Add the new data store pointing the PostGIS database.</p>\n</li>\n<li>\n<p>Add new layers (resources) which point to the tables of interest in our PostGIS database.</p>\n</li>\n</ul>\n<p>After creating the connections between PostGIS and Geoserver, the creation of WMS services is taken care of, allowing us to roll them into OpenLayers with relative ease.</p>\n<p>I guess this got a little off-topic from what I originally wanted to write about. I think that I'll save the actual breakdown of my OL code (taking a user's map click to and using it to calculate a route to the nearest fire-station as determined by manhattan distance, as opposed to euclidean distance) for another day.</p>\n",
			"date_published": "2010-01-31T00:00:00Z"
		}
		,
		{
			"id": "https://mattmakesmaps.com/blog/2010-01-11-pgrouting-on-ubuntu-netbook-remix-9-10/",
			"url": "https://mattmakesmaps.com/blog/2010-01-11-pgrouting-on-ubuntu-netbook-remix-9-10/",
			"title": "pgRouting On Ubuntu Netbook Remix 9.10",
			"content_html": "<p>While working through Regina Obe and Leo Hsu's <a href=\"http://www.postgis.us\">PostGIS In Action</a> I thought that I'd jump into the world of routing. My plan was to develop a sample application that could be used to plan bicycle routes throughout the city of Seattle. A quick google search proved that someone has already done it, and done it very well! <a href=\"http://www.ridethecity.com/\">http://www.ridethecity.com/</a> provides cycling routes using OSM data for many major cities, Seattle included. <!-- more --></p>\n<p>Undeterred and inspired, i decided to compile the <a href=\"http://pgrouting.postlbs.org/\">pgRouting</a> set of tools for PostGIS and give them a whirl.</p>\n<p>My primary tutorial for moving through the install and execution of functions came from the 2009 FOSS4G Tokyo &amp; Osaka workshop entitled, &quot;<a href=\"http://www.google.com/url?sa=t&amp;source=web&amp;ct=res&amp;cd=7&amp;ved=0CCMQFjAG&amp;url=http%3A%2F%2Fwww.osgeo.jp%2Fwordpress%2Fwp-content%2Fuploads%2F2009%2F11%2Fworkshop_manual.pdf&amp;ei=4vdLS63EKIGSsgPFrsGIDA&amp;usg=AFQjCNEoTXqRqtS8fpDXbNLo6H2Nk3cEyg&amp;sig2=RLw7qVqUev7k8pdvzCjXeQ\">FOSS4G routing with pgRouting tools and OpenStreetMap road data.</a>&quot; Although my installation on Ubuntu Netbook Remix (UNR) 9.10 required a little different setup, this guide definitely got me 99% of the way there.</p>\n<p>The majority of my installation woes were caused by the different pathways used on my UNR install of PostgreSQL vs. what are apparently the standard paths.</p>\n<p>After attempting to execute cmake to compile pgRouting, I'd be presented with an error stating that the 'POSTGRESQL_INCLUDE_DIR' was not found. A locate command pointed me to the correct path for my PostgreSQL installation. By modifying the FindPostgreSQL.cmake file to search for the correct path, I was back in business.</p>\n<p>Following the workshop instructions, I then attempted to create the database directly from the terminal, which yielded the following result.</p>\n<p>[sourcecode language=&quot;bash&quot;]matt@matt-netbook:~$ createdb -U postgres routing\ncreatedb: could not connect to database postgres: could not connect to server: No such file or directory\nIs the server running locally and accepting\nconnections on Unix domain socket &quot;/var/run/postgresql/.s.PGSQL.5432&quot;?[/sourcecode]</p>\n<p>After reading the documentation associated with &quot;createdb&quot;, i tried adding the &quot;-h&quot; flag pointing to &quot;localhost&quot;, which solved the problem.</p>\n<p>The final error which I ran into had to do with the &quot;$libdir&quot; environment variable. While trying to register the pgRouting functions in my new database, I'd be presented with the following:</p>\n<p>[sourcecode language=&quot;bash&quot;]psql:/usr/share/postlbs/routing_core.sql:32: ERROR: could not access file &quot;$libdir/librouting&quot;: No such file or directory\npsql:/usr/share/postlbs/routing_core.sql:43: ERROR: could not access file &quot;$libdir/librouting&quot;: No such file or directory\npsql:/usr/share/postlbs/routing_core.sql:53: ERROR: could not access file &quot;$libdir/librouting&quot;: No such file or directory[/sourcecode]</p>\n<p>Getting impatient at this point (i wanted to route!) I modified the SQL files to reference the explicit path of my PostgreSQL lib directory. Once that was done, I had a working routing database!</p>\n<p>Loading the sample data, creating the indexes, and executing the queries was amazingly straightforward. To test visualizing the data, I exported one of the tutorial queries directly into a new table.</p>\n<p>[sourcecode language=&quot;SQL&quot;]SELECT * INTO export\nFROM dijkstra_sp('ways', 10, 20);[/sourcecode]</p>\n<p>[caption id=&quot;attachment_316&quot; align=&quot;alignnone&quot; width=&quot;300&quot; caption=&quot;The route depicted in red as seen in QGIS.&quot;]<a href=\"http://www.mkgeomatics.com/wordpress/wp-content/uploads/2010/01/qgis_routing.png\"><img src=\"http://www.mkgeomatics.com/wordpress/wp-content/uploads/2010/01/qgis_routing-300x175.png\" alt=\"qgis_routing\"></a>[/caption]</p>\n<p>Just for kicks, I tried exporting the data as GeoJSON and visualzing it via OpenLayers.</p>\n<p>The following SQL query aggregates the exported line segments into a single GeoJSON object:</p>\n<p>[sourcecode language=&quot;SQL&quot;]SELECT ST_AsGeoJSON(ST_UNION(the_geom)) AS geom_union\nFROM export;[/sourcecode]</p>\n<p>Using the <a href=\"http://openlayers.org/dev/examples/vector-formats.html\">vector-formats</a> OL example, which displays GeoJSON in either EPSG 4326 or 102113, I was able to visualize the line segment with no problem.</p>\n<p>[caption id=&quot;attachment_317&quot; align=&quot;alignnone&quot; width=&quot;300&quot; caption=&quot;GeoJSON representation of line segment generated using pgRouting, displayed in OpenLayers&quot;]<a href=\"http://www.mkgeomatics.com/wordpress/wp-content/uploads/2010/01/openlayers_vector_formats.png\"><img src=\"http://www.mkgeomatics.com/wordpress/wp-content/uploads/2010/01/openlayers_vector_formats-300x175.png\" alt=\"\"></a>[/caption]</p>\n<p>Well that's all for one day. So it looks like the bike riding app is out, but I'm sure that there will be many more interesting ideas for pgRouting that will come to mind as I continue to explore PostGIS.</p>\n",
			"date_published": "2010-01-11T00:00:00Z"
		}
		,
		{
			"id": "https://mattmakesmaps.com/blog/2009-04-27-esri-uc-student-assistant-sweet/",
			"url": "https://mattmakesmaps.com/blog/2009-04-27-esri-uc-student-assistant-sweet/",
			"title": "ESRI UC Student Assistant, Sweet!",
			"content_html": "<p>Just found out that I'll be participating in the 2009 ESRI UC as a student assistant. Big thanks go out to <a href=\"http://geography.asu.edu/balling\">Dr. Robert Balling</a> and <a href=\"http://www.spatiallyadjusted.com/\">James Fee</a>, who both wrote letters of recommendation for me.</p>\n<p>Now to get back to more pressing matters, like refactoring this giant wad o' javascript. <!-- more --></p>\n<p>See you in San Deigo!</p>\n",
			"date_published": "2009-04-27T00:00:00Z"
		}
		,
		{
			"id": "https://mattmakesmaps.com/blog/2009-04-22-visualizing-an-existing-mysql-database/",
			"url": "https://mattmakesmaps.com/blog/2009-04-22-visualizing-an-existing-mysql-database/",
			"title": "Visualizing An Existing MySQL Database",
			"content_html": "<p>So I've been working for about a month with a fairly-normalized (53-table) database in which I draw out all kinds of tabular information, and display it in a spatial context. This has required the numerous multiple table joins, with all kinds of weird relationships... you know, the kind that usually don't work out very well? <!-- more --></p>\n<p>In any event, my SOP for handling these queries was to submit sample data through the codeigniter site that our project's web developer has been courageously firing away at. In this sense, I'd sort-of trace the flow of new information through the various tables of the database, monitoring the information stream as best as I could. I thought to myself, that there has to be a better way to handle this stuff! In comes the <a href=\"http://dev.mysql.com/workbench/\">MySQL Workbench</a>. This handy tool from the <a href=\"http://dev.mysql.com/\">MySQL Dev Zone</a> apparently comes in two flavors: FOSS and commercial.</p>\n<p>The free version served my visualization needs perfectly. The layout of the program is very solid. I was easily able to take an SQL export of the existing database and import it into the Workbench, through a tool they call 'Reverse Engineer MySQL Create Script'. Once the schema has been injected into the program, a model can be automatically created containing all of the tables as well as relationships. The auto-layout feature however, leaves a lot to be desired.</p>\n<p>[caption id=&quot;attachment_293&quot; align=&quot;alignnone&quot; width=&quot;300&quot; caption=&quot;Above: Automatic Layout Results, Snazzy!&quot;]<a href=\"http://www.mkgeomatics.com/wordpress/wp-content/uploads/2009/04/initial_layout.jpeg\"><img src=\"http://www.mkgeomatics.com/wordpress/wp-content/uploads/2009/04/initial_layout-300x189.jpg\" alt=\"Above: Automatic Layout Results, Snazzy!\"></a>[/caption]</p>\n<p>After about twenty-minutes of fooling with the table graphics, a usable layout can be produced. One feature that I think is really convenient, but will never use, is the automatic setting of the diagram width and height based on numbers of pages. This is useful for those who need a quick-print out of their database for whatever reason.</p>\n<p>[caption id=&quot;attachment_292&quot; align=&quot;alignnone&quot; width=&quot;300&quot; caption=&quot;Above: Workbench w/ Completed Diagram&quot;]<a href=\"http://www.mkgeomatics.com/wordpress/wp-content/uploads/2009/04/workspace.jpeg\"><img src=\"http://www.mkgeomatics.com/wordpress/wp-content/uploads/2009/04/workspace-300x187.jpg\" alt=\"Above: Workbench w/ Completed Diagram\"></a>[/caption]</p>\n<p>The real benefit for me however, is the automatic highlighting of key values linking tables together. I'm now able to quickly work my way from the table I need to get to, drilling backwards until I see the table I need to start with.</p>\n<p>[caption id=&quot;attachment_294&quot; align=&quot;alignnone&quot; width=&quot;300&quot; caption=&quot;Above: Automatically Highlight The Key Fields Between Two Tables.&quot;]<a href=\"http://www.mkgeomatics.com/wordpress/wp-content/uploads/2009/04/linking_tables.jpeg\"><img src=\"http://www.mkgeomatics.com/wordpress/wp-content/uploads/2009/04/linking_tables-300x147.jpg\" alt=\"Above: Automatically Highlight The Key Fields Between Two Tables.\"></a>[/caption]</p>\n",
			"date_published": "2009-04-22T00:00:00Z"
		}
		,
		{
			"id": "https://mattmakesmaps.com/blog/2009-04-08-metacartas-map-rectifier-esri-devsummit-mashup-winner/",
			"url": "https://mattmakesmaps.com/blog/2009-04-08-metacartas-map-rectifier-esri-devsummit-mashup-winner/",
			"title": "MetaCarta&#39;s Map Rectifier + ESRI DevSummit Mashup Winner :)",
			"content_html": "<p>I never knew about the <a href=\"http://labs.metacarta.com/rectifier/\">MetaCarta Labs' Map Rectifier</a> tool, but I'll expect to be using it more in the future. After uploading an image to the site, a user has full control over the creation of Ground Control Points. The advanced nature of this tool is shown though included RMS error reporting as well as the choice between multiple transformation algorithms. <!-- more --> In addition to uploading your own content, a user has the ability to add GCPs for other users' uploads as well.</p>\n<p><code>Archived Post. Image Removed.</code></p>\n<p>What's really amazing is the ability to directly access rectified images via WMS overlay. Each image hosted on the site is given a unique URL, we can insert into our favorite web mapping clients.</p>\n<p>To try it out, I used the <a href=\"http://resources.esri.com/arcgisserver/apis/javascript/gmaps/index.cfm?fa=codeGalleryDetails&amp;scriptID=16067\">ExtMap - Mashup Framework</a> developed by ArcGIS user <a href=\"http://resources.esri.com/arcgisserver/apis/javascript/gmaps/index.cfm?fa=codeGallery&amp;authorID=alperdincer\">alperdincer</a>. This particular application framework was one of the winners at 2009 ESRI DevSummit, with good reason. I was able to quickly pass in the MetaCarta Labs URL, allowing the ExtMap application to consume and display the WMS layer with ease.</p>\n<p><code>Archived Post. Image Removed.</code></p>\n<p>In addition to WMS layers, we can add in KML/GeoRSS as well as ArcGIS Server Dynamic/Tiled Map Layers.</p>\n<p><code>Archived Post. Image Removed.</code></p>\n<p>Easy as pie? Piece of Cake? Yes. It's innovative projects like these that keep pushing me to learn more about web mapping technology. Big thanks go out to crschmidt (who i assumed was involved w/ the project) at MetaCarta and <a href=\"http://resources.esri.com/arcgisserver/apis/javascript/gmaps/index.cfm?fa=codeGallery&amp;authorID=alperdincer\">alperdincer</a> for putting together two great products.</p>\n<p>On a final note, the MetaCarta Rectifier has the ability to export out images as geotiffs, allowing us to consume them in our desktop GIS applications. A quick check in ArcCatalog of the Chernobyl sample image I exported out revealed a WGS84 GCS. I can see some really nice workflows combining this tool with tiling programs such as <a href=\"http://www.klokan.cz/projects/gdal2tiles/\">GDAL2Tiles</a> for painless TMS creation.</p>\n",
			"date_published": "2009-04-08T00:00:00Z"
		}
		,
		{
			"id": "https://mattmakesmaps.com/blog/2009-04-07-cloudmade-tile-request-graphics/",
			"url": "https://mattmakesmaps.com/blog/2009-04-07-cloudmade-tile-request-graphics/",
			"title": "CloudMade Tile Request Graphics",
			"content_html": "<p>I just found a neat feature from CloudMade, a <a href=\"http://maps.cloudmade.com/stats/tile_requests\">heat map</a> showing intensity of their tile requests at each zoom scale. As can be expected, Europe and North America are the definite zones of high activity. It's also interesting to note the high activity in other regions such as Chile and the Philippines. <!-- more --></p>\n<p>[caption id=&quot;attachment_272&quot; align=&quot;alignnone&quot; width=&quot;300&quot; caption=&quot;Above: CloudMade's Tile Request Graphic&quot;]<a href=\"http://www.mkgeomatics.com/wordpress/wp-content/uploads/2009/04/cm_tile_request.jpg\"><img src=\"http://www.mkgeomatics.com/wordpress/wp-content/uploads/2009/04/cm_tile_request-300x187.jpg\" alt=\"Above: CloudMade's Tile Request Overlay\"></a>[/caption]</p>\n<p>Following the link to the <a href=\"http://maps.cloudmade.com/javascripts/stats/cloudmade.js?1238766232\">stats JavaScript</a>, it looks like they are using a custom OpenLayers layer class, OpenLayers.Layer.Cloudmade. Sweet!</p>\n",
			"date_published": "2009-04-07T00:00:00Z"
		}
		,
		{
			"id": "https://mattmakesmaps.com/blog/2009-04-05-spatiallite-my-first-look/",
			"url": "https://mattmakesmaps.com/blog/2009-04-05-spatiallite-my-first-look/",
			"title": "SpatialLite: My First Look",
			"content_html": "<p>With such a small footprint (a single file) <a href=\"http://www.gaia-gis.it/spatialite/\">SpatialLite</a> appears to a novice like myself to be a fantastic niche storage solution for spatial data. In an environment where installing larger FOSS databases such as MySQL or PostGIS/PostgreSQL can be prohibitive, Spatial Lite appears to provide a great solution. Using the provided GUI interface, <!-- more --> it's extremely easy for a first-time user to create an sqllite dbase, load multiple shapefiles, and create spatial indexes against them. Analogous to a FOSSGIS ESRI Geodatabase, I can see a lot of potential uses for GIS developers who require the indexing and searching power of a database as well as the portability of formats such as an ESRI Shapefile or KML.</p>\n<p>It looks like a <a href=\"http://geobabble.wordpress.com/2009/03/26/spatiallite-support-in-qgis/\">QGIS connection</a> is in the works for the 1.1 release as well.</p>\n<p>I'm not sure if it's already being done, but I'd bet that it would be pretty easy to put together a SpatialLite / <a href=\"http://featureserver.org/\">FeatureServer</a> combination, considering its native support for so many spatial-backends.</p>\n<p>Some tutorials I've found to be very helpful have come from: <a href=\"http://www.bostongis.com/PrinterFriendly.aspx?content_name=spatialite_tut01\">BostonGIS</a> and the <a href=\"http://www.gaia-gis.it/spatialite/spatialite-2.2_tutorial.html\">SpatialLite project site</a>.</p>\n",
			"date_published": "2009-04-05T00:00:00Z"
		}
		,
		{
			"id": "https://mattmakesmaps.com/blog/2009-03-13-arcgis-rest-api-openlayers-unit-testing-fun-in-the-sun/",
			"url": "https://mattmakesmaps.com/blog/2009-03-13-arcgis-rest-api-openlayers-unit-testing-fun-in-the-sun/",
			"title": "ArcGIS REST API / OpenLayers / Unit Testing = Fun In The Sun",
			"content_html": "<p>Until today, I had never truly appreciated the value of unit testing. I recently had the need to bring <a href=\"http://dev.openlayers.org/sandbox/august/openlayers/openlayers-2.6/examples/ags/index.html\">these ArcGIS REST controls</a>, designed for version 2.6 of OpenLayers, into the current development version. Having no real idea how to get started on this process, I looked to the unit tests as a guide <!-- more --> to what needed to be changed. One might be asking why this was necessary, when the team over at Avencia just put together a great <a href=\"http://trac.openlayers.org/ticket/1749\">ArcGIS REST Plugin</a> that has made its way into the trunk for the upcoming 2.8 release. The answer is that both plugins do different things well. The older AGSControls can perform 'Identify' and 'Geoprocessing' operations rather well, while the Avencia plugin does a great job at displaying and querying a subset of a layer resource.</p>\n<p>In any event, the <a href=\"http://straytree.com/TestAnotherWay/doc/index.html\">Test.AnotherWay</a> suite, used by OpenLayers, provides an easy-to-navigate interface for debugging javascript code.</p>\n<p>In two steps I was able to begin the debugging process.</p>\n<p>First, adding the unit test for the AGSControl to the 'list-tests.html' file located in the 'tests' folder of a development version of OpenLayers. This unit test, written by the developer, needs to manually downloaded and incorporated into the standard series of tests that come with OpenLayers. As we can see from the image below, this particular test was written as an html file and placed into the 'Control' sub-directory of the 'tests' directory.</p>\n<p>[caption id=&quot;attachment_256&quot; align=&quot;alignnone&quot; width=&quot;224&quot; caption=&quot;Above: Adding a link to the unit test for use by Test.AnotherWay&quot;]<a href=\"http://www.mkgeomatics.com/wordpress/wp-content/uploads/2009/03/list_test.png\"><img src=\"http://www.mkgeomatics.com/wordpress/wp-content/uploads/2009/03/list_test.png\" alt=\"Adding a link to the unit test for use by Test.AnotherWay\"></a>[/caption]</p>\n<p>After adding the test, we open up 'run-tests.html' in the browser and select 'AgsControl' from the list. After the test has executed, the results are provided to us. With the red light of failure burning bright, we might think to abandon all hope. We are, however, given the cause and location of the failure, an invaluable clue as to where to start debugging. Time to soldier on.</p>\n<p>[caption id=&quot;attachment_257&quot; align=&quot;alignnone&quot; width=&quot;300&quot; caption=&quot;Above: Unit Test Failure&quot;]<a href=\"http://www.mkgeomatics.com/wordpress/wp-content/uploads/2009/03/ags_fail.png\"><img src=\"http://www.mkgeomatics.com/wordpress/wp-content/uploads/2009/03/ags_fail-300x98.png\" alt=\"Above: Unit Test Failure\"></a>[/caption]</p>\n<p>Using these test results as a road map, even I can eventually debug a plugin. The green light of success offers a reassuring reminder that all is well in the GIS world.</p>\n<p>[caption id=&quot;attachment_259&quot; align=&quot;alignnone&quot; width=&quot;300&quot; caption=&quot;Above: Successful Unit Test&quot;]<a href=\"http://www.mkgeomatics.com/wordpress/wp-content/uploads/2009/03/ags_success1.png\"><img src=\"http://www.mkgeomatics.com/wordpress/wp-content/uploads/2009/03/ags_success1-300x112.png\" alt=\"Above: Successful Unit Test\"></a>[/caption]</p>\n<p>I've taken away a few things from this experience. Firstly, I'm again deeply impressed by the time and effort that developers in the Open Source community are putting into these projects. The only reason that I could even dream of modifying any of this source code is due to the fact that the developer of the AGSControls provided such detailed unit tests. These allowed me to wrap my brain around what was going on with the code, and how it could be updated. Taking the time to not only write code, but to also provide tools so that others can understand it and modify it with ease is something that I think I'll always be impressed with. And of course, I'll be continuing to rely on unit tests as debugging tools as i continue my exploration of javascript programming.</p>\n<p>In the words of <a href=\"http://www.davebouwman.net/\">Dave Bouwman</a>, who has a whopping fourteen posts in his tag cloud on the subject:</p>\n<blockquote>\n<p>Unit testing is quite possibly the single best practice for ensuring that your code is bug free (or very nearly bug free!).</p>\n</blockquote>\n<p>His 'fundamentals' article provides a great introduction on the subject: which can be read <a href=\"http://www.davebouwman.net/fundamentals/unittesting.aspx\">here</a>.</p>\n",
			"date_published": "2009-03-13T00:00:00Z"
		}
		,
		{
			"id": "https://mattmakesmaps.com/blog/2009-01-31-google-motion-charts-from-data-to-information/",
			"url": "https://mattmakesmaps.com/blog/2009-01-31-google-motion-charts-from-data-to-information/",
			"title": "Google Motion Charts: From Data To Information ",
			"content_html": "<p>I've been playing with the motion chart gadget in Google's AJAX API Playground recently, and have found it to be an extremely interesting tool to use. In order to produce data rich charts, all that is necessary is to import a tabular datasheet into google docs and call on it within a javascript function. <!-- more --></p>\n<p>The spreadsheet itself requires:</p>\n<ul>\n<li>\n<p>The first column be entity data (place names, events, etc.)</p>\n</li>\n<li>\n<p>The second column to be formatted as 'Date'</p>\n</li>\n<li>\n<p>The third and following columns to contain your chart-worthy data.</p>\n</li>\n</ul>\n<p>A simple example can be found below depicting historical weather station information for three cities in the Western United States. This information was downloaded from the <a href=\"http://www.wrcc.dri.edu/\">Western Regional Climate Center</a> and imported manually into a <a href=\"http://spreadsheets.google.com/ccc?key=pPDD5D7AqVH0jefmgJwF9OQ\">google docs spreadsheet</a>. As we can see, we have a variety of different ways to explore the data, and hopefully, synthesize them into useful information for decision makers in a best case scenario.</p>\n<p>Above: Markers indicate the cities in which weather station data was collected.</p>\n<p>Above: Google Motion Chart Gadget. NOTE: The data are actually compiled monthly averages from 1971-2000. For the sake of simplicity however, i fed the date column in a format of 'Jan-1' which turns out automatically appends the current year. The proper date should read for example, '1/1' rather than '1/1/09'.</p>\n<p>In any event, in a data rich GIS environment, we can easily succumb to 'data overload'. This creates a barrier for decision makers in understanding their situations, and as such can lead to poor planning. Through the careful use of data visualization tools such as this, however, decision makers can be empowered to quickly analyze data in a variety of ways, creating useful information on-the-fly and without the use of specialized GIS technical know-how.</p>\n<p>At least I think that's how it works.</p>\n",
			"date_published": "2009-01-31T00:00:00Z"
		}
		,
		{
			"id": "https://mattmakesmaps.com/blog/2009-01-24-osm-minutely-tile-updates-thanks-cloudmade/",
			"url": "https://mattmakesmaps.com/blog/2009-01-24-osm-minutely-tile-updates-thanks-cloudmade/",
			"title": "OSM &#39;Minutely&#39; Tile Updates: Thanks CloudMade!",
			"content_html": "<p>Another great OSM Mapping Party is underway in Tempe Arizona. Brandon of <a href=\"http://www.cloudmade.com/\">CloudMade</a> came out to run the show, with local hosting by <a href=\"http://www.spatiallyadjusted.com/\">James Fee</a> of RSP Architects. Coffee, pizza, libations, and Open Source GIS provided a great foundation for lively discussion on the practical and philosophical aspects that OpenStreetMaps provides. <!-- more --></p>\n<p>Of particular interest was a question posed by a first time OSM'er, who wondered why we had to wait a week for the tiles to render, just to see the results of some type of experiment that we might be trying out in the digitization and attribution of features in the map. Well, no one could really give him a good answer other then, 'it's just the way it is'.</p>\n<p>It appears though, that CloudMade has provided us with an answer just the other day. The <a href=\"http://matt.sandbox.cloudmade.com/\">Minutely Updated Tile Server</a> is updated 'every minute from OpenStreetMap diffs'. The results can be seen below. The first image depicts the standard weekly update view while the bottom image depicts the minutely render. Note the presence of the additional buildings on ASU's Tempe Campus.</p>\n<p>[caption id=&quot;attachment_241&quot; align=&quot;alignnone&quot; width=&quot;300&quot; caption=&quot;Above: OSM Weekly Update&quot;]<a href=\"http://www.mkgeomatics.com/wordpress/wp-content/uploads/2009/01/weekly.jpeg\"><img src=\"http://www.mkgeomatics.com/wordpress/wp-content/uploads/2009/01/weekly-300x242.jpg\" alt=\"Above: OSM Weekly Update\"></a>[/caption]</p>\n<p>[caption id=&quot;attachment_242&quot; align=&quot;alignnone&quot; width=&quot;300&quot; caption=&quot;Above: CloudMade's Minutely Updated Tile Server for OSM&quot;]<a href=\"http://www.mkgeomatics.com/wordpress/wp-content/uploads/2009/01/minutely.jpeg\"><img src=\"http://www.mkgeomatics.com/wordpress/wp-content/uploads/2009/01/minutely-300x240.jpg\" alt=\"Above: CloudMade's Minutely Updated Tile Server for OSM\"></a>[/caption]</p>\n<p>Check out the full post from CloudMade's blog here: <a href=\"http://blog.cloudmade.com/2009/01/23/nearly-live-tiles/\">http://blog.cloudmade.com/2009/01/23/nearly-live-tiles/</a></p>\n",
			"date_published": "2009-01-24T00:00:00Z"
		}
		,
		{
			"id": "https://mattmakesmaps.com/blog/2009-01-20-geocoding-with-openlayers-a-crash-course-in-firebug/",
			"url": "https://mattmakesmaps.com/blog/2009-01-20-geocoding-with-openlayers-a-crash-course-in-firebug/",
			"title": "Geocoding with OpenLayers: A Crash Course In Firebug",
			"content_html": "<p>The vacation is over. A new job and a new semester are already providing plenty of opportunities to explore those crazy technologies of the geoweb.</p>\n<p>A need to incorporate the <a href=\"http://developer.yahoo.com/maps/rest/V1/geocode.html\">Yahoo Geocoder</a> into a new OpenLayers app has proved to be a great learning experience in the navigation of the development version of OL. <!-- more --> The <a href=\"http://trac.openlayers.org/ticket/1784\">YahooGeocoder.js</a> addin, created by OL community member, 'sbenthall', requires two prerequisites to run: A <a href=\"http://trac.openlayers.org/wiki/FrequentlyAskedQuestions#ProxyHost\">proxy.cgi script</a> as well as a Yahoo Developer API key. Why would this RESTful service require a proxy, you might find yourself asking? Well, because even though you can query it in a RESTful fashion, the data is returned in an XML shell, requiring a proxy to allow complete the XMLHttpRequest. Yahoo has a great article for novice web programmers like myself explaining the role of Web Proxies, which can be found <a href=\"http://developer.yahoo.com/javascript/howto-proxy.html\">here</a>.</p>\n<p>A quick overview of the primary steps to add the YahooGeocoder.js addin are as follows:</p>\n<ol>\n<li>\n<p>Sign up for a Yahoo APP Key to enable access to their geocoding service.</p>\n</li>\n<li>\n<p>Add the proxy.cgi script to your webserver's 'cgi-bin'. Note: When navigating to the proxy.cgi's url, you might encounter, 'access denied' errors. If you do, make sure that you have the proper permissions set for your cgi-bin directory. This can be done using the terminal command, 'chmod 755' targeting cgi-bin directory.</p>\n</li>\n<li>\n<p>Edit the proxy.cgi script to include 'local.yahooapis.com' in the list of 'allowedHosts'.</p>\n</li>\n</ol>\n<p>[caption id=&quot;attachment_228&quot; align=&quot;alignnone&quot; width=&quot;300&quot; caption=&quot;Above: Modified 'proxy.cgi'&quot;]<a href=\"http://www.mkgeomatics.com/wordpress/wp-content/uploads/2009/01/proxy_hosts.png\"><img src=\"http://www.mkgeomatics.com/wordpress/wp-content/uploads/2009/01/proxy_hosts-300x54.png\" alt=\"proxy_hosts\"></a>[/caption]</p>\n<ol start=\"4\">\n<li>\n<p>Add the YahooGeocoder.js file to the OpenLayers 'lib/OpenLayers/Control' folder.</p>\n</li>\n<li>\n<p>Add &quot;OpenLayers/Control/YahooGeocoder.js&quot; to the variable array, 'jsfiles' inside the &quot;lib/OpenLayers.js&quot; library.</p>\n</li>\n</ol>\n<p>[caption id=&quot;attachment_229&quot; align=&quot;alignnone&quot; width=&quot;300&quot; caption=&quot;Above: Modified 'lib/OpenLayers.js'&quot;]<a href=\"http://www.mkgeomatics.com/wordpress/wp-content/uploads/2009/01/control_add.png\"><img src=\"http://www.mkgeomatics.com/wordpress/wp-content/uploads/2009/01/control_add-300x149.png\" alt=\"control_add\"></a>[/caption]</p>\n<ol start=\"6\">\n<li>Test the geocoder's functionality using the supplied .HTML file. (Hopefully it should work!)</li>\n</ol>\n<p>[caption id=&quot;attachment_230&quot; align=&quot;alignnone&quot; width=&quot;300&quot; caption=&quot;Above: Geocoder Result with Properly Formed XML Response.&quot;]<a href=\"http://www.mkgeomatics.com/wordpress/wp-content/uploads/2009/01/good_xml_return1.png\"><img src=\"http://www.mkgeomatics.com/wordpress/wp-content/uploads/2009/01/good_xml_return1-300x217.png\" alt=\"good_xml_return1\"></a>[/caption]</p>\n<p>Six simple steps, but it can be challenging if you haven't tried to install any addins to the OL library before.</p>\n<p>In the above image, the firebug window can be seen returning a properly formed XML Response, having successfully executed the geocoding function. If you enlarge the image, we can compare this to the raw XML-Response using a properly constructed query. Note in both the response captured from firebug (above) as well as the raw XML (below) the presence of the address: 510 High Street, Bellingham WA, broken down into it's individual units along with the geocoded result.</p>\n<p>[caption id=&quot;attachment_231&quot; align=&quot;alignnone&quot; width=&quot;300&quot; caption=&quot;Above: Basic XML Return&quot;]<a href=\"http://www.mkgeomatics.com/wordpress/wp-content/uploads/2009/01/basic_xml.png\"><img src=\"http://www.mkgeomatics.com/wordpress/wp-content/uploads/2009/01/basic_xml-300x221.png\" alt=\"basic_xml\"></a>[/caption]</p>\n<p>Further diving into the capabilities of firebug, we can use the DOM inspector to ensure that the various parameters required to properly execute the Yahoo Geocoder are in place. Note in the image below the presence of such necessary information as the APP ID Key, Projection, and Class, for the ygc variable. If any of these parameters happened to be incorrectly set, it would be displayed in this view.</p>\n<p>[caption id=&quot;attachment_232&quot; align=&quot;alignnone&quot; width=&quot;300&quot; caption=&quot;Above: The Firebug DOM Inspector&quot;]<a href=\"http://www.mkgeomatics.com/wordpress/wp-content/uploads/2009/01/dom_inspector.png\"><img src=\"http://www.mkgeomatics.com/wordpress/wp-content/uploads/2009/01/dom_inspector-300x91.png\" alt=\"dom_inspector\"></a>[/caption]</p>\n<p>I'm finally starting to appreciate the power of firebug as a development tool, which just so happens to coincide with my ability to understand it at a basic level. Hopefully as my experience in GIS Web Development grows, so will be ability to use the higher-end functions of this tool.</p>\n",
			"date_published": "2009-01-20T00:00:00Z"
		}
		,
		{
			"id": "https://mattmakesmaps.com/blog/2008-12-20-tms-shaded-relief-for-osm-data-an-adventure-and-a-12/",
			"url": "https://mattmakesmaps.com/blog/2008-12-20-tms-shaded-relief-for-osm-data-an-adventure-and-a-12/",
			"title": "TMS: Shaded Relief for OSM Data (An Adventure and A 1/2)",
			"content_html": "<p>After reading <a href=\"http://stamen.com/\">Michal Migurski's</a> excellent post, '<a href=\"http://mike.teczno.com/notes/hillshading.html\">making friends with hillshading</a>' I decided to try my own hand at producing a TMS-compatible hillshade layer for OSM. Motivated by both the high resolution LiDAR data which I happen to have access to, and the lack of access to ArcDesktop during the winter intersession... I set out on the FOSSGIS path. <!-- more --></p>\n<p>[caption id=&quot;attachment_205&quot; align=&quot;alignnone&quot; width=&quot;259&quot; caption=&quot;The resulting overlay&quot;]<a href=\"http://www.mkgeomatics.com/apps/openlayers/tiles/ol_working.html\"><img src=\"http://www.mkgeomatics.com/wordpress/wp-content/uploads/2008/12/picture-1-259x300.png\" alt=\"The resulting overlay\"></a>[/caption]</p>\n<p>The final output was created in a primarily two-step process. The hillshade was created using Matt Perry's <a href=\"http://www.perrygeo.net/wordpress/?p=7\">GDAL DEM tools</a>. This command line addition to the GDAL suite of tools negated having to import the DEM into a new GRASS location, and exporting the resulting hillshade back out as another format.</p>\n<p>The majority of the work, the tiling that is, was done using <a href=\"http://www.klokan.cz/projects/gdal2tiles/\">GDAL2Tiles</a>. This Google Summer of Code project operates under a command line utility which will take your slick GDAL-compatible raster dataset as input, and export a set of tiles exactly to your specs. What's more is the capability to automatically generate google maps and OpenLayers viewing pages which can be directly uploaded to a webspace.</p>\n<p>Finally, applying a slight transparency to the OSM layer allowed for the shaded relief to appear from behind. Quick-and-Dirty, <a href=\"http://mkgeomatics.com/apps/openlayers/tiles/ol_working.html\">but it works</a>!</p>\n<p>The pain came when trying to compare the local TMS overlay using OSM vs. Google Maps base data. While using Google Maps street data, we clearly see the LiDAR building footprints align with the vector street centerlines. But switching over to OSM data, we see a drastic skew between the two.</p>\n<p>[caption id=&quot;attachment_206&quot; align=&quot;alignnone&quot; width=&quot;300&quot; caption=&quot;Google Street Data: Properly Aligned Local TMS&quot;]<a href=\"http://www.mkgeomatics.com/wordpress/wp-content/uploads/2008/12/picture-21.png\"><img src=\"http://www.mkgeomatics.com/wordpress/wp-content/uploads/2008/12/picture-21-300x209.png\" alt=\"Google Street Data: Properly Aligned Local TMS\"></a>[/caption]</p>\n<p>[caption id=&quot;attachment_209&quot; align=&quot;alignnone&quot; width=&quot;300&quot; caption=&quot;OSM Data: Note Hawaii Belt Road's location compared to its LiDAR footprint.&quot;]<a href=\"http://www.mkgeomatics.com/wordpress/wp-content/uploads/2008/12/picture-4.png\"><img src=\"http://www.mkgeomatics.com/wordpress/wp-content/uploads/2008/12/picture-4-300x297.png\" alt=\"OSM Data: Note Hawaii Belt Rd's location compared to its LiDAR footprint.\"></a>[/caption]</p>\n<p>Initially, I assumed that the problem was the result of some projection issues (EPSG: 4326 vs EPSG: 900913), until I realized that all data sets (LiDAR, Google, and OSM) had matching coastlines. Any distortion resulting from the affine transformation between WGS84 and Spherical Mercator would have clearly showed up along the coast as well as the streets.</p>\n<p>A quick look at the <a href=\"http://wiki.openstreetmap.org/wiki/Potlatch\">Potlatch</a> editor revealed the inaccuracy of the TIGER line files used in this section of the map:</p>\n<p>[caption id=&quot;attachment_210&quot; align=&quot;alignnone&quot; width=&quot;300&quot; caption=&quot;Potlatch: TIGER data is a good, but not great.&quot;]<a href=\"http://www.mkgeomatics.com/wordpress/wp-content/uploads/2008/12/potlatch.png\"><img src=\"http://www.mkgeomatics.com/wordpress/wp-content/uploads/2008/12/potlatch-300x273.png\" alt=\"Potlatch: TIGER data is a good, but not great.\"></a>[/caption]</p>\n<p>All-in-all I was extremely impressed with the speed and efficency of using the <a href=\"http://www.perrygeo.net/wordpress/?p=7\">GDAL DEM Tools</a> as well as <a href=\"http://www.klokan.cz/projects/gdal2tiles/\">GDAL2Tiles</a>. Both projects are great representations of what can be done by individuals who choose to build upon existing FOSSGIS projects, and give back to the community.</p>\n<p>Additional Note:\nA GRASS-based approach to creating a TMS layer is possible, and has been outlined in <a href=\"https://mattmakesmaps.com/blog/2008-12-20-tms-shaded-relief-for-osm-data-an-adventure-and-a-12/sunbird.jrc.it/pvgis/doc/paper/2008_OSGeo5_TiledMapServices.pdf\">this paper</a> appearing in the OSGeo Journal.</p>\n",
			"date_published": "2008-12-20T00:00:00Z"
		}
		,
		{
			"id": "https://mattmakesmaps.com/blog/2008-12-08-osm-recap/",
			"url": "https://mattmakesmaps.com/blog/2008-12-08-osm-recap/",
			"title": "OSM Recap",
			"content_html": "<p>What an awesome weekend. There was a good turnout for the Phoenix OSM mapping party, put on by <a href=\"http://www.cloudmade.com/\">CloudMade</a> and hosted locally by <a href=\"http://gangplankhq.com/\">Gangplank</a>. On both days we saw a mixture of GIS professionals and Open Source users come out to support the project. A new neologism to add to the list also came out of the event, 'crowdsourcing'. <!-- more --> The work of many locals who have an inherent expert knowledge of their surrounding environment replacing the work of what would otherwise be performed by a few skilled professionals.</p>\n<p>Here is the result of our work:</p>\n<p>[caption id=&quot;attachment_199&quot; align=&quot;alignnone&quot; width=&quot;300&quot; caption=&quot;Above: ASU Mapping Party&quot;]<a href=\"http://www.mkgeomatics.com/wordpress/wp-content/uploads/2008/12/export.png\"><img src=\"http://www.mkgeomatics.com/wordpress/wp-content/uploads/2008/12/export-300x225.png\" alt=\"ASU Mapping Party\"></a>[/caption]</p>\n<p>In any event, we decided to focus our efforts on ASU's campus for the weekend. Before we went out with GPS units, an OSM'er named 'jfuredy' had actually taken a stab at some rooftop digitization of buildings along campus. I've already noticed that there are inherent conflicts that occur by digitizing from rooftops. Tall buildings of course, will appear oblique, with their roofs offset from their actual footprints. This creates scenarios in which buildings (created from oblique angled rooftops) are overlapping walkways.</p>\n<p>[caption id=&quot;attachment_200&quot; align=&quot;alignnone&quot; width=&quot;215&quot; caption=&quot;Above: Digitization Conflict&quot;]<a href=\"http://www.mkgeomatics.com/wordpress/wp-content/uploads/2008/12/picture-2.png\"><img src=\"http://www.mkgeomatics.com/wordpress/wp-content/uploads/2008/12/picture-2.png\" alt=\"Above: Digitization Conflict\"></a>[/caption]</p>\n<p>I'm excited to continue working on the OSM project, and hope to see more mapping parties in the future. Speaking with <a href=\"http://cloudmade.com/team/brandon-aguirre\">Brandon</a>, our contact at CloudMade, I mentioned that the end of January could be a potential date. This would be the first week of the new semester for MAS-GIS, and hopefully more of the students will come out and support the project!</p>\n",
			"date_published": "2008-12-08T00:00:00Z"
		}
		,
		{
			"id": "https://mattmakesmaps.com/blog/2008-12-04-openstreetmaporg-mapping-party-this-weekend/",
			"url": "https://mattmakesmaps.com/blog/2008-12-04-openstreetmaporg-mapping-party-this-weekend/",
			"title": "OpenStreetMap.org Mapping Party This Weekend",
			"content_html": "<p><a href=\"http://www.meetup.com/OpenStreetMap-Phoenix/\">http://www.meetup.com/OpenStreetMap-Phoenix/</a> It's going to rock. It really is.</p>\n<p>Having just heard of OSM a little over a month ago, and using their tiles for about two weeks now... I'm really excited to give back to the OSM community. In a way, it's a chance for those who have never committed code to a FOSS project (like me) to really add some positive input back <!-- more --> into a community that we are a part of, if only in a small way. But hey, if we are all contributing small bits to the project-at-large... it'll add up. A little '<a href=\"http://en.wikipedia.org/wiki/Neogeography\">neogeography</a>', anyone?</p>\n<p>Additionally, I have put together a small tool to compare the current OSM offerings to that of various commercial mapping vendors (Google, Microsoft VE). Pretty fun exploration of the OpenLayers API!</p>\n<p>Check it out here: <a href=\"http://mkgeomatics.com/apps/openlayers/osm_compare.html\">http://mkgeomatics.com/apps/openlayers/osm_compare.html</a></p>\n<p>[caption id=&quot;attachment_196&quot; align=&quot;alignnone&quot; width=&quot;300&quot; caption=&quot;Above: Quick and Dirty OSM Tool&quot;]<a href=\"http://www.mkgeomatics.com/wordpress/wp-content/uploads/2008/12/osm_tool.jpeg\"><img src=\"http://www.mkgeomatics.com/wordpress/wp-content/uploads/2008/12/osm_tool-300x244.jpg\" alt=\"Above: Quick and Dirty OSM Tool\"></a>[/caption]</p>\n",
			"date_published": "2008-12-04T00:00:00Z"
		}
		,
		{
			"id": "https://mattmakesmaps.com/blog/2008-12-01-stefan-steinger-foss-desktop-gis-overview/",
			"url": "https://mattmakesmaps.com/blog/2008-12-01-stefan-steinger-foss-desktop-gis-overview/",
			"title": "Stefan Steinger - FOSS Desktop GIS Overview",
			"content_html": "<p>Found via the Cascadia Users of Geospatial Open Source (<a href=\"http://groups.google.com/group/cugos\">CUGOS</a>) website.</p>\n<p>Very recent paper accepted by the International Journal of Geographical Information Science depitcs the current state of the art in FOSS Desktop GIS and much more. The staying power in the article however, IMHO, is the detailed explanation of the various FOSS license agreements <!-- more --> which exist and the organisations which play a major role in the development of FOSSGIS as a whole. One of the most interesting tidbits for me was the realization that the Open Geospatial Consortium cannot be equated directly to the FOSSGIS movement.</p>\n<blockquote>\n<p>A couple of people to which we spoke related the activities of the Open Geospatial Consortium (OGC, www.opengeospatial.org) to open source GIS software. This link is not entirely correct, since the OGC is an organisation that develops standards for the processing and exchange of geo-data between different GIS platforms. Furthermore a large portion of the member organisations of the OGC, besides universities and authorities, are companies that develop proprietary GIS and Databases.</p>\n</blockquote>\n<p>Link: <a href=\"http://cugos.googlegroups.com/web/sstein_foss_desktop_gis_overview.pdf\">http://cugos.googlegroups.com/web/sstein_foss_desktop_gis_overview.pdf</a></p>\n",
			"date_published": "2008-12-01T00:00:00Z"
		}
		,
		{
			"id": "https://mattmakesmaps.com/blog/2008-11-30-spherical-mercator-new-portfolio/",
			"url": "https://mattmakesmaps.com/blog/2008-11-30-spherical-mercator-new-portfolio/",
			"title": "Spherical Mercator / New Portfolio",
			"content_html": "<p>In the continuing adventures of my WFS example, I've now added spherical mercator capabilities to the PROJ.4 library, following those instructions <a href=\"http://crschmidt.net/\">Chris Schmidt</a> gave me last week. On the fly reprojection of the data allows for the incorporation of numerous proprietary vendors, such as Google Maps and Microsoft Virtual Earth, as well as open source tile services such as OpenStreetMaps.org. <!-- more --></p>\n<p>[caption id=&quot;attachment_185&quot; align=&quot;alignnone&quot; width=&quot;300&quot; caption=&quot;Above: WFS Spherical Mercator Reprojection with Google Terrain Base Layer&quot;]<a href=\"http://mkgeomatics.com/apps/openlayers/spherical_merc.html\"><img src=\"http://www.mkgeomatics.com/wordpress/wp-content/uploads/2008/11/wfs_spherical-300x298.jpg\" alt=\"Above: WFS Spherical Mercator Reprojection with Google Terrain Base Layer\"></a>[/caption]</p>\n<p>Feel free to check it out: <a href=\"http://mkgeomatics.com/apps/openlayers/spherical_merc.html\">http://mkgeomatics.com/apps/openlayers/spherical_merc.html</a></p>\n<p>In other news, I'm also nearly finished moving my portfolio from WWU's servers to this site. One can click on the Portfolio link to the right, or simply navigate directly to a sub-section if they choose.</p>\n",
			"date_published": "2008-11-30T00:00:00Z"
		}
		,
		{
			"id": "https://mattmakesmaps.com/blog/2008-11-23-scapetoad-open-source-cartogram-generator/",
			"url": "https://mattmakesmaps.com/blog/2008-11-23-scapetoad-open-source-cartogram-generator/",
			"title": "ScapeToad - Open Source Cartogram Generator",
			"content_html": "<p><a href=\"http://chorogram.choros.ch/scapetoad/index.php\">ScapeToad</a> provides an amazingly easy to use interface for creating cartograms. Accepting shapefiles directly as input, it has a wide variety of fine-tunable settings in addition to its presets. The ability to utilize multiple layers as weights also seems like a pretty exciting feature. Written entirely in java, it's platform-independent, another plus for mac and / or linux GIS users. <!-- more --></p>\n<p>[caption id=&quot;attachment_127&quot; align=&quot;alignnone&quot; width=&quot;300&quot; caption=&quot;Above: The counties of Washington State.&quot;]<a href=\"http://www.mkgeomatics.com/wordpress/wp-content/uploads/2008/11/wa.jpeg\"><img src=\"http://www.mkgeomatics.com/wordpress/wp-content/uploads/2008/11/wa-300x202.jpg\" alt=\"WA_Green\"></a>[/caption]</p>\n<p>What is so cool about this program is that not only does it use shapefiles as an input, but it generates shapefiles as output as well. A SizeError attribute is also generated to allow a user to easily control map symbology using GIS software. In addition to this, one can also export as an SVG directly to use in a graphics editor.</p>\n<p>The cartogram below was generated using the percentage of a county's total area covered by state routes. The lighter colors indicate a smaller distortion in size while the darker colors indicate a larger distortion in size. Note the I-5 corridor in Western Washington is heavily affected using this criteria.</p>\n<p>[caption id=&quot;attachment_128&quot; align=&quot;alignnone&quot; width=&quot;300&quot; caption=&quot;Above: The result. &quot;]<a href=\"http://www.mkgeomatics.com/wordpress/wp-content/uploads/2008/11/cartogram2.jpeg\"><img src=\"http://www.mkgeomatics.com/wordpress/wp-content/uploads/2008/11/cartogram2-300x212.jpg\" alt=\"WA_Cartogram\"></a>[/caption]</p>\n<p>ScapeToad - <a href=\"http://chorogram.choros.ch/scapetoad/index.php\">http://chorogram.choros.ch/scapetoad/index.php</a></p>\n<p>Data (WA DOT) - <a href=\"http://www.wsdot.wa.gov/\">http://www.wsdot.wa.gov/</a></p>\n",
			"date_published": "2008-11-23T00:00:00Z"
		}
		,
		{
			"id": "https://mattmakesmaps.com/blog/2008-11-22-attribution-css-and-irc/",
			"url": "https://mattmakesmaps.com/blog/2008-11-22-attribution-css-and-irc/",
			"title": "Attribution, CSS, and IRC",
			"content_html": "<p>I've built up the <a href=\"http://www.mkgeomatics.com/apps/openlayers/WA_WFS_WGS84_query.html\">WFS OpenLayers example</a> I've been working on to now include attribution (by hovering over a feature) as well as a pointless select feature capability. Click away! It won't do anything but, that's fine. <!-- more --></p>\n<p>A different baselayer is also available, <a href=\"http://www.openstreetmap.org/\">openstreetmaps.org</a> (via telascience.org tiles). You may notice that some of these tiles fail to reload upon panning and zooming operations. I asked why this was on the OpenLayers IRC, and was told that these tiles basically suck. I'm stuck using them however, as they are Lat/Long WGS84. OSM Mapnik and Google maps require a spherical mercator projection, and as such PROJ.4 needs to be amended to support this EPSG code so that Mapserver and render properly.</p>\n<p>[caption id=&quot;attachment_121&quot; align=&quot;alignnone&quot; width=&quot;300&quot; caption=&quot;Screenshot of simple WFS example&quot;]<a href=\"http://www.mkgeomatics.com/wordpress/wp-content/uploads/2008/11/wfs_example.jpeg\"><img src=\"http://www.mkgeomatics.com/wordpress/wp-content/uploads/2008/11/wfs_example-300x276.jpg\" alt=\"Screenshot of simple WFS example\"></a>[/caption]</p>\n<p>It <a href=\"http://docs.openlayers.org/spherical_mercator/#mapserver\">looks pretty straightforward</a>, but another project for another day.</p>\n<p>In any event, I've kept the OpenLayers WMS as the primary base layer, which doesn't have display issues.</p>\n",
			"date_published": "2008-11-22T00:00:00Z"
		}
		,
		{
			"id": "https://mattmakesmaps.com/blog/2008-11-21-whew/",
			"url": "https://mattmakesmaps.com/blog/2008-11-21-whew/",
			"title": "whew...",
			"content_html": "<p>This took a 'lot' longer than i expected.</p>\n<p><a href=\"http://www.mkgeomatics.com/apps/openlayers/WA_WFS_WGS84.html\">http://www.mkgeomatics.com/apps/openlayers/WA_WFS_WGS84.html</a></p>\n<p>Calling Mapserver as a WFS layer, displaying with OpenLayers. Many thanks to <a href=\"http://crschmidt.net/\">Chris Schmidt</a> for a quick response on the OL mailing list! <!-- more --></p>\n<p>Currently set to extract attributes in the OL html, but still need to build in the attribute display. A good example of the necessary javascript can be found in the <a href=\"http://openlayers.org/dev/examples/openmnnd.html\">OL Cookbook</a>.</p>\n<p>I also set a quick thank you to Jeff McKenna at <a href=\"http://www.gatewaygeomatics.com/\">Gateway Geomatics</a> for putting together such a great set of UMN Mapserver WFS and WMS tutorials. He actually wrote back! oh FOSS4G, what a nice community.</p>\n",
			"date_published": "2008-11-21T00:00:00Z"
		}
		,
		{
			"id": "https://mattmakesmaps.com/blog/2008-11-19-happy-gis-day/",
			"url": "https://mattmakesmaps.com/blog/2008-11-19-happy-gis-day/",
			"title": "Happy GIS Day.",
			"content_html": "<p>all across the world, little GIS themed cookies and cakes will be consumed...</p>\n",
			"date_published": "2008-11-19T00:00:00Z"
		}
		,
		{
			"id": "https://mattmakesmaps.com/blog/2008-11-18-wms-to-wfs/",
			"url": "https://mattmakesmaps.com/blog/2008-11-18-wms-to-wfs/",
			"title": "WMS To WFS",
			"content_html": "<p>The main goal for today is figuring out what is going on with <a href=\"http://mkgeomatics.com/apps/FWTools-2.0.6/bin_safe/mapserv.cgi?map=/home/matthewkenny/mkgeomatics.com/apps/FWTools-2.0.6/mapdata/WA/WA_NAD83UTM10N.map&amp;MODE=MAP\">my WFS demo</a>. I've got it a Mapserver mapfile up and running, and can load each layer individually by calling the service in either QGIS or ArcGIS. The mapfile was tweaked to WFS metadata specs via this <a href=\"http://mapserver.gis.umn.edu/docs/howto/wfs_server\">extremely helpful tutorial</a>. <!-- more --></p>\n<p>If we take a look at the DescribeFeatureType() results for <a href=\"http://mkgeomatics.com/apps/FWTools-2.0.6/bin_safe/mapserv.cgi?map=/home/matthewkenny/mkgeomatics.com/apps/FWTools-2.0.6/mapdata/WA/WA_WGS84.map&amp;SERVICE=WFS&amp;VERSION=1.0.0&amp;REQUEST=DescribeFeatureType\">my WFS</a> query (I don't know if I should be calling it a WFS at this point, but I will...) we see that no tabular information is being extracted from the shapefiles.</p>\n<blockquote>\n<schema targetNamespace=\"http://mapserver.gis.umn.edu/mapserver\" elementFormDefault=\"qualified\" version=\"0.1\">\n</schema></blockquote>\n<import namespace=\"http://www.opengis.net/gml\" schemaLocation=\"http://schemas.opengis.net/gml/2.1.2/feature.xsd\">\n\n<p>compare this to the DMSolutions WFS DescribeFeatureType() <a href=\"http://www2.dmsolutions.ca/cgi-bin/mswfs_gmap?SERVICE=WFS&amp;VERSION=1.0.0&amp;REQUEST=DescribeFeatureType\">request</a>.</p>\n<blockquote>\n<schema targetNamespace=\"http://www.ttt.org/myns\" elementFormDefault=\"qualified\" version=\"0.1\">\n</schema></blockquote>\n<import namespace=\"http://www.opengis.net/gml\" schemaLocation=\"http://schemas.opengeospatial.net/gml/2.1.2/feature.xsd\">\n<element name=\"prov_land\" type=\"myns:prov_landType\" substitutionGroup=\"gml:_Feature\">\n\n<complexType name=\"prov_landType\">\n\n<complexContent>\n\n<extension base=\"gml:AbstractFeatureType\">\n\n<sequence>\n<element name=\"msGeometry\" type=\"gml:GeometryPropertyType\" minOccurs=\"0\" maxOccurs=\"1\">\n<element name=\"AREA\" type=\"string\">\n<element name=\"PERIMETER\" type=\"string\">\n<element name=\"PROVINCE_\" type=\"string\">\n...\n<p>I'm thinking that there is more work which needs to be done in the mapfile. My guess is that it has to do with the 'gml_featureid' and 'gml_include_items' metadata information.</p>\n<p>whatever's clever.</p>\n</element></element></element></element></sequence></extension></complexContent></complexType></element></import></import>",
			"date_published": "2008-11-18T00:00:00Z"
		}
		,
		{
			"id": "https://mattmakesmaps.com/blog/2008-11-18-wfs/",
			"url": "https://mattmakesmaps.com/blog/2008-11-18-wfs/",
			"title": "WFS!",
			"content_html": "<p>Wow, i actually have a working WFS server now. I was able to successfully use QGIS to call upon the same mapfile using both 'WMS' and 'WFS' service types. As you can see in the image below, a static baselayer, 'COUNTY' (actually a dissolved shp designed to show the physical outline of Washington State) is displayed as WMS layer, as well as WFS layer, 'NATPARK', capable of actually identifiying features. <!-- more --></p>\n<p>[caption id=&quot;attachment_97&quot; align=&quot;alignnone&quot; width=&quot;300&quot; caption=&quot;QGIS Screenshot: Selected feature in yellow, Identified feature in pinkish-outline.&quot;]<a href=\"http://www.mkgeomatics.com/wordpress/wp-content/uploads/2008/11/wfs_identify.jpeg\"><img src=\"http://www.mkgeomatics.com/wordpress/wp-content/uploads/2008/11/wfs_identify-300x221.jpg\" alt=\"wfs_identify\"></a>[/caption]</p>\n<p>I'm amazed at the ability of Mapserver to take a shapefile, turn it into GML, and send it almost magically to ANY program that can interpret it. I'm finally wrapping my noggin around the whole concept of XML, and just how powerful it can be.</p>\n<p>So what were my primary issues? Well, it took me about an hour to realize that I was running my, 'DescribeFeatureType' request on the mapfile entitled 'WA_WGS84.map' rather than 'WA_WFS_WGS84.map'. So that was my own error. Then I realized that while the KEY field for each of these shapefiles in ArcGIS is simply, 'FID', this **cannot **be used for the 'gml_featureid' metadata requirement in the mapfile. Another primary key such as, 'PARKID' must instead be used, and the GML file will actually create its own, 'FID' based on this.</p>\n<p>Some other key lessons from today:</p>\n<ul>\n<li>\n<p>ESRI ArcGIS does not support WFS out of the box, as it does WMS. To enable the GML simple features profile, try out this <a href=\"http://webhelp.esri.com/arcgisdesktop/9.2/index.cfm?id=5607&amp;pid=5604&amp;topicname=Using_the_GML_simple_features_profile\">ESRI Help Article</a>.</p>\n</li>\n<li>\n<p>Querying your WFS server in-browser using the, 'getfeature' and 'getcapabilities' requests is a really simple and effective way of determining which required pieces of information are missing from your XML. Mapserver will actually create a comment in-line saying which required pieces of metadata are missing.</p>\n</li>\n<li>\n<p>Creating metadata abstracts for both WFS and WMS in your mapfile is a simple way to view how your GIS software is consuming the data. For example, the only reason i realized that I was actually using QGIS to display my WFS mapfile as a WMS was through the use both of the &quot;wms_abstract&quot; and &quot;wfs_abstract&quot; metadata tags.</p>\n</li>\n</ul>\n<p>What's next? Wrap an openlayers display around this with selection and identify capabilities.</p>\n",
			"date_published": "2008-11-18T00:00:00Z"
		}
		,
		{
			"id": "https://mattmakesmaps.com/blog/2008-11-16-mapserver-update/",
			"url": "https://mattmakesmaps.com/blog/2008-11-16-mapserver-update/",
			"title": "Mapserver [Update]",
			"content_html": "<p>Well, using the <a href=\"http://openlayers.org/dev/examples/\">OpenLayers Cookbook</a> I've been able to modify OpenLayers to display base data from Google and their own World WMS layer. That is all for now. <!-- more --></p>\n<p>Viewing the source code might not give you too much insight as to what is going on... it's looking pretty haggard at this point. I'll get around to cleaning it up and adding comments (mainly so I can learn something about what is going on, hah).</p>\n",
			"date_published": "2008-11-16T00:00:00Z"
		}
		,
		{
			"id": "https://mattmakesmaps.com/blog/2008-11-15-73/",
			"url": "https://mattmakesmaps.com/blog/2008-11-15-73/",
			"title": "Mapserver Up and Running",
			"content_html": "<p>Well, after about a month of no progress in the Web GIS realm, i've finally got some progress to show! The openlayers map you are looking at below is consuming information from a Mapserver WMS, running on this site. In case you're also wondering, the data being displayed is actually a <a href=\"http://www.cob.org/services/maps/index.aspx\">shapefile</a> of the neighborhoods of beautiful Bellingham, WA. <!-- more --></p>\n<p>This gets me back to where I was as part of my senior GIS project, with the very large exception that the data is being hosted 24/7 on a shared host, rather than an ubuntu-powered laptop on death's door. Well, 'what is the difference?' one might ask. Well, instead of having to tell someone, 'Hey, you interested person, sure you can view my WMS server. I'll turn my laptop on between the hours of 3-5PM. If the connection is slow, it could be because my wi-fi is dropping out. Or maybe because my roommates are playing Halo 3 on Xbox Live? Or maybe I'm watching a movie on netflix?' In any event, reliability is a plus.</p>\n<p>So what got me over this hurtle? Well, it just so happens that instead of compiling all of these programs from the source, you can just install <a href=\"http://fwtools.maptools.org/\">FWTools</a> as an entire package right onto your website. Neat! As Aaron Racicot also pointed out in <a href=\"http://www.mail-archive.com/mapserver-users@lists.umn.edu/msg13520.html\">some post</a>, it's necessary to add the, '.cgi' extension to the mapserv file, as dreamhost (my current hosting choice) requires the extension to be explicitly set.</p>\n<p>This really opens the door to quite a bit of experimentation using OpenLayers and Mapserver together.</p>\n<p>On a final note, compiling all those programs from source has had an added benefit not attainable with FWTools. That is, the use of command-line GRASS. Who knows when they'll be stuck, needing to do some GIS w/o an ArcDesktop install, <em>but</em> with an SSH terminal?</p>\n",
			"date_published": "2008-11-15T00:00:00Z"
		}
		,
		{
			"id": "https://mattmakesmaps.com/blog/2008-10-03-nested-tuples-and-hours-of-patience/",
			"url": "https://mattmakesmaps.com/blog/2008-10-03-nested-tuples-and-hours-of-patience/",
			"title": "Nested Tuples and Hours of Patience",
			"content_html": "<p>I've finally got a working python script that does the following:</p>\n<p>-Reads each of the vertexes of a polyline shapefile using 'OGR'</p>\n<p>-Runs the vertexes through the Douglas-Peucker smoothing algorithm.</p>\n<p>-Generates an output text file using 'stdout' with the resulting 'smoothed' coordinates (in whatever linear unit of measurement that the source shapefile happens to be in).</p>\n<!-- more -->\n<p>This has taken quite awhile to get this far, but it has been an excellent learning experience. The breakthrough for tonight was understanding that the Douglas-Peucker algorithm which I downloaded from mappinghacks required a nested tuple as an input. Basically then, I needed to figure out how translate the extracted vertexes from the source shapefile into the tuple object.</p>\n<p>Things started to go bad, really bad, when I attempted to create formatted output files for the extracted vertexes... and re-import them as input files for the DP algorithm. It's all good now though, and the code looks (a bit) cleaner.</p>\n<p>The next step will be to take this output text file and build another shapefile from it...</p>\n<p>Here is a link to the heavily commented <a href=\"http://www.mkgeomatics.com/scripts/dp_100308.py\">script</a> (right-click, select 'save-as') as it stands thus-far.</p>\n",
			"date_published": "2008-10-03T00:00:00Z"
		}
		,
		{
			"id": "https://mattmakesmaps.com/blog/2008-09-30-im-obsessed-with-douglas-peucker/",
			"url": "https://mattmakesmaps.com/blog/2008-09-30-im-obsessed-with-douglas-peucker/",
			"title": "I&#39;m Obsessed With Douglas-Peucker",
			"content_html": "<p>The Problem: Web map vector overlays take a really long time to load if there are too many verticies.</p>\n<p>The Idea: Use the Douglas-Peucker algorithm to reduce the number of verticies thereby decreasing load time.</p>\n<p>The [Proposed] Solution: Using a version of the Douglas-Peucker algorithm written in Python, input a source shapefile, and output a smoothed shapefile through the following steps. This script currently uses board coordinates, and as such, is not 'spatially' enabled. The trick is to make it except shapefiles as an input source.</p>\n<!-- more -->\n<p>-Extract each of the verticies using ogrinfo, pipe to grep, and export to output csv file.\n$ogrinfo -al input_polyline.shp | grep linestring | tr -d &quot;LINESTRING()&quot; &gt; output.csv</p>\n<p>-Reformat the verticies [somehow], so that they can be readable to the python script.</p>\n<p>-Rebuild shapefile from output csv with projection information using GDAL/OGR.</p>\n<p>So my plan is to essentially to break down the shapefile, smooth it, and build it back up again, using open source tools. We'll see how far this goes.</p>\n<p>Some reading:</p>\n<p><a href=\"http://en.wikipedia.org/wiki/Ramer-Douglas-Peucker_algorithm\">Douglas-Peucker Algorithm</a></p>\n<p><a href=\"http://users.ox.ac.uk/~orie1848/tutorial.html\">Existing GRASS Implementation</a></p>\n<p><a href=\"http://webhelp.esri.com/arcgisdesktop/9.2/index.cfm?id=530&amp;pid=513&amp;topicname=Simplifying_and_smoothing_features\">Existing ArcGIS Implementation</a></p>\n<ul>\n<li></li>\n</ul>\n",
			"date_published": "2008-09-30T00:00:00Z"
		}
		,
		{
			"id": "https://mattmakesmaps.com/blog/2008-09-14-web-based-grass/",
			"url": "https://mattmakesmaps.com/blog/2008-09-14-web-based-grass/",
			"title": "Web-Based GRASS!",
			"content_html": "<p>Whoo-hoo! After a number of tweaks, I finally was able to install command-line GRASS GIS onto this site. I've been working off of Aaron Racicot's <a href=\"http://www.reprojected.com/geoblog/how-tos/gis-on-a-shared-hosting-environment-the-magic-of-not-having-root/\">tutorial</a> for about a week now. Actually being able to understand and fix some of the errors in the ./configure process is feeling pretty rewarding. I had to manually set the pathways for FFTW and TK using --with-fftw-includes and --with-tclktk-includes respectively. Also, ran into <!-- more --> an issue with NAD2BIN not being explicitly laid out as well, but I was lucky enough to find a forum post stating that I needed to use the command, 'export NAD2BIN=/home/.../bin/nad2bin'.</p>\n<p>I'm not all that familiar with the command line syntax of GRASS, so I actually had to use a local install to view some sample syntax, and modify it for use on the web instance. Pretty fun.</p>\n<p>I'm wondering if there is anyway for a user to access the geoprocessing functionality of this GRASS install w/o logging into the server. Furthermore, could it be possible to tie this into a mapserver / openlayers install? It would be amazing to recreate this <a href=\"http://resources.esri.com/help/9.3/arcgisserver/apis/javascript/arcgis/help/jssamples_start.htm#jssamples/GPviewShed.html\">ESRI on-the-fly geoprocessing example</a> using only open source GIS tools.</p>\n<p>Anyways, it's a pretty cool feeling to be able to upload a file to the server, run a geoprocessing task on it, and download the results back to my machine!</p>\n<blockquote>\n<p>GRASS 6.2.3 (spearfish):~/usr/local/bin &gt; r.shaded.relief map=elevation.dem shadedmap=shade_test altitude=30 azimuth=270 zmult=2 scale=1\nCalculating shading, please stand by.\n100%\nColor table for [shade_test] set to grey</p>\n</blockquote>\n<p>Shaded relief map created and named [shade_test].\nGRASS 6.2.3 (spearfish):~/usr/local/bin &gt; r.out.tiff input=shade_test output=/home/matthewkenny/usr/local/gis_workspace/shade_out compression=none\nWARNING: The map &lt;shade_test&gt; in mapset <user1> is a floating point map.\nDecimal values will be rounded to integer!\nGRASS 6.2.3 (spearfish):~/usr/local/bin &gt;</user1></p>\n<p>And the output image downloaded back to my computer:</p>\n<p><a href=\"http://www.mkgeomatics.com/wordpress/wp-content/uploads/2008/09/shade_out.jpg\"><img src=\"http://www.mkgeomatics.com/wordpress/wp-content/uploads/2008/09/shade_out-300x225.jpg\" alt=\"\"></a></p>\n<p><a href=\"http://www.mkgeomatics.com/wordpress/wp-content/uploads/2008/09/shade_out.tif\"><img src=\"http://www.mkgeomatics.com/wordpress/wp-content/uploads/2008/09/shade_out.tif\" alt=\"\"></a></p>\n",
			"date_published": "2008-09-14T00:00:00Z"
		}
		,
		{
			"id": "https://mattmakesmaps.com/blog/2008-09-14-python-gp-strangeness/",
			"url": "https://mattmakesmaps.com/blog/2008-09-14-python-gp-strangeness/",
			"title": "Python GP Strangeness",
			"content_html": "<p>I had to explicitly set the workspace, list the ASCII files, THEN link the two into a single variable for use in the ASCIIToRaster tool. I could have sworn that all I needed to do was to pass along the ASCII variable right into the ASCIIToRaster tool, and it would automatically carry the file path along with it. Maybe that is only the case when you are working with fields, rather than rasters / feature classes?</p>\n<!-- more -->\n<pre class=\"language-python\" tabindex=\"0\"><code class=\"language-python\"><span class=\"token comment\">#Batch Convert ASCII to ESRI GRID</span>\n<span class=\"token comment\">#Matthew Kenny</span>\n<span class=\"token comment\">#September 14, 2008</span>\n<span class=\"token comment\">#############################################################</span>\n<span class=\"token comment\"># Import the arcgisscripting module</span>\n<span class=\"token keyword\">import</span> sys<span class=\"token punctuation\">,</span> arcgisscripting\n\n<span class=\"token comment\"># Create the Geoprocessor object</span>\ngp <span class=\"token operator\">=</span> arcgisscripting<span class=\"token punctuation\">.</span>create<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># Set the workspace</span>\ngp<span class=\"token punctuation\">.</span>workspace <span class=\"token operator\">=</span> <span class=\"token punctuation\">(</span><span class=\"token string\">\"F:/!South_Kona/DEM_XYZ_Tiled/Area1/Group5/ASCII/\"</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># get list of all the ASCII files in the workspace</span>\nasciiList <span class=\"token operator\">=</span> gp<span class=\"token punctuation\">.</span>ListRasters<span class=\"token punctuation\">(</span><span class=\"token string\">\"*DEM*\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"*\"</span><span class=\"token punctuation\">)</span>\n<span class=\"token builtin\">ascii</span> <span class=\"token operator\">=</span> asciiList<span class=\"token punctuation\">.</span><span class=\"token builtin\">next</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n<span class=\"token keyword\">print</span> <span class=\"token string\">\"Starting with \"</span> <span class=\"token operator\">+</span> <span class=\"token builtin\">ascii</span>\n\n<span class=\"token comment\"># Set initial INPUT file</span>\ninputAscii <span class=\"token operator\">=</span> gp<span class=\"token punctuation\">.</span>workspace <span class=\"token operator\">+</span> <span class=\"token string\">\"/\"</span> <span class=\"token operator\">+</span> <span class=\"token builtin\">ascii</span>\n<span class=\"token keyword\">print</span> inputAscii\n\n<span class=\"token comment\"># Set initial OUTPUT file</span>\nraster <span class=\"token operator\">=</span> gp<span class=\"token punctuation\">.</span>workspace <span class=\"token operator\">+</span> <span class=\"token string\">\"/GRID/\"</span> <span class=\"token operator\">+</span> <span class=\"token builtin\">ascii</span><span class=\"token punctuation\">[</span><span class=\"token punctuation\">:</span><span class=\"token operator\">-</span><span class=\"token number\">8</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">+</span> <span class=\"token string\">\".img\"</span>\n<span class=\"token keyword\">print</span> raster\n\n<span class=\"token comment\"># loop through list of feature classes</span>\n<span class=\"token keyword\">while</span> <span class=\"token builtin\">ascii</span><span class=\"token punctuation\">:</span>\n<span class=\"token comment\">#Execute ASCII to Raster</span>\n    gp<span class=\"token punctuation\">.</span>ASCIIToRaster_conversion<span class=\"token punctuation\">(</span>inputAscii<span class=\"token punctuation\">,</span> raster<span class=\"token punctuation\">,</span> <span class=\"token string\">\"INTEGER\"</span><span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">print</span> <span class=\"token string\">\"File \"</span> <span class=\"token operator\">+</span> raster<span class=\"token operator\">+</span> <span class=\"token string\">\" has been created.\"</span>\n    <span class=\"token builtin\">ascii</span> <span class=\"token operator\">=</span> asciiList<span class=\"token punctuation\">.</span><span class=\"token builtin\">next</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">print</span> <span class=\"token string\">\"Moving onto \"</span> <span class=\"token operator\">+</span> <span class=\"token builtin\">ascii</span>\n    inputAscii <span class=\"token operator\">=</span> gp<span class=\"token punctuation\">.</span>workspace <span class=\"token operator\">+</span> <span class=\"token string\">\"/\"</span> <span class=\"token operator\">+</span> <span class=\"token builtin\">ascii</span>\n    <span class=\"token keyword\">print</span> <span class=\"token string\">\"new inputAscii: \"</span> <span class=\"token operator\">+</span> inputAscii\n    raster <span class=\"token operator\">=</span> gp<span class=\"token punctuation\">.</span>workspace <span class=\"token operator\">+</span> <span class=\"token string\">\"/GRID/\"</span> <span class=\"token operator\">+</span> <span class=\"token builtin\">ascii</span><span class=\"token punctuation\">[</span><span class=\"token punctuation\">:</span><span class=\"token operator\">-</span><span class=\"token number\">8</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">+</span> <span class=\"token string\">\".img\"</span>\n    <span class=\"token keyword\">print</span> <span class=\"token string\">\"new output Raster: \"</span> <span class=\"token operator\">+</span> raster\n<span class=\"token builtin\">ascii</span> <span class=\"token operator\">=</span> asciiList<span class=\"token punctuation\">.</span>reset<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\">#remove geoprocessor object from memory</span>\n<span class=\"token keyword\">del</span> gp</code></pre>\n",
			"date_published": "2008-09-14T00:00:00Z"
		}
		,
		{
			"id": "https://mattmakesmaps.com/blog/2008-09-12-gdal-proj4-on-shared-webhost/",
			"url": "https://mattmakesmaps.com/blog/2008-09-12-gdal-proj4-on-shared-webhost/",
			"title": "GDAL / PROJ.4 On Shared Webhost",
			"content_html": "<p>For the past couple of days, I've been putting hours into understanding Aaron Racicot's, '<a href=\"http://www.reprojected.com/geoblog/how-tos/gis-on-a-shared-hosting-environment-the-magic-of-not-having-root/\">guide to GIS on a shared hosting service</a>'. This has been a great learning experience in working w/ SSH and a full mapserver install from the source. My goal is to host a Mapserver WMS directly from this site. I've got everything in place... probably not configured correctly, probably full of errors, probably will never work (w/o a healthy dose of patience).</p>\n<p>I do however, know that I am on the right track, as GDAL/OGR and PROJ.4 are up and running.</p>\n<!-- more -->\n<blockquote>\n<p>[gotti]$ ./ogrinfo -al -so /home/matthewkenny/usr/local/shp_samples/county_polygon.shp\nINFO: Open of <code>/home/matthewkenny/usr/local/shp_samples/county_polygon.shp' using driver </code>ESRI Shapefile' successful.</p>\n</blockquote>\n<p>Layer name: county_polygon\nGeometry: Polygon\nFeature Count: 39\nExtent: (576751.628593, 81877.320813) - (2551197.698864, 1355595.418907)\nLayer SRS WKT:\nPROJCS[&quot;NAD_1983_HARN_StatePlane_Washington_South_FIPS_4602_Feet&quot;,\nGEOGCS[&quot;GCS_North_American_1983_HARN&quot;,\nDATUM[&quot;NAD83_High_Accuracy_Regional_Network&quot;,\nSPHEROID[&quot;GRS_1980&quot;,6378137.0,298.257222101]],\nPRIMEM[&quot;Greenwich&quot;,0.0],\nUNIT[&quot;Degree&quot;,0.0174532925199433]],\nPROJECTION[&quot;Lambert_Conformal_Conic_2SP&quot;],\nPARAMETER[&quot;False_Easting&quot;,1640416.666666667],\nPARAMETER[&quot;False_Northing&quot;,0.0],\nPARAMETER[&quot;Central_Meridian&quot;,-120.5],\nPARAMETER[&quot;Standard_Parallel_1&quot;,45.83333333333334],\nPARAMETER[&quot;Standard_Parallel_2&quot;,47.33333333333334],\nPARAMETER[&quot;Latitude_Of_Origin&quot;,45.33333333333334],\nUNIT[&quot;Foot_US&quot;,0.3048006096012192]]\nCOUNTY_COD: Integer (2.0)\nCOUNTY_FIP: String (3.0)\nCOUNTY_NM: String (15.0)\nECY_REGION: String (4.0)\nAIR_REGION: String (46.0)\n[gotti]$</p>\n",
			"date_published": "2008-09-12T00:00:00Z"
		}
		,
		{
			"id": "https://mattmakesmaps.com/blog/2008-09-08-plans/",
			"url": "https://mattmakesmaps.com/blog/2008-09-08-plans/",
			"title": "Plans",
			"content_html": "<p>I've finished downloading my previous portfolio site from Western's server. Until I finish pushing the content into this design, it will be accessible either from the link on the right, or by following this link below:</p>\n<p><a href=\"http://deptweb.wwu.edu/huxley/huxweb/gis/Portfolio/08/kennym2\">http://deptweb.wwu.edu/huxley/huxweb/gis/Portfolio/08/kennym2</a></p>\n<p>I hope to have it up by the end of the week. Stay tuned.</p>\n",
			"date_published": "2008-09-08T00:00:00Z"
		}
		,
		{
			"id": "https://mattmakesmaps.com/blog/2008-09-07-i-am-matt/",
			"url": "https://mattmakesmaps.com/blog/2008-09-07-i-am-matt/",
			"title": "i am matt",
			"content_html": "<p>how may i help you visualize the world around us?</p>\n<!-- more -->\n",
			"date_published": "2008-09-07T00:00:00Z"
		}
		,
		{
			"id": "https://mattmakesmaps.com/blog/2008-09-07-free-courses-in-gis/",
			"url": "https://mattmakesmaps.com/blog/2008-09-07-free-courses-in-gis/",
			"title": "University Courses in GIS",
			"content_html": "<p>So, like many GIS users, I find myself scouring google for tips / tricks / solutions to problems. These searches regularly lead me to GIS course webpages from various universities. Hurrah for the internet! Right? <!-- more --></p>\n<p>Some of the best that I have found are in regards to both commercial as well as open source software. I've found the following courses to be of particular benefit to me over the last year.</p>\n<p><a href=\"http://www.gis.usu.edu/~jlowry/python/\">Utah State University - WILD 6900 - GIS Programming with Python (ESRI) </a></p>\n<p><a href=\"http://www.gis.usu.edu/~chrisg/python/\">Utah State University - WILD 6900 - GIS Programming with Python (Open Source) </a></p>\n<p><a href=\"https://courseware.e-education.psu.edu/courses/geog585/content/home.html\">Penn State - GEOG 585 - Open Web Mapping </a></p>\n<p><a href=\"http://ocw.mit.edu/OcwWeb/Urban-Studies-and-Planning/11-521Spatial-Database-Management-and-Advanced-Geographic-Information-SystemsSpring2003/CourseHome/index.htm\">MIT - 11.521 / 11.523 / 11.524 - Database Management and Advanced Geographic Information Systems</a></p>\n<p><a href=\"http://ocw.mit.edu/OcwWeb/Civil-and-Environmental-Engineering/1-963Fall-2004/CourseHome/\">MIT - 1963 - Environmental Engineering Applications of Geographic Information Systems</a></p>\n",
			"date_published": "2008-09-07T00:00:00Z"
		}
		
	]
}
